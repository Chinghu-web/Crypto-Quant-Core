# main.py - [v7.9.4 å¹³è¡¡ä¼˜åŒ–ç‰ˆ]
# æ ¸å¿ƒç­–ç•¥ï¼šåè½¬(RSI 20/80 + è¶‹åŠ¿å‡å¼±) + è¶‹åŠ¿é¢„åˆ¤(è“„åŠ¿ç¡®è®¤) + ğŸ”¥é«˜æ³¢åŠ¨è½¨é“(è“„åŠ¿é¢„åˆ¤)
# æ ¸å¿ƒé£æ§ï¼š30åˆ†é’Ÿå»é‡ + è§‚å¯ŸæœŸäºŒæ¬¡æ¢åº•å®¹å¿ + DeepSeekäºŒå®¡
# v7.9.4æ›´æ–°ï¼šæ”¾å®½RSIé˜ˆå€¼(20/80) + æ”¾å®½åŠ¨èƒ½å‡å¼±åˆ¤æ–­(10æ ¹Kçº¿) + æˆäº¤é‡è¦æ±‚1.5x

import os
import json
import yaml
import ccxt
import sqlite3
import argparse
import datetime as dt
import time
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict

# ============ æ ¸å¿ƒå·¥å…·åº“å¯¼å…¥ ============
from core.utils import (
    ema, atr, realized_vol, wick_scores,
    funding_score, macro_score, orderbook_strength_fetch, oi_trend_score,
    cleanup_funding_oi_cache,
    adx, bollinger_bandwidth, rsi, macd
)

# ============ ç»„ä»¶åº“å¯¼å…¥ ============
from core.notifier import tg_send
from core.state import ensure_db
from core.enhanced_reporting import report_daily_enhanced, report_weekly_enhanced
from core.enhanced_reporting import should_run_daily_report, should_run_weekly_report
from core.adaptive_stops import calculate_adaptive_stops
from core.signal_tracker import update_signal_tracking

from core.btc_advanced_monitor import check_btc_market_advanced, format_btc_status_message
from core.altcoin_correlation import get_cached_correlation, format_correlation_message

from core.claude_reviewer import ClaudeReviewer
from core.free_fingpt import FreeFinGPT
from core.xgboost_collector import XGBoostDataCollector
from core.auto_trader import AutoTrader
from core.signal_watcher import SignalWatcher

# ğŸ”¥ğŸ”¥ğŸ”¥ é«˜æ³¢åŠ¨è½¨é“å¯¼å…¥
try:
    from core.high_volatility_track import HighVolatilityTrack
    HIGH_VOL_TRACK_AVAILABLE = True
except ImportError:
    HIGH_VOL_TRACK_AVAILABLE = False
    print("[WARN] é«˜æ³¢åŠ¨è½¨é“æ¨¡å—(core/high_volatility_track.py)æœªæ‰¾åˆ°ï¼ŒåŠŸèƒ½å°†ç¦ç”¨")

# ============ æ¨¡å—å¯ç”¨æ€§æ£€æµ‹ ============
# è¶‹åŠ¿é¢„åˆ¤æ¨¡å—
try:
    from core.trend_anticipation import (
        detect_trend_anticipation,
        detect_support_resistance,
        SignalDeduplicator,
        get_recent_trades,
        get_trade_statistics,
        add_trade_to_history
    )
    TREND_ANTICIPATION_AVAILABLE = True
except ImportError:
    print("[WARN] è¶‹åŠ¿é¢„åˆ¤æ¨¡å—(core/trend_anticipation.py)æœªæ‰¾åˆ°ï¼Œç›¸å…³åŠŸèƒ½å°†ç¦ç”¨")
    TREND_ANTICIPATION_AVAILABLE = False
    # æä¾›ç©ºå®ç°ä»¥é˜²æ­¢æŠ¥é”™
    def detect_trend_anticipation(*args, **kwargs): return None
    def detect_support_resistance(*args, **kwargs): return {"bonus": 0, "nearest_level": 0}
    class SignalDeduplicator:
        def __init__(self, cfg): pass
        def should_emit(self, *args): return True, "æ¨¡å—æœªåŠ è½½"
    def get_recent_trades(count=10): return []
    def get_trade_statistics(): return {}
    def add_trade_to_history(trade): pass

# ============ å…¨å±€å˜é‡ä¸ç¼“å­˜ ============
_BTC_MARKET_CACHE = {"data": None, "ts": 0}
_CACHE_STATUS = {"fingpt_last_update": 0, "funding_oi_last_update": 0}
_SIGNAL_DEDUP_CACHE: Dict[str, Dict] = {} 
_MTF_KLINE_CACHE: Dict[str, Dict] = {}
_MTF_CACHE_TTL = 60
_TRADE_HISTORY_CACHE: List[Dict] = []
_FIRST_CYCLE_DONE = False

# å…¨å±€ç»„ä»¶å¼•ç”¨
_SIGNAL_WATCHER = None
_AUTO_TRADER = None
_HIGH_VOL_TRACK = None  # ğŸ”¥ é«˜æ³¢åŠ¨è½¨é“

# æ€§èƒ½ä¼˜åŒ–ç¼“å­˜
_DISCOVER_CACHE = {"symbols": [], "ts": 0, "ttl": 1800}
_HIGH_VOL_DISCOVER_CACHE = {"symbols": [], "ts": 0, "ttl": 300}  # ğŸ”¥ è½¨é“2ç‹¬ç«‹ç¼“å­˜ï¼ˆ5åˆ†é’Ÿï¼‰
_ORDERBOOK_CACHE = {}  
_ORDERBOOK_TTL = 120   
_FUNDING_BATCH_CACHE = {} 
_FUNDING_BATCH_TTL = 300   

# ============ è¾…åŠ©æ‰“å°å‡½æ•° ============
def print_btc_status_enhanced(btc_status: Dict[str, Any]):
    """æ‰“å°è¯¦ç»†çš„BTCå¸‚åœºçŠ¶æ€"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š BTC å¸‚åœºçŠ¶æ€ç›‘æ§")
    print(f"{'='*60}")
    
    price = btc_status.get('price', 0)
    print(f"ğŸ’° å½“å‰ä»·æ ¼: ${price:,.2f}")
    
    # æ¶¨è·Œå¹…
    change_1h = btc_status.get('price_change_1h', 0)
    change_4h = btc_status.get('price_change_4h', 0)
    emoji_1h = "ğŸ“ˆ" if change_1h > 0 else "ğŸ“‰"
    print(f"{emoji_1h} 1å°æ—¶æ¶¨è·Œ: {change_1h:+.2f}% | 4å°æ—¶æ¶¨è·Œ: {change_4h:+.2f}%")
    
    # è¶‹åŠ¿ä¸RSI
    trend = btc_status.get('trend', 'neutral')
    rsi_val = btc_status.get('rsi', 50)
    print(f"ğŸŒŠ å¸‚åœºè¶‹åŠ¿: {trend.upper()} | ğŸ”¥ BTC RSI: {rsi_val:.1f}")
    
    # æ³¢åŠ¨ç‡ä¸åŠ¨é‡
    volatility = btc_status.get('volatility', 0)
    momentum = btc_status.get('momentum_15m', 0)
    print(f"ğŸ“‰ æ³¢åŠ¨ç‡: {volatility:.2f}% | ğŸ’ª åŠ¨é‡(15m): {momentum:+.2f}%")
    
    # äº¤æ˜“å»ºè®®
    allow_long = btc_status.get('allow_long', True)
    allow_short = btc_status.get('allow_short', True)
    
    if allow_long and allow_short:
        print(f"âœ… å±±å¯¨å¸ç­–ç•¥: åŒå‘å¯äº¤æ˜“")
    elif allow_long:
        print(f"âš ï¸ å±±å¯¨å¸ç­–ç•¥: ä»…å»ºè®®åšå¤š")
    elif allow_short:
        print(f"âš ï¸ å±±å¯¨å¸ç­–ç•¥: ä»…å»ºè®®åšç©º")
    else:
        reasons = btc_status.get('altcoin_reversal_reasons', [])
        print(f"ğŸš« å±±å¯¨å¸ç­–ç•¥: æš‚åœäº¤æ˜“ ({', '.join(reasons)})")
    
    print(f"{'='*60}\n")

# ============ åŸºç¡€å·¥å…·å‡½æ•° ============
def normalize_datetime(dt_obj):
    if dt_obj is None: return None
    if isinstance(dt_obj, str): dt_obj = dt.datetime.fromisoformat(dt_obj)
    if dt_obj.tzinfo is None: return dt_obj.replace(tzinfo=dt.timezone.utc)
    else: return dt_obj.astimezone(dt.timezone.utc)

def load_cfg(path="config.yaml")->Dict[str,Any]:
    with open(path,"r",encoding="utf-8") as f: cfg=yaml.safe_load(f)
    # é»˜è®¤é…ç½®å…œåº•
    cfg.setdefault("exchange", {"name":"binance","timeframe":"1m","limit":800})
    cfg.setdefault("push", {"master":"on","observe_only":False,"thresholds":{"majors":0.75}})
    cfg.setdefault("analytics", {"storage":{"path":"./signals.db"}})
    cfg.setdefault("performance", {"kline_workers": 5, "kline_limit": 800})
    return cfg

def get_exchange(cfg):
    klass = getattr(ccxt, cfg["exchange"]["name"])
    ex = klass({"enableRateLimit": True, "options": {"adjustForTimeDifference": True}})
    market_type = cfg.get("exchange", {}).get("market_type", "future")
    if market_type == "future": ex.options['defaultType'] = 'future'
    return ex

# ============ æ•°æ®è·å–å‡½æ•° (å¹¶å‘ä¼˜åŒ–) ============
def fetch_df_single(ex, symbol: str, timeframe: str, limit: int) -> tuple:
    """è·å–å•ä¸ªäº¤æ˜“å¯¹Kçº¿"""
    try:
        raw = ex.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)
        if not raw or len(raw) < 60:
            return (symbol, None)
        df = pd.DataFrame(raw, columns=["ts","open","high","low","close","volume"])
        df["ts"] = pd.to_datetime(df["ts"], unit="ms", utc=True)
        return (symbol, df)
    except Exception as e:
        # print(f"[FETCH_ERR] {symbol}: {e}")
        return (symbol, None)

def fetch_df(ex, symbol, timeframe, limit)->Optional[pd.DataFrame]:
    """å…¼å®¹æ—§æ¥å£"""
    _, df = fetch_df_single(ex, symbol, timeframe, limit)
    return df

def fetch_klines_batch(ex, symbols: List[str], timeframe: str, limit: int, workers: int = 5) -> Dict[str, pd.DataFrame]:
    """å¹¶å‘æ‰¹é‡è·å–Kçº¿"""
    results = {}
    print(f"[KLINE] ğŸš€ æ­£åœ¨å¹¶å‘è·å– {len(symbols)} ä¸ªäº¤æ˜“å¯¹ï¼ˆ{workers}çº¿ç¨‹ï¼‰...")
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {
            executor.submit(fetch_df_single, ex, sym, timeframe, limit): sym 
            for sym in symbols
        }
        for future in as_completed(futures):
            try:
                symbol, df = future.result()
                if df is not None:
                    results[symbol] = df
            except Exception: pass
    
    elapsed = time.time() - start_time
    print(f"[KLINE] âœ… å®Œæˆï¼š{len(results)}/{len(symbols)} ä¸ªï¼Œè€—æ—¶ {elapsed:.1f}ç§’")
    return results

def batch_fetch_funding_rates(ex, symbols: List[str]) -> Dict[str, Dict]:
    """æ‰¹é‡è·å–èµ„é‡‘è´¹ç‡"""
    global _FUNDING_BATCH_CACHE
    now = time.time()
    results = {}
    symbols_to_fetch = []
    
    # æ£€æŸ¥ç¼“å­˜
    for sym in symbols:
        cached = _FUNDING_BATCH_CACHE.get(sym)
        if cached and (now - cached["ts"]) < _FUNDING_BATCH_TTL:
            results[sym] = cached
        else:
            symbols_to_fetch.append(sym)
    
    if not symbols_to_fetch: return results
    
    try:
        # å°è¯•ä½¿ç”¨ Binance çš„æ‰¹é‡æ¥å£
        funding_data = ex.fapiPublicGetPremiumIndex()
        funding_map = {item["symbol"]: float(item.get("lastFundingRate", 0) or 0) for item in funding_data}
        
        for sym in symbols_to_fetch:
            clean_sym = sym.replace("/", "").replace(":USDT", "")
            rate = funding_map.get(clean_sym, 0)
            score = float(np.clip(0.5 + 0.5 * np.tanh(-rate * 200), 0.0, 1.0))
            cache_entry = {"rate": rate, "score": score, "ts": now}
            _FUNDING_BATCH_CACHE[sym] = cache_entry
            results[sym] = cache_entry
            
    except Exception:
        # å¦‚æœæ‰¹é‡æ¥å£å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼Œä¸é˜»å¡æµç¨‹
        for sym in symbols_to_fetch:
            results[sym] = {"rate": 0, "score": 0.5, "ts": now}
            
    return results

def orderbook_strength_cached(ex, symbol: str, limit: int = 20) -> float:
    """å¸¦ç¼“å­˜çš„ Orderbook æ·±åº¦è·å–"""
    global _ORDERBOOK_CACHE
    now = time.time()
    cached = _ORDERBOOK_CACHE.get(symbol)
    if cached and (now - cached["ts"]) < _ORDERBOOK_TTL: return cached["data"]
    try:
        ob = ex.fetch_order_book(symbol, limit=limit)
        bid_vol = sum([b[1] for b in ob.get("bids", [])])
        ask_vol = sum([a[1] for a in ob.get("asks", [])])
        
        if bid_vol + ask_vol <= 0:
            result = 0.5
        else:
            result = float(0.5 + 0.5 * np.tanh(np.log(bid_vol / max(1e-9, ask_vol) + 1e-9)))
            
        _ORDERBOOK_CACHE[symbol] = {"data": result, "ts": now}
        return result
    except: return 0.5

def last_price(df: pd.DataFrame)->float: return float(df["close"].iloc[-1])

# ============ FinGPT & Metrics ============
def get_fingpt_sentiment(symbol: str, fingpt: FreeFinGPT, tech_indicators: Dict[str, Any], cfg: Dict[str, Any]) -> Dict[str, Any]:
    """è°ƒç”¨ FinGPT è·å–æƒ…ç»ªåˆ†æ•°"""
    fingpt_cfg = cfg.get("fingpt", {})
    if not fingpt_cfg.get("enabled", True):
        return {"sentiment_score": 0.0, "fear_greed": 50, "_cached": False}
    try:
        result = fingpt.analyze(symbol, tech_indicators)
        sentiment_data = result.get("sentiment", {})
        return {
            "sentiment_score": sentiment_data.get("score", 0.0),
            "fear_greed": sentiment_data.get("fear_greed", 50),
            "_cached": False
        }
    except:
        return {"sentiment_score": 0.0, "fear_greed": 50, "_cached": False}

def compute_common_subscores(cfg: Dict, symbol: str, df: pd.DataFrame, ex, fingpt, tech_indicators, funding_cache: Dict = None)->Dict:
    wick_bull, wick_bear = wick_scores(df)
    fingpt_data = get_fingpt_sentiment(symbol, fingpt, tech_indicators, cfg)
    sentiment_score = (fingpt_data["sentiment_score"] + 1) / 2
    
    if funding_cache and symbol in funding_cache:
        fscore = funding_cache[symbol].get("score", 0.5)
    else:
        fscore = funding_score(symbol, cfg)
        
    mscore = macro_score(cfg)
    obk = orderbook_strength_cached(ex, symbol)
    
    return {
        "fingpt_sentiment": sentiment_score,
        "wick_bull": float(wick_bull), "wick_bear": float(wick_bear), 
        "funding": float(fscore), "macro": float(mscore), "orderbook": float(obk), "oi": 0.5,
        "_fingpt_fear_greed": fingpt_data["fear_greed"]
    }

def weighted_score(base: float, subs: Dict[str,float], weights_cfg: Dict[str,float]):
    candidates = {
        "fingpt_sentiment": subs.get("fingpt_sentiment", 0.5),
        "funding": subs.get("funding", 0.5), 
        "macro": subs.get("macro", 0.5), 
        "orderbook": subs.get("orderbook", 0.5), 
        "oi": subs.get("oi", 0.5)
    }
    
    # æƒé‡è®¡ç®—
    w = {k:max(0.0,float(v)) for k,v in (weights_cfg or {}).items() if k in candidates}
    s = sum(w.values())
    if s<=0: n = max(1,len(candidates)); weights = {k: 1.0/n for k in candidates}
    else: weights = {k: v/s for k,v in w.items()}
    
    adj = sum(float(weights[k]) * (float(candidates[k]) - 0.5) for k in weights)
    return max(0.0, min(1.0, base + adj)), weights

def detect_macd_divergence(df: pd.DataFrame, lookback: int = 50) -> Dict[str, Any]:
    """æ£€æµ‹ MACD èƒŒç¦»"""
    if len(df) < lookback + 26: return {"bullish_divergence": False, "bearish_divergence": False, "divergence_strength": 0.0}
    
    macd_line, signal_line, histogram = macd(df, 12, 26, 9)
    recent_macd = macd_line.tail(lookback).values
    recent_prices = df["close"].tail(lookback).values
    
    price_lows, macd_lows = [], []
    price_highs, macd_highs = [], []
    
    # å¯»æ‰¾æ³¢å³°æ³¢è°·
    for i in range(5, len(recent_prices) - 5):
        if recent_prices[i] == min(recent_prices[i-5:i+6]):
            price_lows.append((i, recent_prices[i]))
        if recent_macd[i] == min(recent_macd[i-5:i+6]):
            macd_lows.append((i, recent_macd[i]))
        if recent_prices[i] == max(recent_prices[i-5:i+6]):
            price_highs.append((i, recent_prices[i]))
        if recent_macd[i] == max(recent_macd[i-5:i+6]):
            macd_highs.append((i, recent_macd[i]))

    bullish_div = False
    div_strength = 0.0
    
    # åˆ¤æ–­åº•èƒŒç¦»
    if len(price_lows) >= 2 and len(macd_lows) >= 2:
        last_p, prev_p = price_lows[-1], price_lows[-2]
        # ç®€å•å–æœ€è¿‘çš„ macd å€¼å¯¹æ¯” (è¿‘ä¼¼å¤„ç†)
        m_last = recent_macd[last_p[0]]
        m_prev = recent_macd[prev_p[0]]
        
        if last_p[1] < prev_p[1] and m_last > m_prev:
            bullish_div = True
            div_strength = 0.8
    
    # åˆ¤æ–­é¡¶èƒŒç¦»
    bearish_div = False
    if len(price_highs) >= 2 and len(macd_highs) >= 2:
        last_p, prev_p = price_highs[-1], price_highs[-2]
        m_last = recent_macd[last_p[0]]
        m_prev = recent_macd[prev_p[0]]
        
        if last_p[1] > prev_p[1] and m_last < m_prev:
            bearish_div = True
            div_strength = 0.8
            
    return {"bullish_divergence": bullish_div, "bearish_divergence": bearish_div, "divergence_strength": div_strength}

def build_enhanced_metrics(df: pd.DataFrame, cfg: Dict[str,Any])->Dict[str,Any]:
    """æ„å»ºå¢å¼ºç‰ˆæŠ€æœ¯æŒ‡æ ‡"""
    ema12_v = float(ema(df["close"], 12).iloc[-1])
    ema26_v = float(ema(df["close"], 26).iloc[-1])
    ema_cross = "golden" if ema12_v > ema26_v else ("death" if ema12_v < ema26_v else "none")
    
    atr_v = float(atr(df, 14).iloc[-1])
    
    vol_ma = float(df["volume"].rolling(20).mean().iloc[-1])
    vol_last = float(df["volume"].iloc[-1])
    vol_spike_ratio = (vol_last / vol_ma) if vol_ma > 0 else 1.0
    
    # ğŸ”¥ ä¿®å¤ï¼šè®¡ç®—wick scores
    wick_bull, wick_bear = wick_scores(df)
    
    adx_val = float(adx(df, 14).iloc[-1])
    bb_width = float(bollinger_bandwidth(df, 20, 2.0).iloc[-1])
    
    obs_cfg = cfg.get("overbought_oversold", {})
    rsi_val = float(rsi(df, obs_cfg.get("rsi_period", 14)).iloc[-1])
    
    macd_line, signal_line, histogram = macd(df, 12, 26, 9)
    macd_hist = float(histogram.iloc[-1])
    divergence_data = detect_macd_divergence(df, 50)
    
    # RSI çŠ¶æ€
    rsi_state = "neutral"
    if rsi_val >= 80: rsi_state = "extreme_overbought"
    elif rsi_val >= 70: rsi_state = "overbought"
    elif rsi_val <= 20: rsi_state = "extreme_oversold"
    elif rsi_val <= 30: rsi_state = "oversold"
    
    # å¸ƒæ—å¸¦æ•°æ®
    sma = df["close"].rolling(20).mean()
    std = df["close"].rolling(20).std()
    bb_middle = float(sma.iloc[-1]) if len(sma) > 0 else 0.0
    bb_upper = float(sma.iloc[-1] + 2 * std.iloc[-1]) if len(sma) > 0 else 0.0
    bb_lower = float(sma.iloc[-1] - 2 * std.iloc[-1]) if len(sma) > 0 else 0.0
    bb_position = (df["close"].iloc[-1] - sma.iloc[-1]) / std.iloc[-1] if std.iloc[-1] > 0 else 0.0
    
    # 24h æ¶¨è·Œå¹…
    price_now = float(df["close"].iloc[-1])
    price_change_24h_pct = 0.0
    try:
        if len(df) >= 1440:
            price_24h = float(df["close"].iloc[-1440])
            price_change_24h_pct = (price_now - price_24h) / price_24h
        elif len(df) > 0:
            price_24h = float(df["close"].iloc[0])
            price_change_24h_pct = (price_now - price_24h) / price_24h
    except: pass

    return {
        "ema12": ema12_v, "ema26": ema26_v, "ema_cross": ema_cross, "atr": atr_v,
        "vol_ma": vol_ma, "vol_last": vol_last, "vol_spike_ratio": vol_spike_ratio,
        "wick_absorb_score": float(max(wick_bull, wick_bear)),
        "adx": adx_val, "bb_width": bb_width, "bb_upper": bb_upper, "bb_lower": bb_lower, "bb_position": bb_position,
        "rsi": rsi_val, "rsi_state": rsi_state,
        "macd": float(macd_line.iloc[-1]), "macd_signal": float(signal_line.iloc[-1]), "macd_histogram": macd_hist, "macd_cross": "none",
        "bullish_divergence": divergence_data["bullish_divergence"],
        "bearish_divergence": divergence_data["bearish_divergence"],
        "divergence_strength": divergence_data["divergence_strength"],
        "price_change_24h_pct": float(price_change_24h_pct)
    }

# ============ ğŸ”¥ [å·²åˆ é™¤] è¶‹åŠ¿è·Ÿéšç­–ç•¥ ============
# v7.9: è¶‹åŠ¿è·Ÿéšå·²åˆ é™¤ï¼Œå…¶åˆç†ç‰¹ç‚¹å·²èå…¥è¶‹åŠ¿é¢„åˆ¤
# åŸå› ï¼š1. å’Œè¶‹åŠ¿é¢„åˆ¤é‡å  2. ä¿¡å·ç¨€å°‘ 3. å…¥åœºæ—¶æœºå·®

# ============ ğŸ”¥ ç­–ç•¥1: åè½¬ (Reversal) - v7.9.4å¹³è¡¡ç‰ˆ ============
def majors_signal_with_obs(cfg, ex, symbol, df, btc_status, fingpt, correlation_analysis=None, funding_cache=None):
    """
    åè½¬ç­–ç•¥ï¼šRSIè¿‡æ»¤ + ğŸ”¥v7.9.4å¹³è¡¡ç‰ˆè¶‹åŠ¿å‡å¼±ç¡®è®¤
    """
    m = build_enhanced_metrics(df, cfg)
    
    adx_val = m.get("adx", 0)
    vol_spike = m.get("vol_spike_ratio", 1.0)
    rsi_val = m.get("rsi", 50.0)
    
    # 1. åŸºç¡€è¿‡æ»¤ï¼šADXå¤ªä½ä¸”æ— é‡
    if adx_val < 15 and vol_spike < 1.5: return None  # ğŸ”¥ v7.9.4: 2.0 -> 1.5
    
    # 2. ğŸ”¥ v7.9.4: å¹³è¡¡ç‰ˆRSIé˜ˆå€¼
    # æç«¯é˜ˆå€¼ï¼šRSIâ‰¤15åšå¤šï¼ŒRSIâ‰¥85åšç©ºï¼ˆç›´æ¥æ”¾è¡Œï¼‰
    # æ™®é€šé˜ˆå€¼ï¼šRSIâ‰¤20åšå¤šï¼ŒRSIâ‰¥80åšç©ºï¼ˆéœ€è¦èƒŒç¦»æˆ–å·¨é‡ï¼‰
    rsi_extreme_oversold = 15   # ğŸ”¥ v7.9.4: 12 -> 15 æ”¾å®½
    rsi_extreme_overbought = 85 # ğŸ”¥ v7.9.4: 88 -> 85 æ”¾å®½
    rsi_normal_oversold = 20    # ğŸ”¥ v7.9.4: 15 -> 20 æ”¾å®½
    rsi_normal_overbought = 80  # ğŸ”¥ v7.9.4: 85 -> 80 æ”¾å®½
    
    bullish_div = m.get("bullish_divergence", False)
    bearish_div = m.get("bearish_divergence", False)
    div_strength = m.get("divergence_strength", 0.0)
    
    valid_signal = False
    bias = "neutral"
    signal_hint = "none"
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ v7.9.4: è¶‹åŠ¿å‡å¼±ç¡®è®¤ï¼ˆæ”¾å®½ç‰ˆï¼‰
    momentum_weakening = False
    still_trending = False
    momentum_weakening_count = 0
    
    if len(df) >= 10:  # ğŸ”¥ v7.9.4: 15 -> 10 æ”¾å®½
        # è®¡ç®—æœ€è¿‘çš„ä»·æ ¼åŠ¨é‡
        prices = df['close'].values
        lows = df['low'].values
        highs = df['high'].values
        
        # ğŸ”¥ v7.9.4: æ£€æŸ¥æœ€è¿‘10æ ¹Kçº¿çš„ä»·æ ¼å˜åŒ–
        recent_changes = [prices[-i] - prices[-i-1] for i in range(1, 10)]
        
        # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨åˆ›æ–°ä½/æ–°é«˜ï¼ˆè¶‹åŠ¿ä»åœ¨è¿›è¡Œï¼‰
        recent_low_5 = min(lows[-5:])
        recent_high_5 = max(highs[-5:])
        current_low = lows[-1]
        current_high = highs[-1]
        prev_low_10 = min(lows[-10:-5]) if len(lows) >= 10 else recent_low_5  # ğŸ”¥ v7.9.4: æ”¾å®½
        prev_high_10 = max(highs[-10:-5]) if len(highs) >= 10 else recent_high_5
        
        # åšå¤šï¼šæ£€æŸ¥ä¸‹è·Œæ˜¯å¦å‡å¼±
        if rsi_val <= rsi_normal_oversold:
            # ğŸ”¥ v7.9.4: è¿˜åœ¨åˆ›æ–°ä½ = è¶‹åŠ¿ä»åœ¨è¿›è¡Œï¼Œä¸å®œåšå¤š
            if current_low < prev_low_10:
                still_trending = True
            
            # ğŸ”¥ v7.9.4: æ£€æŸ¥æœ€è¿‘8æ ¹Kçº¿ä¸­æœ‰å¤šå°‘æ ¹æ˜¯åŠ¨èƒ½å‡å¼±çš„
            if len(recent_changes) >= 8:
                for i in range(0, 6):  # æ£€æŸ¥æœ€è¿‘6æ ¹
                    if recent_changes[i] > recent_changes[i+1]:  # è·Œå¹…å‡å°
                        momentum_weakening_count += 1
                
                # ğŸ”¥ v7.9.4: è‡³å°‘3æ ¹Kçº¿æ˜¾ç¤ºåŠ¨èƒ½å‡å¼±æ‰ç®—ç¡®è®¤
                if momentum_weakening_count >= 3:
                    momentum_weakening = True
                
                # ğŸ”¥ v7.9.4: æ”¾å®½ - æœ€è¿‘3æ ¹æœ‰1æ ¹å‡å¼±å³å¯
                recent_3_weakening = sum(1 for i in range(0, 2) if recent_changes[i] > recent_changes[i+1])
                if recent_3_weakening < 1:
                    momentum_weakening = False
        
        # åšç©ºï¼šæ£€æŸ¥ä¸Šæ¶¨æ˜¯å¦å‡å¼±
        elif rsi_val >= rsi_normal_overbought:
            # ğŸ”¥ v7.9.4: è¿˜åœ¨åˆ›æ–°é«˜ = è¶‹åŠ¿ä»åœ¨è¿›è¡Œï¼Œä¸å®œåšç©º
            if current_high > prev_high_10:
                still_trending = True
            
            # ğŸ”¥ v7.9.4: æ£€æŸ¥æœ€è¿‘8æ ¹Kçº¿ä¸­æœ‰å¤šå°‘æ ¹æ˜¯åŠ¨èƒ½å‡å¼±çš„
            if len(recent_changes) >= 8:
                for i in range(0, 6):  # æ£€æŸ¥æœ€è¿‘6æ ¹
                    if recent_changes[i] < recent_changes[i+1]:  # æ¶¨å¹…å‡å°
                        momentum_weakening_count += 1
                
                # ğŸ”¥ v7.9.4: è‡³å°‘3æ ¹Kçº¿æ˜¾ç¤ºåŠ¨èƒ½å‡å¼±æ‰ç®—ç¡®è®¤
                if momentum_weakening_count >= 3:
                    momentum_weakening = True
                
                # ğŸ”¥ v7.9.4: æ”¾å®½ - æœ€è¿‘3æ ¹æœ‰1æ ¹å‡å¼±å³å¯
                recent_3_weakening = sum(1 for i in range(0, 2) if recent_changes[i] < recent_changes[i+1])
                if recent_3_weakening < 1:
                    momentum_weakening = False
    
    # --- é€»è¾‘ A: åšå¤šæ£€æŸ¥ (RSIâ‰¤20) ---
    if rsi_val <= rsi_normal_oversold: 
        # ğŸ”¥ å¦‚æœè¿˜åœ¨åˆ›æ–°ä½ä¸”æ²¡æœ‰èƒŒç¦»ï¼Œæ‹’ç»ä¿¡å·
        if still_trending and not bullish_div:
            return None
        
        # æƒ…å†µ1: æç«¯è¶…å– (RSI <= 15) + åŠ¨èƒ½å‡å¼± -> æ”¾è¡Œ
        if rsi_val <= rsi_extreme_oversold:
            if momentum_weakening or bullish_div or vol_spike > 1.5:  # ğŸ”¥ v7.9.4: 2.0 -> 1.5
                valid_signal = True
                bias = "long"
                signal_hint = "extreme_oversold" + ("_weakening" if momentum_weakening else "")
        # æƒ…å†µ2: æ™®é€šè¶…å– (15 < RSI <= 20) -> å¿…é¡»æœ‰èƒŒç¦» æˆ– å·¨é‡(>2.0x) + åŠ¨èƒ½å‡å¼±
        elif bullish_div and div_strength > 0.4:
            valid_signal = True
            bias = "long"
            signal_hint = "oversold_with_div"
        elif vol_spike > 2.0 and momentum_weakening:  # ğŸ”¥ v7.9.4: 2.5 -> 2.0
            valid_signal = True
            bias = "long"
            signal_hint = "panic_selling_weakening"
            
    # --- é€»è¾‘ B: åšç©ºæ£€æŸ¥ (RSIâ‰¥80) ---
    elif rsi_val >= rsi_normal_overbought: 
        # ğŸ”¥ å¦‚æœè¿˜åœ¨åˆ›æ–°é«˜ä¸”æ²¡æœ‰èƒŒç¦»ï¼Œæ‹’ç»ä¿¡å·
        if still_trending and not bearish_div:
            return None
        
        # æƒ…å†µ1: æç«¯è¶…ä¹° (RSI >= 85) + åŠ¨èƒ½å‡å¼± -> æ”¾è¡Œ
        if rsi_val >= rsi_extreme_overbought:
            if momentum_weakening or bearish_div or vol_spike > 1.5:  # ğŸ”¥ v7.9.4: 2.0 -> 1.5
                valid_signal = True
                bias = "short"
                signal_hint = "extreme_overbought" + ("_weakening" if momentum_weakening else "")
        # æƒ…å†µ2: æ™®é€šè¶…ä¹° (80 <= RSI < 85) -> å¿…é¡»æœ‰èƒŒç¦» æˆ– å·¨é‡(>2.0x) + åŠ¨èƒ½å‡å¼±
        elif bearish_div and div_strength > 0.4:
            valid_signal = True
            bias = "short"
            signal_hint = "overbought_with_div"
        elif vol_spike > 2.0 and momentum_weakening:  # ğŸ”¥ v7.9.4: 2.5 -> 2.0
            valid_signal = True
            bias = "short"
            signal_hint = "panic_buying_weakening"

    if not valid_signal: return None
    
    # ğŸ”¥ è®°å½•è¶‹åŠ¿å‡å¼±çŠ¶æ€åˆ°metrics
    m["momentum_weakening"] = momentum_weakening
    m["still_trending"] = still_trending
    m["momentum_weakening_count"] = momentum_weakening_count
    
    # 3. è®¡ç®—åˆ†æ•°
    tech_indicators = {'rsi': rsi_val, 'vol_spike_ratio': vol_spike, 'adx': adx_val}
    subs = compute_common_subscores(cfg, symbol, df, ex, fingpt, tech_indicators, funding_cache)
    
    base_score = 0.75 # èµ·æ­¥åˆ†ç»™é«˜ç‚¹
    wcfg = cfg.get("weights", {})
    score_long, _ = weighted_score(base_score, subs, wcfg)
    score_short, _ = weighted_score(base_score, subs, wcfg)
    
    score = score_long if bias == "long" else score_short
    side = bias
    
    # ç›¸å…³æ€§è°ƒæ•´
    if correlation_analysis:
        score += correlation_analysis.get("score_adjustment", 0.0)
    
    px = last_price(df)
    entry_price = px # Entryç®€åŒ–ä¸ºå½“å‰ä»·ï¼Œåç»­AIå®š
    
    stops = calculate_adaptive_stops(symbol=symbol, price=entry_price, atr=m["atr"], side=side, btc_status=btc_status, df=df)
    
    # è®¡ç®—å¸‚åœºæƒ¯æ€§
    try:
        if len(df) >= 15:
            m["momentum_5m"] = ((df['close'].iloc[-1] - df['close'].iloc[-5]) / df['close'].iloc[-5]) * 100
            m["momentum_15m"] = ((df['close'].iloc[-1] - df['close'].iloc[-15]) / df['close'].iloc[-15]) * 100
        else:
            m["momentum_5m"] = 0.0
            m["momentum_15m"] = 0.0
    except Exception:
        m["momentum_5m"] = 0.0
        m["momentum_15m"] = 0.0
    
    m["fingpt_sentiment"] = subs.get("fingpt_sentiment", 0.5)
    m["funding"] = subs.get("funding", 0.5)
    m["signal_hint"] = signal_hint
    
    return {
        "ts": dt.datetime.utcnow().isoformat(), 
        "category": "majors", "symbol": symbol, "price": px, "entry": entry_price, 
        "score": float(score), "bias": side, "subscores": subs, "metrics": m,
        "calculated_stops": stops, "btc_status": btc_status, 
        "correlation_analysis": correlation_analysis,
        "obs_signals": [signal_hint], "obs_adjustment": 0,
        "signal_type": "reversal", "pullback_pct": 0.0
    }

# ============ Claudeå®¡æ ¸æ¨é€ ============
def claude_review_and_push(cfg, cur, s, reviewer, collector):
    """ä¼˜åŒ–ç‰ˆ: å®¡æ ¸åªåˆ¤æ–­ä¿¡å·è´¨é‡ï¼Œå…¥åœºä»·ç”±è§‚å¯ŸæœŸåAIè¯„ä¼°"""
    push_cfg = cfg.get("push", {})
    master_on = (str(push_cfg.get("master","on")).lower() == "on")
    observe_only = bool(push_cfg.get("observe_only", False))
    th = push_cfg.get("thresholds", {}).get("majors", 0.75)
    
    symbol = s["symbol"]
    print(f"\n[SIGNAL] {symbol} {s['bias'].upper()} | è¯„åˆ†:{s['score']:.2f} | ä»·æ ¼:${s['price']:.4f}")
    
    if s["score"] < th:
        print(f"[SKIP] {symbol} - è¯„åˆ†{s['score']:.2f}<{th:.2f}")
        return None
    
    calculated_stops = s.get("calculated_stops", {})
    if not calculated_stops:
        calculated_stops = {'sl_pct': 3.0, 'tp_pct': 6.0, 'max_leverage': 10, 'category': 'normal'}
    
    # ğŸ†• å‡†å¤‡ä¼ ç»™AIçš„ä¿¡æ¯
    signal_info = {
        "current_price": s["price"],
        "signal_type": s.get("signal_type", "unknown")
    }
    
    payload = {
        "cfg": cfg, "symbol": s["symbol"], "category": s["category"], 
        "price": s["price"], "score": s["score"], "bias": s["bias"],
        "subscores": s.get("subscores", {}), "metrics": s.get("metrics", {}),
        "calculated_stops": calculated_stops, "btc_status": s.get("btc_status", {}),
        "obs_signals": s.get("obs_signals", []),
        "funding": {"rate": 0.0, "score": 0.5}, "oi_data": {"change_24h": 0.0, "score": 0.5},
        "signal_info": signal_info,
        "signal_type": s.get("signal_type", "unknown"),
        "correlation_analysis": s.get("correlation_analysis", {}),
        "support_analysis": s.get("support_analysis", {}),
        "pattern_analysis": s.get("pattern_analysis", {}),
        "volume_analysis": s.get("volume_analysis", {}),
        "mtf_analysis": s.get("mtf_analysis", {}),
        "pullback_pct": s.get("pullback_pct", 0)
    }
    
    print(f"\n[AI_REVIEW] æ­£åœ¨å®¡æ ¸ {s['symbol']} {s['bias']} ({s.get('signal_type')})...")
    result = reviewer.review_signal(payload)
    
    if not result.get("approved", False):
        print(f"âŒ æ‹’ç»: {result.get('reasoning', '')}")
        return None
    
    # ğŸ”¥ å®¡æ ¸é€šè¿‡
    reasoning = result.get("reasoning", "æ— ")
    
    # æ£€æµ‹æ–¹å‘æ˜¯å¦åè½¬
    original_side = s["bias"]
    final_side = result.get("side", original_side)
    
    if final_side != original_side:
        print(f"[AI] ğŸ”„ æ–¹å‘åè½¬: {original_side.upper()} â†’ {final_side.upper()}")
    
    print(f"âœ… å®¡æ ¸é€šè¿‡: {reasoning}")
    
    llm_json_str = json.dumps(result, ensure_ascii=False)
    
    cur.execute("""INSERT INTO signals(ts, category, symbol, price, entry, tp, sl, score, rationale, bias, llm_json, policy_version, ab_bucket)
                   VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)""",
        (s["ts"], s["category"], s["symbol"], s["price"], 0, 0, 0, s["score"], 
         result.get("reasoning", "")[:50], final_side, llm_json_str, "v7.9.4", "A"))
    
    sid = cur.lastrowid
    
    # XGBoost
    if collector and cfg.get("xgboost", {}).get("enabled", True):
        try:
            collector.record_signal(payload, {"approved": True, "entry_price": s["price"]})
        except Exception as e:
            # print(f"[XGBOOST_ERR] {e}")
            pass
    
    # ğŸ†• æ¨é€
    if master_on and not observe_only:
        m = s.get("metrics", {})
        rsi_val = m.get("rsi", 50)
        momentum_5m = m.get("momentum_5m", 0)
        
        signal_type_text = s.get("signal_type", "unknown")
        signal_type_emoji = "ğŸ”„" if signal_type_text == "reversal" else "ğŸ“ˆ"
        
        title = f"ğŸ”” æ–°ä¿¡å· | {s['symbol']} {final_side.upper()} {signal_type_emoji}"
        
        msg_lines = [
            "",
            f"ğŸ’° å½“å‰ä»·: `${s['price']:.6f}`",
            f"ğŸ“Š RSI: `{rsi_val:.1f}` | åŠ¨é‡: `{momentum_5m:+.2f}%`",
            ""
        ]
        
        # ğŸ”¥ è§‚å¯Ÿç³»ç»Ÿæç¤º
        watch_enabled = cfg.get("watch", {}).get("enabled", False)
        if watch_enabled:
            expire_min = cfg.get("watch", {}).get("expire_minutes", 4)
            msg_lines.append(f"ğŸƒ **è¿›å…¥{expire_min}åˆ†é’Ÿè§‚å¯ŸæœŸ**")
            msg_lines.append(f"  AIå°†è¯„ä¼°æœ€ä½³å…¥åœºæ—¶æœºå’Œä»·æ ¼")
            msg_lines.append("")
        
        if reasoning:
            msg_lines.append(f"ğŸ’¡ {reasoning[:70]}")
            msg_lines.append("")
        
        if final_side != original_side:
            msg_lines.append(f"âš ï¸ æ–¹å‘åè½¬: {original_side.upper()} â†’ {final_side.upper()}")
        
        tg_send(cfg, title, msg_lines)
        print(f"[PUSH] {s['symbol']} {final_side} | å®¡æ ¸é€šè¿‡ï¼Œè¿›å…¥è§‚å¯ŸæœŸ")

        # ğŸ”¥ğŸ”¥ åŠ å…¥è§‚å¯Ÿé˜Ÿåˆ—
        global _SIGNAL_WATCHER
        if _SIGNAL_WATCHER:
            try:
                original_signal_type = s.get("signal_type", "unknown")
                
                # æ ¹æ®åŸå§‹ä¿¡å·ç±»å‹ç¡®å®šè§‚å¯Ÿç±»å‹ï¼ˆv7.9: å·²åˆ é™¤trend_continuationï¼‰
                if original_signal_type == "trend_anticipation":
                    signal_type = "trend_anticipation"
                else:
                    # åè½¬ä¿¡å·ï¼šæ ¹æ®RSIåˆ¤æ–­ï¼ˆv7.9.4å¹³è¡¡ç‰ˆï¼š20/80ï¼‰
                    is_reversal = (final_side == "long" and rsi_val <= 20) or \
                                 (final_side == "short" and rsi_val >= 80)
                    signal_type = "reversal" if is_reversal else "trend"

                _SIGNAL_WATCHER.add_signal_to_watch(
                    symbol=s["symbol"],
                    side=final_side,
                    signal_type=signal_type,
                    price=s["price"],
                    rsi=rsi_val,
                    adx=m.get("adx", 0),
                    sl_price=0, tp_price=0, metrics=m, original_payload=payload
                )

            except Exception as e:
                print(f"[WATCHER_ERR] æ·»åŠ è§‚å¯Ÿä¿¡å·å¤±è´¥: {e}")

    else:
        print(f"[OBSERVE] {s['symbol']} {final_side}")

    return sid

def _get_fallback_majors(quote: str = "USDT") -> list:
    majors = ["BTC", "ETH", "SOL", "XRP", "DOGE", "ADA", "AVAX", "LINK", "DOT", "LTC", "BCH", "UNI", "AAVE", "FIL", "INJ", "SUI", "APT", "ARB", "OP", "NEAR", "HBAR", "ETC", "XLM", "TON", "TRX", "DASH", "ZEC", "WAVES", "CRV", "ICP", "BNB", "BONK", "WIF", "CHZ"]
    return [f"{coin}/{quote}:{quote}" for coin in majors]

# ============ Discover Symbols (ä¼˜åŒ–ç‰ˆ) ============
def discover_symbols(cfg, ex):
    """30åˆ†é’Ÿç¼“å­˜ï¼Œé¿å…æ¯å‘¨æœŸè°ƒç”¨CoinGecko"""
    global _DISCOVER_CACHE
    now = time.time()
    perf_cfg = cfg.get("performance", {})
    cache_ttl = perf_cfg.get("discover_cache_ttl", 1800)
    
    if _DISCOVER_CACHE["symbols"] and (now - _DISCOVER_CACHE["ts"]) < cache_ttl:
        cache_age_min = (now - _DISCOVER_CACHE["ts"]) / 60
        print(f"[DISCOVER] ğŸ“¦ ä½¿ç”¨ç¼“å­˜ï¼ˆ{cache_age_min:.1f}åˆ†é’Ÿå‰ï¼‰: {len(_DISCOVER_CACHE['symbols'])} ä¸ªäº¤æ˜“å¯¹")
        return _DISCOVER_CACHE["symbols"]
    
    dynamic_cfg = cfg.get("majors", {}).get("dynamic", {})
    static_symbols = cfg.get("majors", {}).get("symbols", [])

    if not dynamic_cfg.get("enable", False):
        return static_symbols if static_symbols else []

    try:
        quote = dynamic_cfg.get("quote", "USDT")
        top_n_volume = dynamic_cfg.get("top_n_volume", 45)
        max_market_cap_rank = dynamic_cfg.get("max_market_cap_rank", 100)
        min_volume_24h = dynamic_cfg.get("min_volume_24h_usdt", 10000000)
        stablecoin_blacklist = {"USDT", "USDC", "BUSD", "TUSD", "DAI", "FDUSD", "USDP", "USDE"}

        print(f"[DISCOVER] å¼€å§‹åŠ¨æ€å‘ç° | äº¤æ˜“é¢å‰{top_n_volume} + å¸‚å€¼å‰{max_market_cap_rank}...")
        tickers = ex.fetch_tickers()
        pairs = []

        for symbol, ticker in tickers.items():
            if ":" not in symbol: continue
            if f"/{quote}:USDT" not in symbol: continue
            base = symbol.split("/")[0].upper()
            if base in stablecoin_blacklist: continue
            volume_usd = ticker.get('quoteVolume', 0)
            if volume_usd and volume_usd >= min_volume_24h:
                pairs.append({'symbol': symbol, 'base': base, 'volume': volume_usd})

        pairs.sort(key=lambda x: x['volume'], reverse=True)
        top_volume_pairs = pairs[:top_n_volume]

        # CoinGeckoè·å–å¸‚å€¼æ•°æ®
        from core.free_fingpt import FreeFinGPT
        coingecko_id_map = FreeFinGPT.SYMBOL_TO_COINGECKO_ID
        try:
            import requests
            cg_api_key = dynamic_cfg.get("coingecko_api_key", "")
            coin_ids = []
            base_to_symbol = {}

            for pair in top_volume_pairs:
                base = pair['base']
                cg_id = coingecko_id_map.get(base)
                if cg_id:
                    coin_ids.append(cg_id)
                    base_to_symbol[cg_id] = pair['symbol']

            if not coin_ids:
                final_symbols = [p['symbol'] for p in top_volume_pairs]
            else:
                url = "https://api.coingecko.com/api/v3/coins/markets"
                params = {"vs_currency": "usd", "ids": ",".join(coin_ids), "order": "market_cap_desc", "per_page": len(coin_ids), "page": 1}
                headers = {}
                if cg_api_key: headers["x-cg-demo-api-key"] = cg_api_key
                
                resp = None
                for retry in range(3):
                    try:
                        resp = requests.get(url, params=params, headers=headers, timeout=20)
                        if resp.status_code == 200: break
                    except Exception: time.sleep(2)

                if resp and resp.status_code == 200:
                    cg_data = resp.json()
                    qualified_symbols = []
                    for coin in cg_data:
                        coin_id = coin.get("id", "")
                        market_cap_rank = coin.get("market_cap_rank", 9999)
                        symbol = base_to_symbol.get(coin_id)
                        if symbol and market_cap_rank and market_cap_rank <= max_market_cap_rank:
                            qualified_symbols.append(symbol)
                    final_symbols = qualified_symbols
                else:
                    final_symbols = static_symbols if static_symbols else _get_fallback_majors(quote)

        except Exception as e:
            final_symbols = static_symbols if static_symbols else _get_fallback_majors(quote)

        all_symbols_raw = list(set(static_symbols + final_symbols))
        seen_bases = set()
        unique_symbols = []
        for symbol in all_symbols_raw:
            base = symbol.split("/")[0].split(":")[0].upper()
            if base not in seen_bases:
                seen_bases.add(base)
                unique_symbols.append(symbol)

        print(f"[DISCOVER] âœ… æœ€ç»ˆé€‰æ‹©: {len(unique_symbols)} ä¸ªäº¤æ˜“å¯¹")
        _DISCOVER_CACHE["symbols"] = unique_symbols
        _DISCOVER_CACHE["ts"] = now
        return unique_symbols

    except Exception as e:
        print(f"[DISCOVER_ERR] {e}")
        return static_symbols if static_symbols else []

# ============ ğŸ”¥ğŸ”¥ğŸ”¥ è½¨é“2ä¸“ç”¨ï¼šå…¨å¸‚åœºå¸ç§å‘ç° ============
def discover_high_vol_symbols(cfg, ex):
    """
    ğŸ”¥ è½¨é“2ä¸“ç”¨ï¼šè·å–å…¨å¸‚åœº100+é«˜æˆäº¤é‡å¸ç§
    ç‹¬ç«‹äºè½¨é“1ï¼Œæ‰«æèŒƒå›´æ›´å¹¿
    """
    global _HIGH_VOL_DISCOVER_CACHE
    now = time.time()
    
    # 5åˆ†é’Ÿç¼“å­˜
    if _HIGH_VOL_DISCOVER_CACHE["symbols"] and (now - _HIGH_VOL_DISCOVER_CACHE["ts"]) < 300:
        cache_age = (now - _HIGH_VOL_DISCOVER_CACHE["ts"]) / 60
        print(f"[HIGH_VOL_DISCOVER] ğŸ“¦ ä½¿ç”¨ç¼“å­˜ï¼ˆ{cache_age:.1f}åˆ†é’Ÿå‰ï¼‰: {len(_HIGH_VOL_DISCOVER_CACHE['symbols'])} ä¸ªå¸ç§")
        return _HIGH_VOL_DISCOVER_CACHE["symbols"]
    
    try:
        hv_cfg = cfg.get("high_volatility_track", {}).get("scan", {})
        min_volume_24h = hv_cfg.get("min_volume_24h", 2000000)  # é»˜è®¤2M
        
        stablecoin_blacklist = {"USDT", "USDC", "BUSD", "TUSD", "DAI", "FDUSD", "USDP", "USDE"}
        
        print(f"[HIGH_VOL_DISCOVER] ğŸ” æ‰«æå…¨å¸‚åœºå¸ç§ (æˆäº¤é‡>{min_volume_24h/1e6:.0f}M)...")
        tickers = ex.fetch_tickers()
        pairs = []
        
        for symbol, ticker in tickers.items():
            if ":" not in symbol: 
                continue
            if "/USDT:USDT" not in symbol: 
                continue
            base = symbol.split("/")[0].upper()
            if base in stablecoin_blacklist: 
                continue
            
            volume_usd = ticker.get('quoteVolume', 0)
            change_24h = ticker.get('percentage', 0) or 0  # 24hæ¶¨è·Œå¹…
            
            if volume_usd and volume_usd >= min_volume_24h:
                pairs.append({
                    'symbol': symbol, 
                    'base': base, 
                    'volume': volume_usd,
                    'change_24h': change_24h
                })
        
        # æŒ‰æˆäº¤é‡æ’åº
        pairs.sort(key=lambda x: x['volume'], reverse=True)
        
        # å–å‰150ä¸ª
        top_pairs = pairs[:150]
        symbols = [p['symbol'] for p in top_pairs]
        
        # ç»Ÿè®¡æ³¢åŠ¨æƒ…å†µ
        high_vol_count = sum(1 for p in top_pairs if abs(p['change_24h']) >= 8)
        print(f"[HIGH_VOL_DISCOVER] âœ… å‘ç° {len(symbols)} ä¸ªå¸ç§ | å…¶ä¸­24hæ³¢åŠ¨â‰¥8%: {high_vol_count}ä¸ª")
        
        _HIGH_VOL_DISCOVER_CACHE["symbols"] = symbols
        _HIGH_VOL_DISCOVER_CACHE["ts"] = now
        return symbols
        
    except Exception as e:
        print(f"[HIGH_VOL_DISCOVER] âŒ é”™è¯¯: {e}")
        return []

def notify_startup(cfg):
    if not cfg.get("runtime", {}).get("start_notify", True): return
    perf_cfg = cfg.get("performance", {})
    msg_lines = [
        "âœ… v7.9.4 å¹³è¡¡ä¼˜åŒ–ç‰ˆå¯åŠ¨",
        f"äº¤æ˜“æ‰€: {cfg['exchange']['name']}",
        f"æ—¶é—´æ¡†æ¶: {cfg['exchange']['timeframe']}", "",
        "ğŸš€ æ€§èƒ½ä¼˜åŒ–:",
        f"  âš¡ Kçº¿å¹¶å‘: {perf_cfg.get('kline_workers', 5)}çº¿ç¨‹",
        f"  ğŸ“Š Kçº¿æ•°é‡: {perf_cfg.get('kline_limit', 800)}æ ¹", "",
        "ğŸ†• ä¿¡å·ç±»å‹ (v7.9.4å¹³è¡¡ç‰ˆ):",
        "  ğŸ”® è¶‹åŠ¿é¢„åˆ¤ (RSI 15-25/75-85 + è“„åŠ¿ç¡®è®¤)",
        "  ğŸ”„ åè½¬ä¿¡å· (RSI â‰¤20/â‰¥80 + è¶‹åŠ¿å‡å¼±)", "",
        "ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–:",
        "  ğŸ¯ 30åˆ†é’Ÿå»é‡",
        "  ğŸ“Š è§‚å¯ŸæœŸå®¹å¿äºŒæ¬¡æ¢åº•",
        "  ğŸ›¡ï¸ è¶‹åŠ¿å‡å¼±ç¡®è®¤é˜²æ¥é£åˆ€"
    ]
    tg_send(cfg, "å¯åŠ¨", msg_lines)

# ============ ğŸš€ ä¼˜åŒ–ç‰ˆè¿è¡Œç­–ç•¥ ============
def run_majors(cfg, ex, cur, btc_status, fingpt, reviewer, collector):
    """ğŸš€ v7.9.4 å¹³è¡¡ç‰ˆï¼šåè½¬ + é¢„åˆ¤"""
    global _FIRST_CYCLE_DONE
    
    tf = cfg["exchange"]["timeframe"]
    perf_cfg = cfg.get("performance", {})
    limit = perf_cfg.get("kline_limit", 800)
    workers = perf_cfg.get("kline_workers", 5)
    
    symbols = discover_symbols(cfg, ex)
    
    # ğŸ¯ æ–¹æ¡ˆ2: ç¬¬ä¸€ä¸ªå‘¨æœŸåªæ³¨å†Œå¸ç§åˆ°FinGPTé¢„åŠ è½½åˆ—è¡¨
    if not _FIRST_CYCLE_DONE:
        print("[FINGPT] ç¬¬ä¸€ä¸ªå‘¨æœŸ:æ³¨å†Œå¸ç§åˆ°é¢„åŠ è½½åˆ—è¡¨...")
        for sym in symbols: fingpt.register_symbol(sym)
        print(f"[FINGPT] ç­‰å¾…30ç§’è®©FinGPTå®Œæˆé¦–æ¬¡æ›´æ–°...")
        time.sleep(30)
        _FIRST_CYCLE_DONE = True
        return
    
    # ğŸš€ğŸš€ğŸš€ å¹¶å‘è·å–æ‰€æœ‰Kçº¿æ•°æ®
    all_symbols = ["BTC/USDT:USDT"] + [s for s in symbols if s != "BTC/USDT:USDT"]
    kline_data = fetch_klines_batch(ex, all_symbols, tf, limit, workers)
    btc_df = kline_data.get("BTC/USDT:USDT")
    
    # ğŸš€ğŸš€ğŸš€ æ‰¹é‡è·å–fundingæ•°æ®
    funding_cache = batch_fetch_funding_rates(ex, symbols)

    for sym in symbols:
        df = kline_data.get(sym)
        if df is None: continue
        
        m = build_enhanced_metrics(df, cfg)
        vol_spike_ratio = m.get("vol_spike_ratio", 1.0)
        
        # 1. è¶‹åŠ¿é¢„åˆ¤ä¿¡å·æ£€æµ‹ (Trend Anticipation)
        correlation_analysis = None
        clean_sym = sym.split(':')[0].upper()
        if clean_sym != "BTC/USDT" and btc_df is not None:
            correlation_analysis = get_cached_correlation(sym, df, btc_df, btc_status, vol_spike_ratio=vol_spike_ratio)
        
        if cfg.get("trend_anticipation", {}).get("enabled", False) and TREND_ANTICIPATION_AVAILABLE:
            try:
                anti_sig = detect_trend_anticipation(cfg, ex, sym, df, btc_status, m, correlation_analysis)
                if anti_sig:
                    dedup = SignalDeduplicator(cfg)
                    should_emit, dedup_reason = dedup.should_emit(sym, "trend_anticipation", anti_sig["score"], anti_sig["bias"])
                    if should_emit:
                        if anti_sig["score"] >= cfg.get("push", {}).get("thresholds", {}).get("majors", 0.50):
                            claude_review_and_push(cfg, cur, anti_sig, reviewer, collector)
                    else:
                        print(f"[DEDUP] {sym} é¢„åˆ¤å»é‡: {dedup_reason}")
            except Exception as e:
                # print(f"  âš ï¸ {sym} è¶‹åŠ¿é¢„åˆ¤å¼‚å¸¸: {e}")
                pass
        
        # 2. ğŸ”¥ [å·²åˆ é™¤] è¶‹åŠ¿è·Ÿéš - v7.9å·²ç§»é™¤ï¼Œå…¶ç‰¹ç‚¹å·²èå…¥è¶‹åŠ¿é¢„åˆ¤

        # 3. åè½¬ä¿¡å·æ£€æµ‹ (Reversal)
        signal = majors_signal_with_obs(cfg, ex, sym, df, btc_status, fingpt, correlation_analysis, funding_cache)
        if not signal: continue
        
        # ä¿¡å·å»é‡
        if TREND_ANTICIPATION_AVAILABLE:
            dedup = SignalDeduplicator(cfg)
            # ğŸ”¥ 30åˆ†é’Ÿå»é‡ (Configè®¾ç½®)
            should_emit, dedup_reason = dedup.should_emit(sym, "reversal", signal["score"], signal["bias"])
            if not should_emit:
                print(f"[DEDUP] ğŸ”„ {sym} åè½¬å»é‡: {dedup_reason}")
                continue
        
        if signal["score"] < cfg.get("push", {}).get("thresholds", {}).get("majors", 0.85):
            print(f"[SKIP] {sym} - è¯„åˆ†{signal['score']:.2f}ä½")
            continue
        
        # BTCè¿‡æ»¤
        if clean_sym != "BTC/USDT":
            gate_cfg = cfg.get("push", {}).get("llm_gate", {})
            reversal_mode = gate_cfg.get("reversal_only", False)
            if not reversal_mode:
                should_skip = False
                skip_reasons = []
                if signal["bias"] == "long" and not btc_status.get("allow_long", True):
                    should_skip, skip_reasons = True, btc_status.get('altcoin_reversal_reasons', [])
                if signal["bias"] == "short" and not btc_status.get("allow_short", True):
                    should_skip, skip_reasons = True, btc_status.get('altcoin_reversal_reasons', [])
                if should_skip:
                    print(f"[BTC_FILTER] è·³è¿‡ {sym} ({', '.join(skip_reasons)})")
                    continue
        
        claude_review_and_push(cfg, cur, signal, reviewer, collector)

# ============ ä¸»å‡½æ•° ============
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--run-loop", action="store_true")
    ap.add_argument("--interval", type=int, default=60)
    ap.add_argument("--observe-only", action="store_true")
    ap.add_argument("--daily-report", action="store_true")
    ap.add_argument("--weekly-report", action="store_true")
    args = ap.parse_args()
    
    cfg = load_cfg()
    if args.observe_only:
        cfg.setdefault("push", {}).update({"observe_only": True})
    
    db = cfg["analytics"]["storage"]["path"]
    ensure_db(db)
    ex = get_exchange(cfg)
    
    if args.daily_report:
        report_daily_enhanced(cfg)
        return
    if args.weekly_report:
        report_weekly_enhanced(cfg, ex)
        return
    
    print("[INIT] åˆå§‹åŒ–ç»„ä»¶...")
    cg_key = cfg.get("coingecko", {}).get("api_key", "")
    if not cg_key: cg_key = os.getenv("COINGECKO_API_KEY", "")
    fingpt = FreeFinGPT(coingecko_api_key=cg_key, config=cfg)
    fingpt.start_background_update()
    
    reviewer = ClaudeReviewer(cfg)
    print("  âœ… AIå®¡æ ¸å™¨ (Claude/DeepSeek)")
    
    collector = None
    if cfg.get("xgboost", {}).get("enabled", True):
        try:
            collector = XGBoostDataCollector(cfg, ex)
            print("  âœ… XGBoostæ”¶é›†å™¨")
        except Exception: pass

    global _AUTO_TRADER, _SIGNAL_WATCHER
    _AUTO_TRADER = None
    if cfg.get("auto_trading", {}).get("enabled", False):
        try:
            _AUTO_TRADER = AutoTrader(cfg.get("auto_trading", {}), db, full_config=cfg)
            print("  âœ… OKXè‡ªåŠ¨äº¤æ˜“å™¨")
        except Exception as e: print(f"  âš ï¸ è‡ªåŠ¨äº¤æ˜“å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

    _SIGNAL_WATCHER = None
    if cfg.get("watch", {}).get("enabled", False):
        try:
            _SIGNAL_WATCHER = SignalWatcher(
                config=cfg.get("watch", {}),
                db_path="data/watch_signals.db",
                exchange=ex,
                claude_api_key=cfg.get("claude", {}).get("api_key", ""),
                deepseek_config=cfg.get("deepseek", {}),
                full_config=cfg
            )
            print("  âœ… ä¿¡å·è§‚å¯Ÿå™¨ (v5.2)")
        except Exception as e: print(f"  âš ï¸ ä¿¡å·è§‚å¯Ÿå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ é«˜æ³¢åŠ¨è½¨é“åˆå§‹åŒ– (Track 2)
    global _HIGH_VOL_TRACK
    _HIGH_VOL_TRACK = None
    if cfg.get("high_volatility_track", {}).get("enabled", False) and HIGH_VOL_TRACK_AVAILABLE:
        try:
            _HIGH_VOL_TRACK = HighVolatilityTrack(
                config=cfg,
                exchange=ex,
                auto_trader=_AUTO_TRADER,
                db_path="data/high_vol_track.db"
            )
            hv_cfg = cfg.get("high_volatility_track", {})
            print("  âœ… é«˜æ³¢åŠ¨è½¨é“ (Track 2)")
            print(f"     â””â”€ æ‰«æ: 24hæ³¢åŠ¨{hv_cfg.get('scan',{}).get('min_change_24h',0.08)*100:.0f}%-{hv_cfg.get('scan',{}).get('max_change_24h',0.40)*100:.0f}%")
            print(f"     â””â”€ è§‚å¯Ÿæ± : {hv_cfg.get('observation_pool',{}).get('capacity',10)}ä¸ª | å°±ç»ªé˜ˆå€¼: {hv_cfg.get('observation_pool',{}).get('readiness_threshold',75)}åˆ†")
            print(f"     â””â”€ èµ„é‡‘å æ¯”: {hv_cfg.get('capital',{}).get('track_pct',0.30)*100:.0f}%")
        except Exception as e:
            print(f"  âš ï¸ é«˜æ³¢åŠ¨è½¨é“åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    notify_startup(cfg)
    
    def one_cycle():
        global _BTC_MARKET_CACHE, _FIRST_CYCLE_DONE, _HIGH_VOL_TRACK
        conn = sqlite3.connect(db, timeout=30)
        conn.execute("PRAGMA journal_mode=WAL")
        cur = conn.cursor()
        try:
            print(f"\n{'='*60}\n[CYCLE] {dt.datetime.now().strftime('%H:%M:%S')}\n{'='*60}")
            if _FIRST_CYCLE_DONE: fingpt.clear_old_registrations()
            
            now = time.time()
            if now - _BTC_MARKET_CACHE.get("ts", 0) > 60:
                btc_status = check_btc_market_advanced(ex, cfg)
                _BTC_MARKET_CACHE["data"] = btc_status
                _BTC_MARKET_CACHE["ts"] = now
                print_btc_status_enhanced(btc_status)
            else:
                btc_status = _BTC_MARKET_CACHE["data"]
            
            # ğŸ”¹ è½¨é“1ï¼šå¸¸è§„ä¿¡å·å¤„ç†
            run_majors(cfg, ex, cur, btc_status, fingpt, reviewer, collector)
            
            # ğŸ”¸ğŸ”¸ğŸ”¸ è½¨é“2ï¼šé«˜æ³¢åŠ¨ä¿¡å·å¤„ç†ï¼ˆç‹¬ç«‹æ‰«æå…¨å¸‚åœºï¼‰
            if _HIGH_VOL_TRACK and _HIGH_VOL_TRACK.enabled:
                try:
                    # ğŸ”¥ ç‹¬ç«‹è·å–å…¨å¸‚åœºå¸ç§ï¼ˆä¸å¤ç”¨è½¨é“1çš„symbolsï¼‰
                    hv_symbols = discover_high_vol_symbols(cfg, ex)
                    
                    if hv_symbols:
                        tf = cfg.get("exchange", {}).get("timeframe", "1m")
                        limit = cfg.get("exchange", {}).get("limit", 2000)
                        workers = cfg.get("performance", {}).get("fetch_workers", 8)
                        
                        # ç¡®ä¿åŒ…å«BTC
                        all_symbols = ["BTC/USDT:USDT"] + [s for s in hv_symbols if s != "BTC/USDT:USDT"]
                        
                        print(f"[HIGH_VOL] ğŸ“Š è·å– {len(all_symbols)} ä¸ªå¸ç§Kçº¿...")
                        kline_data = fetch_klines_batch(ex, all_symbols, tf, limit, workers)
                        btc_df = kline_data.get("BTC/USDT:USDT")
                        
                        _HIGH_VOL_TRACK.run_once(
                            all_klines=kline_data,
                            btc_df=btc_df,
                            btc_status=btc_status
                        )
                        
                        # æ‰“å°é«˜æ³¢åŠ¨è½¨é“çŠ¶æ€
                        hv_status = _HIGH_VOL_TRACK.get_status()
                        if hv_status['observation_pool'] > 0 or hv_status['active_orders'] > 0 or hv_status['active_positions'] > 0:
                            print(f"\nğŸ”¸ è½¨é“2çŠ¶æ€: è§‚å¯Ÿ{hv_status['observation_pool']}/{hv_status['pool_capacity']} | "
                                  f"æŒ‚å•{hv_status['active_orders']}/{hv_status['max_orders']} | "
                                  f"æŒä»“{hv_status['active_positions']}")
                        
                except Exception as e:
                    print(f"[HIGH_VOL] âŒ è½¨é“2å¼‚å¸¸: {e}")
                    import traceback
                    traceback.print_exc()
            
            if _SIGNAL_WATCHER: _SIGNAL_WATCHER.monitor()
            if _AUTO_TRADER: _AUTO_TRADER.run_once()
            if collector: 
                try: collector.check_pending_signals() 
                except: pass
                
            conn.commit()
        finally:
            conn.close()
    
    if args.run_loop:
        print("[MAIN] è¿›å…¥ä¸»å¾ªç¯...")
        print(f"é—´éš”: {args.interval}ç§’\n")
        last_daily_check = None
        last_weekly_check = None
        last_tracking_check = None
        cycle_count = 0
        try:
            while True:
                now = dt.datetime.now()
                cycle_count += 1
                if last_tracking_check is None or (now - last_tracking_check).total_seconds() > 14400:
                    update_signal_tracking(cfg, db)
                    last_tracking_check = now
                
                if should_run_daily_report(cfg):
                    if last_daily_check is None or (now - last_daily_check).total_seconds() > 3600:
                        report_daily_enhanced(cfg)
                        last_daily_check = now
                        
                if should_run_weekly_report(cfg):
                    if last_weekly_check is None or (now - last_weekly_check).total_seconds() > 3600:
                        report_weekly_enhanced(cfg, ex)
                        last_weekly_check = now
                        
                if cycle_count % 10 == 0: cleanup_funding_oi_cache()
                
                one_cycle()
                time.sleep(max(10, int(args.interval)))
        except KeyboardInterrupt:
            print("\n[MAIN] æ­£åœ¨åœæ­¢...")
            fingpt.stop()
            tg_send(cfg, "ç³»ç»Ÿ", ["å·²åœæ­¢"])
            print("[MAIN] é€€å‡º")
    else:
        one_cycle()

if __name__ == "__main__":
    main()