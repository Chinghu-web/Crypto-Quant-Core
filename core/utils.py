# core/utils.py - v2.0 å‡çº§ç‰ˆ (æ–°å¢CVD + Efficiency Ratio + HurstæŒ‡æ ‡)
# -*- coding: utf-8 -*-
"""
ğŸ”¥ v2.0 æ›´æ–°:
1. æ–°å¢ CVD (ç´¯ç§¯æˆäº¤é‡å·®) - è¯†åˆ«çœŸå‡çªç ´
2. æ–°å¢ Efficiency Ratio - è¶‹åŠ¿çº¯åº¦
3. æ–°å¢ Hurst Exponent - è¶‹åŠ¿æŒç»­æ€§
4. æ–°å¢ çœŸå‡çªç ´ç»¼åˆæ£€æµ‹å™¨
"""

import os, json, time, math, subprocess, hashlib
from typing import List, Dict, Any, Optional, Tuple
import pandas as pd
import numpy as np
from datetime import datetime, timezone, timedelta

# ========== æŠ€æœ¯æŒ‡æ ‡ ==========
def ema(series: pd.Series, period: int) -> pd.Series:
    return series.ewm(span=int(period), adjust=False).mean()

def atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    h, l, c = df["high"], df["low"], df["close"]
    tr = pd.concat([(h - l).abs(),
                    (h - c.shift(1)).abs(),
                    (l - c.shift(1)).abs()], axis=1).max(axis=1)
    out = tr.rolling(int(period)).mean()
    out = out.bfill()
    return out

def obv(df: pd.DataFrame) -> pd.Series:
    close = df["close"].values
    vol = df["volume"].values
    obv_vals = [0.0]
    for i in range(1, len(close)):
        if close[i] > close[i-1]:
            obv_vals.append(obv_vals[-1] + vol[i])
        elif close[i] < close[i-1]:
            obv_vals.append(obv_vals[-1] - vol[i])
        else:
            obv_vals.append(obv_vals[-1])
    return pd.Series(obv_vals, index=df.index)

def realized_vol(returns: pd.Series) -> float:
    if returns is None or len(returns) == 0:
        return 0.0
    return float(np.sqrt(np.sum(np.square(returns))))

def wick_scores(df: pd.DataFrame) -> Tuple[float, float]:
    body = (df["close"] - df["open"]).abs() + 1e-12
    up_wick = (df["high"] - df[["close","open"]].max(axis=1)) / body
    down_wick = (df[["close","open"]].min(axis=1) - df["low"]) / body
    return float(up_wick.tail(50).clip(0,10).mean()), float(down_wick.tail(50).clip(0,10).mean())


# ========== ğŸ†• CVD (ç´¯ç§¯æˆäº¤é‡å·®) ==========
def calculate_cvd(df: pd.DataFrame) -> pd.Series:
    """
    è®¡ç®—CVD (Cumulative Volume Delta) - ç´¯ç§¯æˆäº¤é‡å·®
    
    åŸç†: ä»·æ ¼ä¸Šæ¶¨æ—¶è§†ä¸ºä¸»ä¹°ï¼Œä¸‹è·Œæ—¶è§†ä¸ºä¸»å–
    - CVDä¸Šå‡ = ä¹°ç›˜åŠ›é‡å ä¼˜
    - CVDä¸‹é™ = å–ç›˜åŠ›é‡å ä¼˜
    
    ç”¨é€”: é…åˆä»·æ ¼è¯†åˆ«çœŸå‡çªç ´
    - ä»·æ ¼ä¸Šæ¶¨ + CVDä¸Šæ¶¨ = çœŸçªç ´ (ä¹°ç›˜æ¨åŠ¨)
    - ä»·æ ¼ä¸Šæ¶¨ + CVDä¸‹è·Œ = å‡çªç ´ (å–ç›˜å‡ºè´§)
    
    Returns:
        CVDåºåˆ—
    """
    # æ–¹å‘åˆ¤æ–­: close > open ä¸ºä¹°ç›˜ä¸»å¯¼ï¼Œåä¹‹ä¸ºå–ç›˜ä¸»å¯¼
    direction = np.sign(df['close'].values - df['open'].values)
    # æˆäº¤é‡ä¹˜ä»¥æ–¹å‘
    volume_delta = direction * df['volume'].values
    # ç´¯ç§¯æ±‚å’Œ
    cvd = np.cumsum(volume_delta)
    return pd.Series(cvd, index=df.index)


def cvd_divergence(df: pd.DataFrame, lookback: int = 20) -> Dict[str, Any]:
    """
    æ£€æµ‹CVDèƒŒç¦» - æ ¸å¿ƒçš„çœŸå‡çªç ´æ£€æµ‹å™¨
    
    Args:
        df: Kçº¿æ•°æ®
        lookback: å›çœ‹å‘¨æœŸ
        
    Returns:
        {
            "cvd_delta": CVDå˜åŒ–ç™¾åˆ†æ¯”,
            "price_delta": ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”,
            "divergence": "bullish"/"bearish"/"none",
            "divergence_strength": èƒŒç¦»å¼ºåº¦ 0-100,
            "is_fake_breakout": æ˜¯å¦å‡çªç ´,
            "signal_quality": ä¿¡å·è´¨é‡è¯„åˆ†
        }
    """
    if len(df) < lookback + 5:
        return {
            "cvd_delta": 0, "price_delta": 0,
            "divergence": "none", "divergence_strength": 0,
            "is_fake_breakout": False, "signal_quality": 50
        }
    
    cvd = calculate_cvd(df)
    
    # è®¡ç®—è¿‘æœŸå˜åŒ–
    cvd_now = cvd.iloc[-1]
    cvd_past = cvd.iloc[-lookback]
    price_now = df['close'].iloc[-1]
    price_past = df['close'].iloc[-lookback]
    
    # é˜²æ­¢é™¤é›¶
    cvd_range = max(abs(cvd.iloc[-lookback:].max() - cvd.iloc[-lookback:].min()), 1)
    price_past_safe = max(price_past, 1e-10)
    
    cvd_delta = (cvd_now - cvd_past) / cvd_range * 100  # å½’ä¸€åŒ–
    price_delta = (price_now - price_past) / price_past_safe * 100
    
    # åˆ¤æ–­èƒŒç¦»ç±»å‹
    divergence = "none"
    divergence_strength = 0
    is_fake_breakout = False
    
    # ä»·æ ¼ä¸Šæ¶¨ä½†CVDä¸‹è·Œ = çœ‹è·ŒèƒŒç¦» (å‡çªç ´é£é™©)
    if price_delta > 1 and cvd_delta < -5:
        divergence = "bearish"
        divergence_strength = min(100, abs(cvd_delta) * 2)
        if price_delta > 3 and cvd_delta < -10:
            is_fake_breakout = True
    
    # ä»·æ ¼ä¸‹è·Œä½†CVDä¸Šæ¶¨ = çœ‹æ¶¨èƒŒç¦» (å‡è·Œé£é™©)
    elif price_delta < -1 and cvd_delta > 5:
        divergence = "bullish"
        divergence_strength = min(100, abs(cvd_delta) * 2)
        if price_delta < -3 and cvd_delta > 10:
            is_fake_breakout = True
    
    # è®¡ç®—ä¿¡å·è´¨é‡ (CVDå’Œä»·æ ¼åŒå‘æ—¶è´¨é‡é«˜)
    if price_delta * cvd_delta > 0:  # åŒå‘
        signal_quality = min(100, 50 + abs(cvd_delta) * 2)
    else:  # èƒŒç¦»
        signal_quality = max(0, 50 - divergence_strength * 0.5)
    
    return {
        "cvd_delta": round(cvd_delta, 2),
        "price_delta": round(price_delta, 2),
        "divergence": divergence,
        "divergence_strength": round(divergence_strength, 1),
        "is_fake_breakout": is_fake_breakout,
        "signal_quality": round(signal_quality, 1)
    }


# ========== ğŸ†• Efficiency Ratio (æ•ˆç‡æ¯”) ==========
def efficiency_ratio(df: pd.DataFrame, period: int = 20) -> float:
    """
    è®¡ç®—Efficiency Ratio (æ•ˆç‡æ¯”/ER)
    
    å…¬å¼: ER = å‡€ç§»åŠ¨è·ç¦» / æ€»ç§»åŠ¨è·ç¦»
    
    è§£é‡Š:
    - ERæ¥è¿‘1: ä»·æ ¼è¶‹åŠ¿çº¯å‡€ï¼Œç›´çº¿ç§»åŠ¨ï¼Œå™ªéŸ³å°
    - ERæ¥è¿‘0: ä»·æ ¼éœ‡è¡å‰§çƒˆï¼Œæ¥å›æ³¢åŠ¨ï¼Œå™ªéŸ³å¤§
    
    ç”¨é€”:
    - ER > 0.6: è¶‹åŠ¿æ˜ç¡®ï¼Œé€‚åˆè¶‹åŠ¿è·Ÿè¸ª
    - ER < 0.3: éœ‡è¡å¸‚ï¼Œä¸é€‚åˆè¶‹åŠ¿ç­–ç•¥
    - ER 0.3-0.6: è¶‹åŠ¿å½¢æˆä¸­
    
    Args:
        df: Kçº¿æ•°æ®
        period: è®¡ç®—å‘¨æœŸ
        
    Returns:
        æ•ˆç‡æ¯” (0-1)
    """
    if len(df) < period + 1:
        return 0.5
    
    close = df['close'].tail(period + 1)
    
    # å‡€ç§»åŠ¨è·ç¦» (èµ·ç‚¹åˆ°ç»ˆç‚¹çš„ç›´çº¿è·ç¦»)
    net_move = abs(close.iloc[-1] - close.iloc[0])
    
    # æ€»ç§»åŠ¨è·ç¦» (æ¯æ ¹Kçº¿å˜åŒ–çš„ç»å¯¹å€¼ä¹‹å’Œ)
    total_move = close.diff().abs().sum()
    
    if total_move == 0:
        return 0.5
    
    er = net_move / total_move
    return round(float(er), 4)


def efficiency_ratio_trend(df: pd.DataFrame, period: int = 20) -> Dict[str, Any]:
    """
    æ•ˆç‡æ¯”è¶‹åŠ¿åˆ†æ
    
    Returns:
        {
            "er": å½“å‰æ•ˆç‡æ¯”,
            "er_5": 5å‘¨æœŸå‰æ•ˆç‡æ¯”,
            "trend": "trending"/"ranging"/"forming",
            "trend_quality": è¶‹åŠ¿è´¨é‡è¯„åˆ† 0-100,
            "recommendation": å»ºè®®
        }
    """
    if len(df) < period + 10:
        return {
            "er": 0.5, "er_5": 0.5,
            "trend": "unknown", "trend_quality": 50,
            "recommendation": "æ•°æ®ä¸è¶³"
        }
    
    er_now = efficiency_ratio(df, period)
    er_5 = efficiency_ratio(df.iloc[:-5], period)
    
    # åˆ¤æ–­è¶‹åŠ¿çŠ¶æ€
    if er_now >= 0.6:
        trend = "trending"
        trend_quality = min(100, er_now * 100 + 20)
        recommendation = "è¶‹åŠ¿æ˜ç¡®ï¼Œå¯ä»¥è·Ÿéš"
    elif er_now <= 0.3:
        trend = "ranging"
        trend_quality = max(0, er_now * 100)
        recommendation = "éœ‡è¡å¸‚ï¼Œè°¨æ…æ“ä½œ"
    else:
        trend = "forming"
        trend_quality = er_now * 100
        if er_now > er_5:
            recommendation = "è¶‹åŠ¿æ­£åœ¨å½¢æˆï¼Œç­‰å¾…ç¡®è®¤"
        else:
            recommendation = "è¶‹åŠ¿å‡å¼±ï¼Œæ³¨æ„é£é™©"
    
    return {
        "er": er_now,
        "er_5": er_5,
        "trend": trend,
        "trend_quality": round(trend_quality, 1),
        "recommendation": recommendation
    }


# ========== ğŸ†• Hurst Exponent (èµ«æ–¯ç‰¹æŒ‡æ•°) ==========
def hurst_exponent(series: pd.Series, max_lag: int = 20) -> float:
    """
    è®¡ç®—Hurst Exponent (èµ«æ–¯ç‰¹æŒ‡æ•°)
    
    ä½¿ç”¨R/S (Rescaled Range) åˆ†ææ³•
    
    è§£é‡Š:
    - H > 0.5: è¶‹åŠ¿æŒç»­æ€§ (è¶‹åŠ¿å€¾å‘äºç»§ç»­)
    - H = 0.5: éšæœºæ¸¸èµ° (æ— æ³•é¢„æµ‹)
    - H < 0.5: å‡å€¼å›å½’ (ä»·æ ¼å€¾å‘äºåè½¬)
    
    ç”¨é€”:
    - H > 0.55: é€‚åˆè¶‹åŠ¿è·Ÿè¸ªç­–ç•¥
    - H < 0.45: é€‚åˆå‡å€¼å›å½’ç­–ç•¥
    - H â‰ˆ 0.5: å¸‚åœºéšæœºï¼Œç­–ç•¥æ•ˆæœä¸ä½³
    
    Args:
        series: ä»·æ ¼åºåˆ—
        max_lag: æœ€å¤§æ»åæœŸ
        
    Returns:
        HurstæŒ‡æ•° (0-1)
    """
    if len(series) < max_lag * 2:
        return 0.5
    
    series = series.dropna()
    if len(series) < max_lag * 2:
        return 0.5
    
    lags = range(2, min(max_lag, len(series) // 2))
    
    # è®¡ç®—æ¯ä¸ªæ»åæœŸçš„æ ‡å‡†å·®
    tau = []
    for lag in lags:
        # è®¡ç®—æ»åå·®åˆ†çš„æ ‡å‡†å·®
        diff = series.values[lag:] - series.values[:-lag]
        if len(diff) > 0:
            tau.append(np.std(diff))
        else:
            tau.append(1e-10)
    
    if len(tau) < 3:
        return 0.5
    
    # å¯¹æ•°å›å½’æ±‚æ–œç‡
    try:
        log_lags = np.log(list(lags))
        log_tau = np.log(np.array(tau) + 1e-10)
        
        # çº¿æ€§å›å½’
        slope, _ = np.polyfit(log_lags, log_tau, 1)
        
        # HurstæŒ‡æ•° = æ–œç‡
        hurst = slope
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        hurst = max(0.0, min(1.0, hurst))
        
        return round(float(hurst), 4)
    except:
        return 0.5


def hurst_analysis(df: pd.DataFrame, period: int = 60) -> Dict[str, Any]:
    """
    HurstæŒ‡æ•°ç»¼åˆåˆ†æ
    
    Returns:
        {
            "hurst": å½“å‰HurstæŒ‡æ•°,
            "regime": "trending"/"mean_reverting"/"random",
            "persistence": æŒç»­æ€§è¯„åˆ† 0-100,
            "strategy_fit": é€‚åˆçš„ç­–ç•¥ç±»å‹,
            "recommendation": å»ºè®®
        }
    """
    if len(df) < period:
        return {
            "hurst": 0.5,
            "regime": "unknown",
            "persistence": 50,
            "strategy_fit": "unknown",
            "recommendation": "æ•°æ®ä¸è¶³"
        }
    
    close = df['close'].tail(period)
    h = hurst_exponent(close, max_lag=min(20, period // 3))
    
    # åˆ¤æ–­å¸‚åœºçŠ¶æ€
    if h > 0.55:
        regime = "trending"
        persistence = min(100, (h - 0.5) * 200 + 50)
        strategy_fit = "è¶‹åŠ¿è·Ÿè¸ª"
        recommendation = "è¶‹åŠ¿æŒç»­æ€§å¼ºï¼Œé€‚åˆé¡ºåŠ¿äº¤æ˜“"
    elif h < 0.45:
        regime = "mean_reverting"
        persistence = max(0, (0.5 - h) * 200)
        strategy_fit = "å‡å€¼å›å½’"
        recommendation = "ä»·æ ¼å€¾å‘å›å½’ï¼Œé€‚åˆé€†åŠ¿äº¤æ˜“"
    else:
        regime = "random"
        persistence = 50
        strategy_fit = "è§‚æœ›"
        recommendation = "å¸‚åœºéšæœºæ€§å¼ºï¼Œå»ºè®®è§‚æœ›"
    
    return {
        "hurst": h,
        "regime": regime,
        "persistence": round(persistence, 1),
        "strategy_fit": strategy_fit,
        "recommendation": recommendation
    }


# ========== ğŸ†• ç»¼åˆçªç ´è´¨é‡è¯„ä¼° ==========
def breakout_quality_score(df: pd.DataFrame, lookback: int = 20) -> Dict[str, Any]:
    """
    ç»¼åˆçªç ´è´¨é‡è¯„ä¼° - æ•´åˆCVDã€ERã€Hurstä¸‰ä¸ªæŒ‡æ ‡
    
    è¿™æ˜¯ç”¨äºé«˜æ³¢åŠ¨è½¨é“AIå®¡æ ¸çš„æ ¸å¿ƒå‡½æ•°
    
    Args:
        df: Kçº¿æ•°æ®
        lookback: å›çœ‹å‘¨æœŸ
        
    Returns:
        {
            "cvd_analysis": CVDåˆ†æç»“æœ,
            "er_analysis": æ•ˆç‡æ¯”åˆ†æç»“æœ,
            "hurst_analysis": Hurståˆ†æç»“æœ,
            "overall_score": ç»¼åˆè¯„åˆ† 0-100,
            "is_quality_signal": æ˜¯å¦ä¼˜è´¨ä¿¡å·,
            "risk_level": "low"/"medium"/"high",
            "recommendation": äº¤æ˜“å»ºè®®
        }
    """
    # è·å–ä¸‰ä¸ªæŒ‡æ ‡åˆ†æ
    cvd_result = cvd_divergence(df, lookback)
    er_result = efficiency_ratio_trend(df, lookback)
    hurst_result = hurst_analysis(df, lookback * 3)
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    # CVDæƒé‡40% (å‡çªç ´æ£€æµ‹æœ€é‡è¦)
    cvd_score = cvd_result["signal_quality"]
    if cvd_result["is_fake_breakout"]:
        cvd_score = max(0, cvd_score - 30)  # å‡çªç ´ä¸¥é‡æ‰£åˆ†
    
    # ERæƒé‡30% (è¶‹åŠ¿çº¯åº¦)
    er_score = er_result["trend_quality"]
    
    # Hurstæƒé‡30% (è¶‹åŠ¿æŒç»­æ€§)
    hurst_score = hurst_result["persistence"]
    
    overall_score = cvd_score * 0.4 + er_score * 0.3 + hurst_score * 0.3
    
    # åˆ¤æ–­é£é™©ç­‰çº§
    if cvd_result["is_fake_breakout"]:
        risk_level = "high"
    elif overall_score >= 70:
        risk_level = "low"
    elif overall_score >= 50:
        risk_level = "medium"
    else:
        risk_level = "high"
    
    # ç»¼åˆå»ºè®®
    is_quality_signal = overall_score >= 60 and not cvd_result["is_fake_breakout"]
    
    if cvd_result["is_fake_breakout"]:
        recommendation = f"âš ï¸ æ£€æµ‹åˆ°å‡çªç ´ä¿¡å·! CVDèƒŒç¦»å¼ºåº¦:{cvd_result['divergence_strength']:.0f}"
    elif is_quality_signal:
        recommendation = f"âœ… ä¿¡å·è´¨é‡è‰¯å¥½ (CVD:{cvd_score:.0f} ER:{er_score:.0f} H:{hurst_score:.0f})"
    else:
        weak_points = []
        if cvd_score < 50:
            weak_points.append("CVDèƒŒç¦»")
        if er_score < 50:
            weak_points.append("è¶‹åŠ¿ä¸çº¯")
        if hurst_score < 50:
            weak_points.append("æŒç»­æ€§å·®")
        recommendation = f"âš ï¸ ä¿¡å·è´¨é‡ä¸€èˆ¬ï¼Œé£é™©ç‚¹: {', '.join(weak_points)}"
    
    return {
        "cvd_analysis": cvd_result,
        "er_analysis": er_result,
        "hurst_analysis": hurst_result,
        "overall_score": round(overall_score, 1),
        "is_quality_signal": is_quality_signal,
        "risk_level": risk_level,
        "recommendation": recommendation
    }


# ========== ğŸ†• RSI (ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡) ==========
def rsi(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """
    è®¡ç®—RSIæŒ‡æ ‡ (Relative Strength Index)
    ç”¨äºåˆ¤æ–­è¶…ä¹°è¶…å–:
    - RSI > 70: è¶…ä¹°åŒºåŸŸ
    - RSI > 80: æåº¦è¶…ä¹°
    - RSI < 30: è¶…å–åŒºåŸŸ
    - RSI < 20: æåº¦è¶…å–
    """
    close = df['close']
    delta = close.diff()
    
    # åˆ†ç¦»æ¶¨è·Œ
    gain = delta.where(delta > 0, 0.0)
    loss = -delta.where(delta < 0, 0.0)
    
    # è®¡ç®—å¹³å‡æ¶¨è·Œå¹…
    avg_gain = gain.rolling(window=period, min_periods=1).mean()
    avg_loss = loss.rolling(window=period, min_periods=1).mean()
    
    # é¿å…é™¤ä»¥0
    avg_loss = avg_loss.replace(0, 1e-10)
    
    # è®¡ç®—RSå’ŒRSI
    rs = avg_gain / avg_loss
    rsi_val = 100 - (100 / (1 + rs))
    
    # å¡«å……NaNä¸º50(ä¸­æ€§)
    rsi_val = rsi_val.fillna(50)
    
    return rsi_val


# ========== ğŸ†• MACD (æŒ‡æ•°å¹³æ»‘å¼‚åŒç§»åŠ¨å¹³å‡çº¿) ==========
def macd(df: pd.DataFrame, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series, pd.Series]:
    """
    è®¡ç®—MACDæŒ‡æ ‡
    è¿”å›: (MACDçº¿, ä¿¡å·çº¿, æŸ±çŠ¶å›¾)
    
    ç”¨äºåˆ¤æ–­è¶‹åŠ¿å’ŒåŠ¨é‡:
    - MACD > Signal: çœ‹æ¶¨
    - MACD < Signal: çœ‹è·Œ
    - æŸ±çŠ¶å›¾ > 0: å¤šå¤´åŠ›é‡å¢å¼º
    - æŸ±çŠ¶å›¾ < 0: ç©ºå¤´åŠ›é‡å¢å¼º
    """
    close = df['close']
    
    # è®¡ç®—å¿«æ…¢EMA
    ema_fast = close.ewm(span=fast, adjust=False).mean()
    ema_slow = close.ewm(span=slow, adjust=False).mean()
    
    # MACDçº¿ = å¿«çº¿ - æ…¢çº¿
    macd_line = ema_fast - ema_slow
    
    # ä¿¡å·çº¿ = MACDçº¿çš„EMA
    signal_line = macd_line.ewm(span=signal, adjust=False).mean()
    
    # æŸ±çŠ¶å›¾ = MACDçº¿ - ä¿¡å·çº¿
    histogram = macd_line - signal_line
    
    return macd_line, signal_line, histogram


# ========== ğŸ†• ADX (å¹³å‡è¶‹å‘æŒ‡æ•°) ==========
def adx(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """
    è®¡ç®—å¹³å‡è¶‹å‘æŒ‡æ•° ADX (Average Directional Index)
    ç”¨äºåˆ¤æ–­è¶‹åŠ¿å¼ºåº¦:
    - ADX < 20: éœ‡è¡å¸‚/æ— è¶‹åŠ¿
    - ADX 20-25: è¶‹åŠ¿å½¢æˆä¸­
    - ADX 25-40: æ˜ç¡®è¶‹åŠ¿
    - ADX > 40: å¼ºè¶‹åŠ¿
    """
    high, low, close = df['high'], df['low'], df['close']
    
    # è®¡ç®—True Range
    tr1 = high - low
    tr2 = (high - close.shift()).abs()
    tr3 = (low - close.shift()).abs()
    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    
    # è®¡ç®—æ–¹å‘ç§»åŠ¨ +DM å’Œ -DM
    plus_dm = high.diff()
    minus_dm = -low.diff()
    
    # åªä¿ç•™æ­£å€¼
    plus_dm = plus_dm.where(plus_dm > 0, 0)
    minus_dm = minus_dm.where(minus_dm > 0, 0)
    
    # è¿‡æ»¤:åªæœ‰å½“+DM > -DMæ—¶æ‰è®¡å…¥+DM,åä¹‹äº¦ç„¶
    plus_dm = plus_dm.where(plus_dm > minus_dm, 0)
    minus_dm = minus_dm.where(minus_dm > plus_dm, 0)
    
    # è®¡ç®—ATR (æ·»åŠ å°å€¼é¿å…é™¤0)
    atr_val = tr.rolling(period).mean()
    atr_val = atr_val.replace(0, 1e-10)
    
    # è®¡ç®—+DIå’Œ-DI
    plus_di = 100 * (plus_dm.rolling(period).mean() / atr_val)
    minus_di = 100 * (minus_dm.rolling(period).mean() / atr_val)
    
    # è®¡ç®—DX (Directional Index) - æ·»åŠ å°å€¼é¿å…é™¤0
    di_sum = plus_di + minus_di
    di_sum = di_sum.replace(0, 1e-10)
    dx = 100 * ((plus_di - minus_di).abs() / di_sum)
    dx = dx.fillna(0)
    
    # ADXæ˜¯DXçš„ç§»åŠ¨å¹³å‡
    adx_val = dx.rolling(period).mean()
    
    # ç¡®ä¿è¿”å›å€¼æœ‰æ•ˆ (å¡«å……NaNä¸º0)
    adx_val = adx_val.fillna(0)
    
    return adx_val


# ========== ğŸ†• å¸ƒæ—å¸¦å®½åº¦ ==========
def bollinger_bandwidth(df: pd.DataFrame, period: int = 20, std_dev: float = 2.0) -> pd.Series:
    """
    è®¡ç®—å¸ƒæ—å¸¦å®½åº¦ (Bollinger Bandwidth)
    ç”¨äºåˆ¤æ–­æ³¢åŠ¨ç‡çŠ¶æ€:
    - å®½åº¦æ”¶ç¼© (< 0.02): ç›˜æ•´æœŸ,å¯èƒ½å³å°†çªç ´
    - å®½åº¦æ­£å¸¸ (0.02-0.05): æ­£å¸¸æ³¢åŠ¨
    - å®½åº¦æ‰©å¼  (> 0.05): é«˜æ³¢åŠ¨,è¶‹åŠ¿è¿›è¡Œä¸­
    
    è¿”å›: å½’ä¸€åŒ–å®½åº¦ (ä¸Šè½¨-ä¸‹è½¨)/ä¸­è½¨
    """
    close = df['close']
    sma = close.rolling(period).mean()
    std = close.rolling(period).std()
    
    upper = sma + (std_dev * std)
    lower = sma - (std_dev * std)
    
    # å½’ä¸€åŒ–å®½åº¦ = (ä¸Šè½¨-ä¸‹è½¨) / ä¸­è½¨
    # æ·»åŠ å°å€¼é¿å…é™¤0
    sma_safe = sma.replace(0, 1e-10)
    bandwidth = (upper - lower) / sma_safe
    
    # å¡«å……NaN
    bandwidth = bandwidth.fillna(0.03)
    
    return bandwidth


# ========== ğŸ†• åˆ†å½¢ç»´æ•° FDI (Fractal Dimension Index) ==========
def fractal_dimension(df: pd.DataFrame, period: int = 30) -> float:
    """
    è®¡ç®—åˆ†å½¢ç»´æ•° FDI (Fractal Dimension Index)
    
    ä½¿ç”¨Higuchiæ–¹æ³•è®¡ç®—ä»·æ ¼æ›²çº¿çš„"å¹³æ»‘åº¦"
    
    è§£é‡Š:
    - FDI â‰ˆ 1.0: ä»·æ ¼åƒç›´çº¿ç§»åŠ¨ï¼ˆå¼ºè¶‹åŠ¿ï¼Œç¡®å®šæ€§é«˜ï¼‰
    - FDI â‰ˆ 1.5: ä»·æ ¼åƒå¸ƒæœ—è¿åŠ¨ï¼ˆéšæœºéœ‡è¡ï¼Œæ— è¶‹åŠ¿ï¼‰
    
    ç”¨é€”:
    - FDI < 1.3: è¶‹åŠ¿æ¸…æ™°ï¼Œå¯ä»¥è·Ÿéš
    - FDI > 1.4: å……æ»¡å™ªéŸ³ï¼Œä¸é€‚åˆè¶‹åŠ¿ç­–ç•¥
    
    Args:
        df: Kçº¿æ•°æ®
        period: è®¡ç®—å‘¨æœŸ
        
    Returns:
        åˆ†å½¢ç»´æ•° (1.0-1.5)
    """
    if len(df) < period:
        return 1.35  # é»˜è®¤ä¸­æ€§å€¼
    
    try:
        prices = df['close'].tail(period).values
        n = len(prices)
        
        # Higuchiæ–¹æ³•
        k_max = min(10, n // 4)
        lk = []
        
        for k in range(1, k_max + 1):
            lm_sum = 0
            for m in range(1, k + 1):
                # æ„å»ºå­åºåˆ—
                indices = np.arange(m - 1, n, k)
                if len(indices) < 2:
                    continue
                sub_series = prices[indices]
                
                # è®¡ç®—è·¯å¾„é•¿åº¦
                length = np.sum(np.abs(np.diff(sub_series)))
                norm_factor = (n - 1) / (k * ((n - m) // k) * k)
                lm_sum += length * norm_factor
            
            if lm_sum > 0:
                lk.append(lm_sum / k)
        
        if len(lk) < 3:
            return 1.35
        
        # å¯¹æ•°å›å½’æ±‚æ–œç‡
        x = np.log(np.arange(1, len(lk) + 1))
        y = np.log(np.array(lk) + 1e-10)
        
        slope, _ = np.polyfit(x, y, 1)
        
        # FDI = 2 - slope (ç†è®ºä¸Š)
        fdi = 2 + slope  # slopeé€šå¸¸ä¸ºè´Ÿ
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´
        fdi = max(1.0, min(1.5, fdi))
        
        return round(float(fdi), 4)
    except:
        return 1.35


def fdi_analysis(df: pd.DataFrame, period: int = 30) -> Dict[str, Any]:
    """
    FDIç»¼åˆåˆ†æ
    
    Returns:
        {
            "fdi": å½“å‰FDIå€¼,
            "regime": "trending"/"noisy"/"neutral",
            "trend_quality": è¶‹åŠ¿è´¨é‡ 0-100,
            "recommendation": å»ºè®®
        }
    """
    fdi = fractal_dimension(df, period)
    
    if fdi < 1.25:
        regime = "trending"
        trend_quality = min(100, (1.5 - fdi) * 200)
        recommendation = "è¶‹åŠ¿éå¸¸æ¸…æ™°ï¼Œé€‚åˆè¶‹åŠ¿è·Ÿè¸ª"
    elif fdi < 1.35:
        regime = "neutral"
        trend_quality = 50
        recommendation = "è¶‹åŠ¿ä¸€èˆ¬ï¼Œéœ€è¦å…¶ä»–æŒ‡æ ‡ç¡®è®¤"
    else:
        regime = "noisy"
        trend_quality = max(0, (1.5 - fdi) * 100)
        recommendation = "å¸‚åœºå™ªéŸ³å¤§ï¼Œä¸é€‚åˆè¶‹åŠ¿ç­–ç•¥"
    
    return {
        "fdi": fdi,
        "regime": regime,
        "trend_quality": round(trend_quality, 1),
        "recommendation": recommendation
    }


# ========== ğŸ†• OI/Volume Ratio (èªæ˜é’±æŒ‡æ ‡) ==========
def oi_volume_ratio(oi_change: float, volume: float) -> float:
    """
    è®¡ç®—OI/Volumeæ¯”ç‡ - åˆ¤æ–­è¶‹åŠ¿çœŸå‡
    
    åŸç†:
    - æˆäº¤é‡å¤§å¯èƒ½æ˜¯åˆ·é‡
    - ä½†OIå¢åŠ æ„å‘³ç€æœ‰èµ„é‡‘ç•™å®¿ï¼Œæ˜¯çœŸå®æŠ¼æ³¨
    
    è§£é‡Š:
    - ratioé«˜ + ä»·æ ¼æ¶¨ = å¢é‡èµ„é‡‘æ¨åŠ¨ï¼ˆçœŸè¶‹åŠ¿ï¼‰
    - ratioä½/è´Ÿ + ä»·æ ¼æ¶¨ = ç©ºå¤´å›è¡¥ï¼ˆå‡è¶‹åŠ¿ï¼‰
    
    Args:
        oi_change: OIå˜åŒ–é‡
        volume: æˆäº¤é‡
        
    Returns:
        OI/Volumeæ¯”ç‡
    """
    if volume <= 0:
        return 0
    
    return round(oi_change / volume, 6)


def smart_money_analysis(oi_change: float, volume: float, price_change_pct: float) -> Dict[str, Any]:
    """
    èªæ˜é’±åˆ†æ - åŸºäºOI/Volumeåˆ¤æ–­è¶‹åŠ¿çœŸå‡
    
    Returns:
        {
            "oi_vol_ratio": æ¯”ç‡,
            "is_real_trend": æ˜¯å¦çœŸè¶‹åŠ¿,
            "money_flow": "smart_buy"/"smart_sell"/"retail"/"mixed",
            "confidence": ç½®ä¿¡åº¦ 0-100,
            "recommendation": å»ºè®®
        }
    """
    ratio = oi_volume_ratio(oi_change, volume)
    
    # åˆ¤æ–­èµ„é‡‘æµå‘
    is_real_trend = False
    money_flow = "mixed"
    confidence = 50
    
    if price_change_pct > 0.5:  # ä»·æ ¼ä¸Šæ¶¨
        if ratio > 0.01:  # OIå¢åŠ 
            is_real_trend = True
            money_flow = "smart_buy"
            confidence = min(100, 50 + ratio * 2000)
            recommendation = "âœ… çœŸè¶‹åŠ¿ï¼šå¢é‡èµ„é‡‘æ¨åŠ¨ä¸Šæ¶¨"
        elif ratio < -0.005:  # OIå‡å°‘
            is_real_trend = False
            money_flow = "retail"
            confidence = max(0, 50 - abs(ratio) * 2000)
            recommendation = "âš ï¸ å‡è¶‹åŠ¿ï¼šç©ºå¤´å›è¡¥ï¼Œéå¢é‡èµ„é‡‘"
        else:
            recommendation = "è§‚å¯Ÿä¸­ï¼šèµ„é‡‘æµå‘ä¸æ˜ç¡®"
    
    elif price_change_pct < -0.5:  # ä»·æ ¼ä¸‹è·Œ
        if ratio > 0.01:  # OIå¢åŠ 
            is_real_trend = True
            money_flow = "smart_sell"
            confidence = min(100, 50 + ratio * 2000)
            recommendation = "âœ… çœŸä¸‹è·Œï¼šå¢é‡èµ„é‡‘åšç©º"
        elif ratio < -0.005:  # OIå‡å°‘
            is_real_trend = False
            money_flow = "retail"
            confidence = max(0, 50 - abs(ratio) * 2000)
            recommendation = "âš ï¸ å‡ä¸‹è·Œï¼šå¤šå¤´å¹³ä»“ï¼Œå¯èƒ½åå¼¹"
        else:
            recommendation = "è§‚å¯Ÿä¸­ï¼šèµ„é‡‘æµå‘ä¸æ˜ç¡®"
    else:
        recommendation = "ä»·æ ¼æ³¢åŠ¨å°ï¼Œæ— æ˜ç¡®ä¿¡å·"
    
    return {
        "oi_vol_ratio": ratio,
        "is_real_trend": is_real_trend,
        "money_flow": money_flow,
        "confidence": round(confidence, 1),
        "recommendation": recommendation
    }


# ========== ğŸ†• åˆ†å½¢ç»´æ•° FDI (Fractal Dimension Index) ==========
def fractal_dimension(df: pd.DataFrame, period: int = 30) -> float:
    """
    è®¡ç®—åˆ†å½¢ç»´æ•° FDI (Fractal Dimension Index)
    
    ä½¿ç”¨Higuchiæ–¹æ³•è®¡ç®—ä»·æ ¼æ›²çº¿çš„"æ··ä¹±åº¦"
    
    è§£é‡Š:
    - FDIæ¥è¿‘1.0: ä»·æ ¼è¿åŠ¨åƒç›´çº¿ï¼ˆå¼ºè¶‹åŠ¿ï¼Œç¡®å®šæ€§é«˜ï¼‰
    - FDIæ¥è¿‘1.5: ä»·æ ¼è¿åŠ¨åƒå¸ƒæœ—è¿åŠ¨ï¼ˆéšæœºéœ‡è¡ï¼Œæ— è¶‹åŠ¿ï¼‰
    
    ç”¨é€”:
    - FDI < 1.3: è¶‹åŠ¿æ˜ç¡®ï¼Œå¯è·Ÿéš
    - FDI > 1.4: éœ‡è¡å‰§çƒˆï¼Œè¶‹åŠ¿ä¸å¯é 
    - FDI 1.3-1.4: è¶‹åŠ¿å½¢æˆä¸­
    
    Args:
        df: Kçº¿æ•°æ®
        period: è®¡ç®—å‘¨æœŸ
        
    Returns:
        FDIå€¼ (1.0-1.5)
    """
    if len(df) < period:
        return 1.25  # é»˜è®¤ä¸­æ€§
    
    try:
        prices = df['close'].tail(period).values
        n = len(prices)
        
        # Higuchiæ–¹æ³•è®¡ç®—
        k_max = min(10, n // 4)
        L = []
        
        for k in range(1, k_max + 1):
            Lk = []
            for m in range(1, k + 1):
                # æ„å»ºå­åºåˆ—
                indices = np.arange(m - 1, n, k)
                if len(indices) < 2:
                    continue
                sub_prices = prices[indices]
                
                # è®¡ç®—é•¿åº¦
                length = np.sum(np.abs(np.diff(sub_prices))) * (n - 1) / (k * len(indices))
                if length > 0:
                    Lk.append(length)
            
            if Lk:
                L.append((k, np.mean(Lk)))
        
        if len(L) < 3:
            return 1.25
        
        # å¯¹æ•°å›å½’æ±‚æ–œç‡ï¼ˆæ–œç‡å°±æ˜¯åˆ†å½¢ç»´æ•°ï¼‰
        log_k = np.log([x[0] for x in L])
        log_L = np.log([x[1] for x in L])
        
        slope, _ = np.polyfit(log_k, log_L, 1)
        fdi = -slope  # å–è´Ÿå€¼
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´
        fdi = max(1.0, min(1.5, fdi))
        
        return round(float(fdi), 4)
    except:
        return 1.25


def fdi_analysis(df: pd.DataFrame, period: int = 30) -> Dict[str, Any]:
    """
    åˆ†å½¢ç»´æ•°ç»¼åˆåˆ†æ
    
    Returns:
        {
            "fdi": å½“å‰FDIå€¼,
            "trend_quality": "strong"/"weak"/"noise",
            "quality_score": è´¨é‡è¯„åˆ† 0-100,
            "recommendation": å»ºè®®
        }
    """
    fdi = fractal_dimension(df, period)
    
    if fdi < 1.25:
        trend_quality = "strong"
        quality_score = min(100, (1.5 - fdi) * 200)
        recommendation = "è¶‹åŠ¿çº¯å‡€ï¼Œå¯è·Ÿéš"
    elif fdi < 1.35:
        trend_quality = "moderate"
        quality_score = 50 + (1.35 - fdi) * 100
        recommendation = "è¶‹åŠ¿ä¸€èˆ¬ï¼Œè°¨æ…è·Ÿéš"
    elif fdi < 1.45:
        trend_quality = "weak"
        quality_score = max(0, (1.45 - fdi) * 200)
        recommendation = "è¶‹åŠ¿è¾ƒå¼±ï¼Œä¸å»ºè®®è·Ÿéš"
    else:
        trend_quality = "noise"
        quality_score = 0
        recommendation = "çº¯å™ªéŸ³ï¼Œé¿å…äº¤æ˜“"
    
    return {
        "fdi": fdi,
        "trend_quality": trend_quality,
        "quality_score": round(quality_score, 1),
        "recommendation": recommendation
    }


# ========== ğŸ†• OI/Volume Ratio (èªæ˜é’±æŒ‡æ ‡) ==========
def oi_volume_ratio(oi_change: float, volume: float) -> float:
    """
    è®¡ç®—OI/Volumeæ¯”ç‡ - åˆ¤æ–­è¶‹åŠ¿çœŸå‡
    
    åŸç†:
    - æˆäº¤é‡å¤§å¯èƒ½æ˜¯åˆ·é‡
    - OIå¢åŠ æ„å‘³ç€æœ‰èµ„é‡‘ç•™å®¿ï¼ˆçœŸå®æŠ¼æ³¨ï¼‰
    
    è§£é‡Š:
    - ä»·æ ¼æ¶¨ + ratioé«˜ = å¢é‡èµ„é‡‘æ¨åŠ¨ âœ… çœŸè¶‹åŠ¿
    - ä»·æ ¼æ¶¨ + ratioä½/è´Ÿ = ç©ºå¤´å›è¡¥ âš ï¸ å‡è¶‹åŠ¿
    - ä»·æ ¼è·Œ + ratioé«˜ = å¢é‡åšç©º âœ… çœŸè¶‹åŠ¿
    - ä»·æ ¼è·Œ + ratioä½/è´Ÿ = å¤šå¤´å¹³ä»“ âš ï¸ å‡è¶‹åŠ¿
    
    Args:
        oi_change: OIå˜åŒ–é‡
        volume: æˆäº¤é‡
        
    Returns:
        æ¯”ç‡å€¼
    """
    if volume <= 0:
        return 0
    return oi_change / volume


def smart_money_analysis(price_change: float, oi_change: float, volume: float) -> Dict[str, Any]:
    """
    èªæ˜é’±åˆ†æ - åˆ¤æ–­è¶‹åŠ¿æ˜¯å¦ç”±çœŸå®èµ„é‡‘æ¨åŠ¨
    
    Returns:
        {
            "oi_vol_ratio": OI/Volumeæ¯”ç‡,
            "is_smart_money": æ˜¯å¦èªæ˜é’±æ¨åŠ¨,
            "trend_type": "accumulation"/"distribution"/"short_squeeze"/"long_liquidation",
            "quality_score": è´¨é‡è¯„åˆ† 0-100,
            "recommendation": å»ºè®®
        }
    """
    ratio = oi_volume_ratio(oi_change, volume)
    
    # åˆ¤æ–­è¶‹åŠ¿ç±»å‹
    if price_change > 0:  # ä»·æ ¼ä¸Šæ¶¨
        if oi_change > 0 and ratio > 0.3:
            trend_type = "accumulation"  # å¸ç­¹
            is_smart_money = True
            quality_score = min(100, 50 + ratio * 100)
            recommendation = "å¢é‡èµ„é‡‘æ¨åŠ¨ï¼ŒçœŸè¶‹åŠ¿"
        elif oi_change < 0:
            trend_type = "short_squeeze"  # ç©ºå¤´å›è¡¥
            is_smart_money = False
            quality_score = max(0, 50 - abs(ratio) * 50)
            recommendation = "ç©ºå¤´å›è¡¥ï¼Œè¶‹åŠ¿ä¸å¯æŒç»­"
        else:
            trend_type = "neutral"
            is_smart_money = False
            quality_score = 50
            recommendation = "èµ„é‡‘ä¸­æ€§"
    else:  # ä»·æ ¼ä¸‹è·Œ
        if oi_change > 0 and ratio > 0.3:
            trend_type = "distribution"  # å‡ºè´§
            is_smart_money = True
            quality_score = min(100, 50 + ratio * 100)
            recommendation = "å¢é‡åšç©ºï¼ŒçœŸè¶‹åŠ¿"
        elif oi_change < 0:
            trend_type = "long_liquidation"  # å¤šå¤´å¹³ä»“
            is_smart_money = False
            quality_score = max(0, 50 - abs(ratio) * 50)
            recommendation = "å¤šå¤´å¹³ä»“ï¼Œè¶‹åŠ¿ä¸å¯æŒç»­"
        else:
            trend_type = "neutral"
            is_smart_money = False
            quality_score = 50
            recommendation = "èµ„é‡‘ä¸­æ€§"
    
    return {
        "oi_vol_ratio": round(ratio, 4),
        "is_smart_money": is_smart_money,
        "trend_type": trend_type,
        "quality_score": round(quality_score, 1),
        "recommendation": recommendation
    }


# ========== ğŸ†• Funding Rate Z-Score ==========
_FUNDING_HISTORY: Dict[str, List[float]] = {}

def funding_zscore(symbol: str, current_rate: float, history_days: int = 30) -> Dict[str, Any]:
    """
    è®¡ç®—Funding Rateçš„Z-Score
    
    åŸç†:
    - ç®€å•çœ‹è´¹ç‡æ­£è´Ÿæ²¡ç”¨ï¼Œè¦çœ‹ç›¸å¯¹åå·®
    - Z-Score > 2: æåº¦æ‹¥æŒ¤ï¼Œåå‘ä¿¡å·ä»·å€¼é«˜
    - Z-Score < -2: æåº¦ææ…Œï¼Œåå‘ä¿¡å·ä»·å€¼é«˜
    
    Args:
        symbol: äº¤æ˜“å¯¹
        current_rate: å½“å‰è´¹ç‡
        history_days: å†å²å¤©æ•°ï¼ˆç”¨äºä¼°ç®—ï¼‰
        
    Returns:
        {
            "zscore": Z-Scoreå€¼,
            "percentile": ç™¾åˆ†ä½,
            "crowding": "extreme_long"/"extreme_short"/"moderate"/"neutral",
            "reversal_value": åè½¬ä¿¡å·ä»·å€¼ 0-100,
            "recommendation": å»ºè®®
        }
    """
    global _FUNDING_HISTORY
    
    # æ›´æ–°å†å²
    if symbol not in _FUNDING_HISTORY:
        _FUNDING_HISTORY[symbol] = []
    
    _FUNDING_HISTORY[symbol].append(current_rate)
    
    # åªä¿ç•™æœ€è¿‘Nä¸ªæ•°æ®ç‚¹ï¼ˆå‡è®¾æ¯8å°æ—¶ä¸€ä¸ªè´¹ç‡ï¼Œ30å¤©çº¦90ä¸ªï¼‰
    max_points = history_days * 3
    if len(_FUNDING_HISTORY[symbol]) > max_points:
        _FUNDING_HISTORY[symbol] = _FUNDING_HISTORY[symbol][-max_points:]
    
    history = _FUNDING_HISTORY[symbol]
    
    # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
    if len(history) < 10:
        return {
            "zscore": 0,
            "percentile": 50,
            "crowding": "neutral",
            "reversal_value": 50,
            "recommendation": "å†å²æ•°æ®ä¸è¶³"
        }
    
    # è®¡ç®—Z-Score
    mean_rate = np.mean(history)
    std_rate = np.std(history)
    
    if std_rate < 1e-10:
        zscore = 0
    else:
        zscore = (current_rate - mean_rate) / std_rate
    
    # è®¡ç®—ç™¾åˆ†ä½
    percentile = (np.sum(np.array(history) < current_rate) / len(history)) * 100
    
    # åˆ¤æ–­æ‹¥æŒ¤ç¨‹åº¦
    if zscore > 2.5:
        crowding = "extreme_long"
        reversal_value = min(100, 50 + zscore * 15)
        recommendation = "æåº¦å¤šå¤´æ‹¥æŒ¤ï¼Œåšç©ºä¿¡å·ä»·å€¼æé«˜"
    elif zscore > 1.5:
        crowding = "long_crowded"
        reversal_value = min(100, 50 + zscore * 10)
        recommendation = "å¤šå¤´æ‹¥æŒ¤ï¼Œåšç©ºä¿¡å·ä»·å€¼é«˜"
    elif zscore < -2.5:
        crowding = "extreme_short"
        reversal_value = min(100, 50 + abs(zscore) * 15)
        recommendation = "æåº¦ç©ºå¤´æ‹¥æŒ¤ï¼Œåšå¤šä¿¡å·ä»·å€¼æé«˜"
    elif zscore < -1.5:
        crowding = "short_crowded"
        reversal_value = min(100, 50 + abs(zscore) * 10)
        recommendation = "ç©ºå¤´æ‹¥æŒ¤ï¼Œåšå¤šä¿¡å·ä»·å€¼é«˜"
    else:
        crowding = "neutral"
        reversal_value = 50
        recommendation = "è´¹ç‡ä¸­æ€§"
    
    return {
        "zscore": round(zscore, 2),
        "percentile": round(percentile, 1),
        "crowding": crowding,
        "reversal_value": round(reversal_value, 1),
        "recommendation": recommendation
    }


# ========== ğŸ†• åè½¬ä¿¡å·ç»¼åˆè´¨é‡è¯„ä¼° ==========
def reversal_quality_score(df: pd.DataFrame, side: str, 
                           funding_rate: float = 0, 
                           symbol: str = "UNKNOWN") -> Dict[str, Any]:
    """
    åè½¬ä¿¡å·ç»¼åˆè´¨é‡è¯„ä¼° - æ•´åˆCVDèƒŒç¦» + Funding Z-Score
    
    è¿™æ˜¯ç”¨äºclaude_reviewerçš„æ ¸å¿ƒå‡½æ•°
    
    Args:
        df: Kçº¿æ•°æ®
        side: äº¤æ˜“æ–¹å‘ "long"/"short"
        funding_rate: å½“å‰è´¹ç‡
        symbol: äº¤æ˜“å¯¹
        
    Returns:
        {
            "cvd_analysis": CVDåˆ†æç»“æœ,
            "funding_analysis": Fundingåˆ†æç»“æœ,
            "overall_score": ç»¼åˆè¯„åˆ† 0-100,
            "is_quality_reversal": æ˜¯å¦ä¼˜è´¨åè½¬ä¿¡å·,
            "risk_level": "low"/"medium"/"high",
            "recommendation": äº¤æ˜“å»ºè®®
        }
    """
    # CVDåˆ†æ
    cvd_result = cvd_divergence(df, lookback=20)
    
    # Fundingåˆ†æ
    funding_result = funding_zscore(symbol, funding_rate)
    
    # CVDè¯„åˆ† (æƒé‡50%)
    cvd_score = cvd_result["signal_quality"]
    
    # æ£€æŸ¥CVDæ˜¯å¦æ”¯æŒåè½¬æ–¹å‘
    if side == "long" and cvd_result["divergence"] == "bullish":
        cvd_score += 20  # çœ‹æ¶¨èƒŒç¦»æ”¯æŒåšå¤š
    elif side == "short" and cvd_result["divergence"] == "bearish":
        cvd_score += 20  # çœ‹è·ŒèƒŒç¦»æ”¯æŒåšç©º
    elif cvd_result["is_fake_breakout"]:
        cvd_score -= 20  # å‡çªç ´æ‰£åˆ†
    
    cvd_score = max(0, min(100, cvd_score))
    
    # Fundingè¯„åˆ† (æƒé‡50%)
    funding_score = funding_result["reversal_value"]
    
    # æ£€æŸ¥Fundingæ˜¯å¦æ”¯æŒåè½¬æ–¹å‘
    if side == "long" and funding_result["crowding"] in ["extreme_short", "short_crowded"]:
        funding_score += 20  # ç©ºå¤´æ‹¥æŒ¤æ”¯æŒåšå¤š
    elif side == "short" and funding_result["crowding"] in ["extreme_long", "long_crowded"]:
        funding_score += 20  # å¤šå¤´æ‹¥æŒ¤æ”¯æŒåšç©º
    
    funding_score = max(0, min(100, funding_score))
    
    # ç»¼åˆè¯„åˆ†
    overall_score = cvd_score * 0.5 + funding_score * 0.5
    
    # åˆ¤æ–­æ˜¯å¦ä¼˜è´¨åè½¬
    is_quality_reversal = overall_score >= 65
    
    # é£é™©ç­‰çº§
    if overall_score >= 75:
        risk_level = "low"
    elif overall_score >= 55:
        risk_level = "medium"
    else:
        risk_level = "high"
    
    # ç»¼åˆå»ºè®®
    if is_quality_reversal:
        if cvd_result["divergence"] != "none" and funding_result["crowding"] != "neutral":
            recommendation = f"âœ… ä¼˜è´¨åè½¬: CVD{cvd_result['divergence']}èƒŒç¦» + {funding_result['crowding']}"
        elif cvd_result["divergence"] != "none":
            recommendation = f"âœ… CVD{cvd_result['divergence']}èƒŒç¦»ç¡®è®¤åè½¬"
        else:
            recommendation = f"âœ… è´¹ç‡æ”¯æŒåè½¬"
    else:
        weak_points = []
        if cvd_score < 50:
            weak_points.append("CVDä¸æ”¯æŒ")
        if funding_score < 50:
            weak_points.append("è´¹ç‡ä¸æ”¯æŒ")
        recommendation = f"âš ï¸ åè½¬ä¿¡å·å¼±: {', '.join(weak_points)}"
    
    return {
        "cvd_analysis": cvd_result,
        "funding_analysis": funding_result,
        "cvd_score": round(cvd_score, 1),
        "funding_score": round(funding_score, 1),
        "overall_score": round(overall_score, 1),
        "is_quality_reversal": is_quality_reversal,
        "risk_level": risk_level,
        "recommendation": recommendation
    }


# ========== ğŸ†• è¶‹åŠ¿é¢„åˆ¤ç»¼åˆè´¨é‡è¯„ä¼° ==========
def trend_quality_score(df: pd.DataFrame, side: str,
                        oi_change: float = 0,
                        volume: float = 1) -> Dict[str, Any]:
    """
    è¶‹åŠ¿é¢„åˆ¤ç»¼åˆè´¨é‡è¯„ä¼° - æ•´åˆFDI + OI/Vol + ER + Hurst
    
    è¿™æ˜¯ç”¨äºtrend_anticipationçš„æ ¸å¿ƒå‡½æ•°
    
    Args:
        df: Kçº¿æ•°æ®
        side: äº¤æ˜“æ–¹å‘
        oi_change: OIå˜åŒ–é‡
        volume: æˆäº¤é‡
        
    Returns:
        {
            "fdi_analysis": FDIåˆ†æç»“æœ,
            "smart_money_analysis": èªæ˜é’±åˆ†æç»“æœ,
            "er_analysis": æ•ˆç‡æ¯”åˆ†æç»“æœ,
            "hurst_analysis": Hurståˆ†æç»“æœ,
            "overall_score": ç»¼åˆè¯„åˆ† 0-100,
            "is_quality_trend": æ˜¯å¦ä¼˜è´¨è¶‹åŠ¿ä¿¡å·,
            "risk_level": "low"/"medium"/"high",
            "recommendation": äº¤æ˜“å»ºè®®
        }
    """
    # è®¡ç®—ä»·æ ¼å˜åŒ–
    if len(df) >= 20:
        price_change = (df['close'].iloc[-1] - df['close'].iloc[-20]) / df['close'].iloc[-20]
    else:
        price_change = 0
    
    # å„é¡¹åˆ†æ
    fdi_result = fdi_analysis(df)
    smart_money_result = smart_money_analysis(price_change, oi_change, volume)
    er_result = efficiency_ratio_trend(df)
    hurst_result = hurst_analysis(df)
    
    # è¯„åˆ†æƒé‡:
    # FDI 30% (è¶‹åŠ¿çº¯åº¦æœ€é‡è¦)
    # èªæ˜é’± 25% (èµ„é‡‘çœŸå‡)
    # ER 25% (è¶‹åŠ¿æ•ˆç‡)
    # Hurst 20% (æŒç»­æ€§)
    
    fdi_score = fdi_result["quality_score"]
    sm_score = smart_money_result["quality_score"]
    er_score = er_result["trend_quality"]
    hurst_score = hurst_result["persistence"]
    
    overall_score = fdi_score * 0.30 + sm_score * 0.25 + er_score * 0.25 + hurst_score * 0.20
    
    # åˆ¤æ–­æ˜¯å¦ä¼˜è´¨è¶‹åŠ¿
    is_quality_trend = overall_score >= 60 and fdi_result["fdi"] < 1.4
    
    # é£é™©ç­‰çº§
    if overall_score >= 70 and fdi_result["fdi"] < 1.3:
        risk_level = "low"
    elif overall_score >= 50:
        risk_level = "medium"
    else:
        risk_level = "high"
    
    # ç»¼åˆå»ºè®®
    if is_quality_trend:
        if smart_money_result["is_smart_money"]:
            recommendation = f"âœ… ä¼˜è´¨è¶‹åŠ¿: FDI{fdi_result['fdi']:.2f} + èªæ˜é’±{smart_money_result['trend_type']}"
        else:
            recommendation = f"âœ… è¶‹åŠ¿è‰¯å¥½: FDI{fdi_result['fdi']:.2f}"
    else:
        weak_points = []
        if fdi_result["fdi"] >= 1.4:
            weak_points.append(f"FDIé«˜({fdi_result['fdi']:.2f})")
        if not smart_money_result["is_smart_money"]:
            weak_points.append("éèªæ˜é’±")
        if er_score < 50:
            weak_points.append("ERä½")
        recommendation = f"âš ï¸ è¶‹åŠ¿è´¨é‡å·®: {', '.join(weak_points)}"
    
    return {
        "fdi_analysis": fdi_result,
        "smart_money_analysis": smart_money_result,
        "er_analysis": er_result,
        "hurst_analysis": hurst_result,
        "overall_score": round(overall_score, 1),
        "is_quality_trend": is_quality_trend,
        "risk_level": risk_level,
        "recommendation": recommendation
    }


# ========== èµ„é‡‘è´¹ç‡ç¼“å­˜ ==========
_FUNDING_CACHE: Dict[str, Dict[str, Any]] = {}
_FUNDING_HISTORY: Dict[str, List[Tuple[float, float]]] = {}  # ğŸ†• å†å²è®°å½•ç”¨äºZ-Score

def funding_score(symbol: str, cfg: Dict[str, Any]) -> float:
    fcfg = cfg.get("funding") or {}
    if not fcfg.get("enabled", False): return 0.5
    now = time.time()
    cached = _FUNDING_CACHE.get(symbol)
    if cached and (now - cached["ts"] < 300): return cached["score"]
    
    try:
        import ccxt
        ex = getattr(ccxt, cfg.get("exchange", {}).get("name", "binance"))()
        contract_symbol = (fcfg.get("symbol_map") or {}).get(symbol, f"{symbol}:USDT")
        
        funding_rate = ex.fetch_funding_rate(contract_symbol).get("fundingRate")
        if funding_rate is None: return 0.5

        clip_val = float(fcfg.get("clip", 0.01))
        funding_rate = np.clip(funding_rate, -clip_val, clip_val)
        score = float(np.clip(0.5 + 0.5 * np.tanh(-funding_rate * 200), 0.0, 1.0))
        
        # ğŸ†• è®°å½•å†å²ç”¨äºZ-Score
        if symbol not in _FUNDING_HISTORY:
            _FUNDING_HISTORY[symbol] = []
        _FUNDING_HISTORY[symbol].append((now, funding_rate))
        # ä¿ç•™30å¤©æ•°æ®ï¼ˆæ¯8å°æ—¶ä¸€æ¬¡ï¼Œçº¦90æ¡ï¼‰
        _FUNDING_HISTORY[symbol] = [(t, r) for t, r in _FUNDING_HISTORY[symbol] if now - t < 30 * 86400][-100:]
        
        _FUNDING_CACHE[symbol] = {"ts": now, "score": score, "rate": funding_rate}
        return score
    except Exception as e:
        # print(f"[FUNDING_ERR] {symbol}: {e}")
        return 0.5


# ========== ğŸ†• Funding Rate Z-Score ==========
def funding_zscore(symbol: str, cfg: Dict[str, Any]) -> Dict[str, Any]:
    """
    è®¡ç®—èµ„é‡‘è´¹ç‡çš„Z-Score - è¯†åˆ«æç«¯æ‹¥æŒ¤
    
    åŸç†:
    - ç®€å•çš„è´¹ç‡æ­£è´Ÿæ²¡ç”¨ï¼Œè¦çœ‹ç›¸å¯¹åå·®
    - Z-Score > 2: æåº¦æ‹¥æŒ¤ï¼Œåå‘ä¿¡å·ä»·å€¼é«˜
    - Z-Score < -2: æåº¦ææ…Œï¼Œåå‘ä¿¡å·ä»·å€¼é«˜
    
    Returns:
        {
            "current_rate": å½“å‰è´¹ç‡,
            "zscore": Z-Scoreå€¼,
            "is_extreme": æ˜¯å¦æç«¯,
            "crowd_direction": "long"/"short"/"neutral",
            "contrarian_value": åå‘äº¤æ˜“ä»·å€¼ 0-100,
            "recommendation": å»ºè®®
        }
    """
    result = {
        "current_rate": 0,
        "zscore": 0,
        "is_extreme": False,
        "crowd_direction": "neutral",
        "contrarian_value": 50,
        "recommendation": "æ•°æ®ä¸è¶³"
    }
    
    # å…ˆè°ƒç”¨funding_scoreç¡®ä¿æœ‰æœ€æ–°æ•°æ®
    funding_score(symbol, cfg)
    
    cached = _FUNDING_CACHE.get(symbol)
    history = _FUNDING_HISTORY.get(symbol, [])
    
    if not cached or len(history) < 10:
        return result
    
    current_rate = cached.get("rate", 0)
    result["current_rate"] = current_rate
    
    # è®¡ç®—å†å²å‡å€¼å’Œæ ‡å‡†å·®
    rates = [r for _, r in history]
    mean_rate = np.mean(rates)
    std_rate = np.std(rates)
    
    if std_rate < 1e-10:
        return result
    
    # è®¡ç®—Z-Score
    zscore = (current_rate - mean_rate) / std_rate
    result["zscore"] = round(zscore, 2)
    
    # åˆ¤æ–­æç«¯ç¨‹åº¦
    if zscore > 2:
        result["is_extreme"] = True
        result["crowd_direction"] = "long"
        result["contrarian_value"] = min(100, 50 + zscore * 15)
        result["recommendation"] = f"ğŸ”¥ æåº¦æ­£è´¹ç‡(Z={zscore:.1f})ï¼Œå…¨ç½‘åšå¤šæ‹¥æŒ¤ï¼Œåšç©ºåè½¬ä»·å€¼é«˜"
    elif zscore < -2:
        result["is_extreme"] = True
        result["crowd_direction"] = "short"
        result["contrarian_value"] = min(100, 50 + abs(zscore) * 15)
        result["recommendation"] = f"ğŸ”¥ æåº¦è´Ÿè´¹ç‡(Z={zscore:.1f})ï¼Œå…¨ç½‘åšç©ºæ‹¥æŒ¤ï¼Œåšå¤šåè½¬ä»·å€¼é«˜"
    elif zscore > 1:
        result["crowd_direction"] = "long"
        result["contrarian_value"] = 50 + zscore * 10
        result["recommendation"] = f"è´¹ç‡åé«˜(Z={zscore:.1f})ï¼Œå¤šå¤´ç•¥æ‹¥æŒ¤"
    elif zscore < -1:
        result["crowd_direction"] = "short"
        result["contrarian_value"] = 50 + abs(zscore) * 10
        result["recommendation"] = f"è´¹ç‡åä½(Z={zscore:.1f})ï¼Œç©ºå¤´ç•¥æ‹¥æŒ¤"
    else:
        result["recommendation"] = "è´¹ç‡æ­£å¸¸ï¼Œæ— æç«¯æ‹¥æŒ¤"
    
    return result


# ========== OI(æœªå¹³ä»“é‡)ç¼“å­˜ ==========
_OI_HISTORY: Dict[str, list] = {}

def oi_trend_score(symbol: str, cfg: Dict[str, Any]) -> float:
    oicfg = cfg.get("oi") or {}
    if not oicfg.get("enabled", False): return 0.5
    try:
        import ccxt
        ex = getattr(ccxt, cfg.get("exchange", {}).get("name", "binance"))()
        contract_symbol = (oicfg.get("symbol_map") or {}).get(symbol, symbol.replace("/",""))
        
        oi_value = float(ex.fapiPublicGetOpenInterest({"symbol": contract_symbol}).get("openInterest", 0))
        if oi_value == 0: return 0.5
        
        history = _OI_HISTORY.setdefault(symbol, [])
        history.append((time.time(), oi_value))
        
        lookback_n = int(oicfg.get("lookback_n", 24))
        history = history[-lookback_n:]
        _OI_HISTORY[symbol] = history
        
        if len(history) < 3: return 0.5
        
        timestamps = np.array([x[0] for x in history])
        oi_array = np.array([x[1] for x in history])
        slope, _ = np.polyfit(timestamps - timestamps.min(), oi_array, 1)
        
        score = float(np.clip(0.5 + 0.5 * np.tanh(slope / max(1, np.mean(oi_array)) * 50), 0.0, 1.0))
        return score
    except Exception as e:
        # print(f"[OI_ERR] {symbol}: {e}")
        return 0.5


# ========== å®šæ—¶æ¸…ç†ç¼“å­˜ ==========
def cleanup_funding_oi_cache():
    global _FUNDING_CACHE, _OI_HISTORY
    now = time.time()
    for k in [k for k, v in _FUNDING_CACHE.items() if now - v["ts"] > 3600]: del _FUNDING_CACHE[k]
    for k in list(_OI_HISTORY.keys()):
        _OI_HISTORY[k] = [item for item in _OI_HISTORY[k] if now - item[0] < 86400]
        if not _OI_HISTORY[k]: del _OI_HISTORY[k]


# ========== å®è§‚ã€ç›˜å£ ==========
def macro_score(cfg: Dict[str,Any]) -> float:
    return 0.5

def orderbook_strength_fetch(ex, symbol: str, limit: int = 50) -> float:
    try:
        ob = ex.fetch_order_book(symbol, limit=limit)
        bid_vol = sum([b[1] for b in ob.get("bids", [])])
        ask_vol = sum([a[1] for a in ob.get("asks", [])])
        if bid_vol + ask_vol <= 0: return 0.5
        return float(0.5 + 0.5*np.tanh(np.log(bid_vol / max(1e-9, ask_vol) + 1e-9)))
    except Exception:
        return 0.5