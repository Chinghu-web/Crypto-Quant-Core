# core/trend_anticipation.py - è¶‹åŠ¿é¢„åˆ¤æ”¯æŒæ¨¡å— v2.1
# -*- coding: utf-8 -*-
"""
è¶‹åŠ¿é¢„åˆ¤æ”¯æŒæ¨¡å— v2.1

ğŸ”¥ğŸ”¥ğŸ”¥ v2.1 é‡å¤§æ›´æ–° (é«˜æ³¢åŠ¨è½¨é“é›†æˆç‰ˆ):
1. æ–°å¢ analyze_trend_context() ç‹¬ç«‹åˆ†æå‡½æ•°
2. ä¾›é«˜æ³¢åŠ¨è½¨é“AIå®¡æ ¸è°ƒç”¨
3. ä¸å†ç‹¬ç«‹æ¨é€ä¿¡å·ï¼Œä½œä¸ºåˆ†æå·¥å…·ä½¿ç”¨

ğŸ”¥ğŸ”¥ğŸ”¥ v2.0 é‡å¤§æ›´æ–° (æ™ºèƒ½è¶‹åŠ¿è¯†åˆ«ç‰ˆ):
1. æ–°å¢FDIåˆ†å½¢ç»´æ•° - è¯†åˆ«è¶‹åŠ¿çº¯åº¦ï¼Œè¿‡æ»¤å™ªéŸ³è¶‹åŠ¿
2. æ–°å¢OI/Volume Ratio - è¯†åˆ«èªæ˜é’±ï¼Œåˆ¤æ–­è¶‹åŠ¿çœŸå‡
3. æ–°å¢Efficiency Ratio - è¯„ä¼°è¶‹åŠ¿æ•ˆç‡
4. æ–°å¢trend_quality_scoreç»¼åˆè¯„ä¼°
5. ä¿¡å·è¾“å‡ºæ–°å¢è¶‹åŠ¿è´¨é‡æŒ‡æ ‡

ğŸ”¥ v1.3 æ›´æ–° (v7.9.4 å¹³è¡¡ç‰ˆ):
1. RSIåŒºé—´æ”¾å®½: [15,25] / [75,85]
2. ADXé˜ˆå€¼: 28 -> 22
3. æˆäº¤é‡é˜ˆå€¼: 1.0x -> 0.8x
4. è¯„åˆ†é˜ˆå€¼: 0.85 -> 0.75
5. å»é‡å†·å´æœŸ: 45 -> 30åˆ†é’Ÿ
6. æœ€ä½æ¡ä»¶æ•°: 4 -> 3

åŠŸèƒ½ï¼š
1. æ”¯æ’‘ä½/é˜»åŠ›ä½æ£€æµ‹
2. Kçº¿å½¢æ€è¯†åˆ«
3. æˆäº¤é‡ç»“æ„åˆ†æ
4. å¤šæ—¶é—´æ¡†æ¶åˆ†æ
5. ä¿¡å·å»é‡
6. è¶‹åŠ¿é¢„åˆ¤ä¿¡å·ç”Ÿæˆ
7. ğŸ†• FDIè¶‹åŠ¿çº¯åº¦æ£€æµ‹
8. ğŸ†• èªæ˜é’±åˆ†æ
9. ğŸ†• v2.1: analyze_trend_context() ä¾›å¤–éƒ¨è°ƒç”¨
"""

import time
import numpy as np
import pandas as pd
import datetime as dt
from typing import Dict, List, Optional, Tuple, Any

# ğŸ”¥ v2.0: å¯¼å…¥æ–°æŒ‡æ ‡å‡½æ•°
try:
    from .utils import (
        fractal_dimension, fdi_analysis,
        smart_money_analysis, oi_volume_ratio,
        efficiency_ratio_trend, hurst_analysis,
        trend_quality_score
    )
    HAS_TREND_INDICATORS = True
except ImportError:
    HAS_TREND_INDICATORS = False
    print("[TREND_ANTICIPATION] âš ï¸ æ–°æŒ‡æ ‡å‡½æ•°æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å†…ç½®ç‰ˆæœ¬")

# ============ å…¨å±€ç¼“å­˜ ============
_SIGNAL_DEDUP_CACHE: Dict[str, Dict] = {}
_MTF_KLINE_CACHE: Dict[str, Dict] = {}
_MTF_CACHE_TTL = 60
_TRADE_HISTORY: List[Dict] = []


# ============ ğŸ”¥v2.0æ–°å¢: å†…ç½®FDIè®¡ç®— ============
def _calculate_fdi(df: pd.DataFrame, period: int = 30) -> float:
    """
    è®¡ç®—åˆ†å½¢ç»´æ•° FDI (Fractal Dimension Index) - å†…ç½®ç‰ˆæœ¬
    
    FDIæ¥è¿‘1.0 = å¼ºè¶‹åŠ¿ï¼ˆç›´çº¿ï¼‰
    FDIæ¥è¿‘1.5 = éœ‡è¡ï¼ˆå¸ƒæœ—è¿åŠ¨ï¼‰
    """
    if len(df) < period:
        return 1.25  # é»˜è®¤ä¸­æ€§
    
    try:
        prices = df['close'].tail(period).values
        n = len(prices)
        
        # ç®€åŒ–Higuchiæ–¹æ³•
        k_max = min(8, n // 4)
        L = []
        
        for k in range(1, k_max + 1):
            Lk = []
            for m in range(1, k + 1):
                indices = np.arange(m - 1, n, k)
                if len(indices) < 2:
                    continue
                sub_prices = prices[indices]
                length = np.sum(np.abs(np.diff(sub_prices))) * (n - 1) / (k * len(indices))
                if length > 0:
                    Lk.append(length)
            
            if Lk:
                L.append((k, np.mean(Lk)))
        
        if len(L) < 3:
            return 1.25
        
        log_k = np.log([x[0] for x in L])
        log_L = np.log([x[1] for x in L])
        
        slope, _ = np.polyfit(log_k, log_L, 1)
        fdi = -slope
        
        return max(1.0, min(1.5, float(fdi)))
    except:
        return 1.25


def _analyze_smart_money(price_change: float, oi_change: float, volume: float) -> Dict:
    """
    ğŸ”¥v2.0æ–°å¢: èªæ˜é’±åˆ†æ - å†…ç½®ç‰ˆæœ¬
    
    åˆ¤æ–­è¶‹åŠ¿æ˜¯å¦ç”±çœŸå®èµ„é‡‘æ¨åŠ¨
    """
    if volume <= 0:
        return {"is_smart_money": False, "trend_type": "unknown", "quality_score": 50}
    
    ratio = oi_change / volume
    
    if price_change > 0:  # ä»·æ ¼ä¸Šæ¶¨
        if oi_change > 0 and ratio > 0.3:
            return {
                "is_smart_money": True,
                "trend_type": "accumulation",
                "quality_score": min(100, 50 + ratio * 100)
            }
        elif oi_change < 0:
            return {
                "is_smart_money": False,
                "trend_type": "short_squeeze",
                "quality_score": max(0, 50 - abs(ratio) * 50)
            }
    else:  # ä»·æ ¼ä¸‹è·Œ
        if oi_change > 0 and ratio > 0.3:
            return {
                "is_smart_money": True,
                "trend_type": "distribution",
                "quality_score": min(100, 50 + ratio * 100)
            }
        elif oi_change < 0:
            return {
                "is_smart_money": False,
                "trend_type": "long_liquidation",
                "quality_score": max(0, 50 - abs(ratio) * 50)
            }
    
    return {"is_smart_money": False, "trend_type": "neutral", "quality_score": 50}


# ============ æ”¯æ’‘ä½/é˜»åŠ›ä½æ£€æµ‹ ============
def detect_support_resistance(df: pd.DataFrame, cfg: Dict, side: str, current_price: float = None) -> Dict:
    """
    æ£€æµ‹æ”¯æ’‘ä½å’Œé˜»åŠ›ä½
    """
    sr_cfg = cfg.get("support_resistance", {})
    if not sr_cfg.get("enabled", True):
        return {"nearest_level": 0, "distance_pct": 999, "level_type": "none", "bonus": 0, "all_levels": []}
    
    if current_price is None:
        current_price = float(df["close"].iloc[-1])
    
    levels = []
    
    if side == "long":
        sources = sr_cfg.get("support_sources", {})
        
        # 24hæœ€ä½ä»·
        if sources.get("recent_low_24h", True):
            lookback = min(1440, len(df))
            if lookback > 0:
                low_val = float(df["low"].tail(lookback).min())
                levels.append({"price": low_val, "type": "recent_low"})
        
        # å¸ƒæ—å¸¦ä¸‹è½¨
        if sources.get("bollinger_lower", True) and len(df) >= 20:
            sma = df["close"].rolling(window=20).mean()
            std = df["close"].rolling(window=20).std()
            bb_lower = float(sma.iloc[-1] - 2 * std.iloc[-1])
            if bb_lower > 0:
                levels.append({"price": bb_lower, "type": "bb_lower"})
        
        # EMA200
        if sources.get("ema_200", True) and len(df) >= 200:
            ema200 = float(df["close"].ewm(span=200, adjust=False).mean().iloc[-1])
            if ema200 < current_price:
                levels.append({"price": ema200, "type": "ema_200"})
        
        # å±€éƒ¨ä½ç‚¹
        if sources.get("local_lows", True):
            local_lows = _find_local_pivots(df, 5, "low")
            for ll in local_lows[-3:]:
                if ll < current_price:
                    levels.append({"price": ll, "type": "local_low"})
        
        # æ•´æ•°å…³å£
        if sources.get("round_numbers", True):
            round_levels = _find_round_numbers(current_price, side="long")
            for rl in round_levels:
                levels.append({"price": rl, "type": "round_number"})
    
    else:  # side == "short"
        sources = sr_cfg.get("resistance_sources", {})
        
        # 24hæœ€é«˜ä»·
        if sources.get("recent_high_24h", True):
            lookback = min(1440, len(df))
            if lookback > 0:
                high_val = float(df["high"].tail(lookback).max())
                levels.append({"price": high_val, "type": "recent_high"})
        
        # å¸ƒæ—å¸¦ä¸Šè½¨
        if sources.get("bollinger_upper", True) and len(df) >= 20:
            sma = df["close"].rolling(window=20).mean()
            std = df["close"].rolling(window=20).std()
            bb_upper = float(sma.iloc[-1] + 2 * std.iloc[-1])
            if bb_upper > 0:
                levels.append({"price": bb_upper, "type": "bb_upper"})
        
        # EMA200
        if sources.get("ema_200", True) and len(df) >= 200:
            ema200 = float(df["close"].ewm(span=200, adjust=False).mean().iloc[-1])
            if ema200 > current_price:
                levels.append({"price": ema200, "type": "ema_200"})
        
        # å±€éƒ¨é«˜ç‚¹
        if sources.get("local_highs", True):
            local_highs = _find_local_pivots(df, 5, "high")
            for lh in local_highs[-3:]:
                if lh > current_price:
                    levels.append({"price": lh, "type": "local_high"})
        
        # æ•´æ•°å…³å£
        if sources.get("round_numbers", True):
            round_levels = _find_round_numbers(current_price, side="short")
            for rl in round_levels:
                levels.append({"price": rl, "type": "round_number"})
    
    if not levels:
        return {"nearest_level": 0, "distance_pct": 999, "level_type": "none", "bonus": 0, "all_levels": []}
    
    # æ‰¾æœ€è¿‘çš„æ”¯æ’‘/é˜»åŠ›ä½
    if side == "long":
        valid_levels = [l for l in levels if l["price"] < current_price]
        if valid_levels:
            nearest = max(valid_levels, key=lambda x: x["price"])
        else:
            nearest = min(levels, key=lambda x: abs(x["price"] - current_price))
    else:
        valid_levels = [l for l in levels if l["price"] > current_price]
        if valid_levels:
            nearest = min(valid_levels, key=lambda x: x["price"])
        else:
            nearest = min(levels, key=lambda x: abs(x["price"] - current_price))
    
    distance_pct = abs(current_price - nearest["price"]) / current_price if current_price > 0 else 999
    
    # è®¡ç®—è¯„åˆ†åŠ æˆ
    scoring = sr_cfg.get("scoring", {})
    if distance_pct <= scoring.get("distance_very_close", 0.005):
        bonus = scoring.get("bonus_very_close", 0.15)
    elif distance_pct <= scoring.get("distance_close", 0.01):
        bonus = scoring.get("bonus_close", 0.10)
    elif distance_pct <= scoring.get("distance_near", 0.02):
        bonus = scoring.get("bonus_near", 0.05)
    else:
        bonus = 0
    
    # å¤šé‡æ”¯æ’‘åŠ æˆ
    cluster_threshold = sr_cfg.get("detection", {}).get("cluster_threshold", 0.01)
    nearby_count = sum(1 for l in levels if abs(l["price"] - nearest["price"]) / current_price < cluster_threshold)
    if nearby_count >= 2:
        bonus += scoring.get("multi_support_bonus", 0.05)
    
    return {
        "nearest_level": nearest["price"],
        "distance_pct": distance_pct,
        "level_type": nearest["type"],
        "bonus": min(bonus, 0.20),
        "all_levels": levels
    }


def _find_local_pivots(df: pd.DataFrame, periods: int, pivot_type: str) -> List[float]:
    """æ‰¾å±€éƒ¨é«˜ç‚¹æˆ–ä½ç‚¹"""
    pivots = []
    col = "high" if pivot_type == "high" else "low"
    values = df[col].values
    
    for i in range(periods, len(values) - periods):
        if pivot_type == "high":
            if all(values[i] >= values[i-j] for j in range(1, periods+1)) and \
               all(values[i] >= values[i+j] for j in range(1, min(periods+1, len(values)-i))):
                pivots.append(float(values[i]))
        else:
            if all(values[i] <= values[i-j] for j in range(1, periods+1)) and \
               all(values[i] <= values[i+j] for j in range(1, min(periods+1, len(values)-i))):
                pivots.append(float(values[i]))
    
    return pivots


def _find_round_numbers(price: float, side: str) -> List[float]:
    """æ‰¾æ•´æ•°å…³å£"""
    levels = []
    
    if price >= 1000:
        step = 100
    elif price >= 100:
        step = 10
    elif price >= 10:
        step = 1
    elif price >= 1:
        step = 0.1
    else:
        step = 0.01
    
    base = round(price / step) * step
    
    if side == "long":
        for i in range(1, 4):
            level = base - i * step
            if level > 0 and level < price:
                levels.append(level)
    else:
        for i in range(1, 4):
            level = base + i * step
            if level > price:
                levels.append(level)
    
    return levels


# ============ Kçº¿å½¢æ€è¯†åˆ« ============
def detect_candlestick_patterns(df: pd.DataFrame, side: str) -> Dict:
    """è¯†åˆ«Kçº¿å½¢æ€"""
    patterns = []
    
    if len(df) < 5:
        return {"patterns": [], "bonus": 0}
    
    o = df["open"].values[-5:]
    h = df["high"].values[-5:]
    l = df["low"].values[-5:]
    c = df["close"].values[-5:]
    
    body = np.abs(c - o)
    upper_shadow = h - np.maximum(o, c)
    lower_shadow = np.minimum(o, c) - l
    total_range = h - l
    
    # é¿å…é™¤é›¶
    total_range = np.where(total_range == 0, 0.0001, total_range)
    body = np.where(body == 0, 0.0001, body)
    
    if side == "long":
        # é”¤å­çº¿
        if body[-1] < total_range[-1] * 0.3 and lower_shadow[-1] > body[-1] * 2:
            patterns.append("hammer")
        
        # çœ‹æ¶¨åæ²¡
        if c[-2] < o[-2] and c[-1] > o[-1]:
            if c[-1] > o[-2] and o[-1] < c[-2]:
                patterns.append("bullish_engulfing")
        
        # æ—©æ™¨ä¹‹æ˜Ÿ
        if c[-3] < o[-3] and body[-2] < body[-3] * 0.5:
            if c[-1] > o[-1] and c[-1] > (o[-3] + c[-3]) / 2:
                patterns.append("morning_star")
    
    else:  # side == "short"
        # å°„å‡»ä¹‹æ˜Ÿ
        if body[-1] < total_range[-1] * 0.3 and upper_shadow[-1] > body[-1] * 2:
            patterns.append("shooting_star")
        
        # çœ‹è·Œåæ²¡
        if c[-2] > o[-2] and c[-1] < o[-1]:
            if o[-1] > c[-2] and c[-1] < o[-2]:
                patterns.append("bearish_engulfing")
        
        # é»„æ˜ä¹‹æ˜Ÿ
        if c[-3] > o[-3] and body[-2] < body[-3] * 0.5:
            if c[-1] < o[-1] and c[-1] < (o[-3] + c[-3]) / 2:
                patterns.append("evening_star")
    
    bonus = min(len(patterns) * 0.06, 0.12)
    
    return {"patterns": patterns, "bonus": bonus}


# ============ æˆäº¤é‡ç»“æ„åˆ†æ ============
def analyze_volume_structure(df: pd.DataFrame, side: str) -> Dict:
    """åˆ†ææˆäº¤é‡ç»“æ„"""
    if len(df) < 30:
        return {"structure": "unknown", "bonus": 0, "details": {}}
    
    vol = df["volume"].values
    close = df["close"].values
    
    vol_ma = np.mean(vol[-20:])
    
    recent_vol = vol[-10:]
    recent_close = close[-10:]
    
    up_bars = []
    down_bars = []
    for i in range(1, len(recent_close)):
        if recent_close[i] > recent_close[i-1]:
            up_bars.append(recent_vol[i])
        else:
            down_bars.append(recent_vol[i])
    
    avg_up_vol = np.mean(up_bars) if up_bars else 0
    avg_down_vol = np.mean(down_bars) if down_bars else 0
    
    is_dry_volume = vol[-1] < vol_ma * 0.5
    is_volume_spike = vol[-1] > vol_ma * 1.5
    
    bonus = 0
    structure = "neutral"
    
    if side == "long":
        if avg_down_vol > 0 and avg_up_vol > avg_down_vol * 1.2:
            structure = "bullish_accumulation"
            bonus = 0.06
        
        if is_dry_volume:
            structure = "dry_volume"
            bonus = 0.04
        elif is_volume_spike and recent_close[-1] > recent_close[-2]:
            structure = "bullish_breakout"
            bonus = 0.08
        
        if avg_down_vol > avg_up_vol * 1.5 and recent_close[-1] < recent_close[0]:
            structure = "panic_selling"
            bonus = -0.05
    
    else:
        if avg_up_vol > 0 and avg_down_vol > avg_up_vol * 1.2:
            structure = "bearish_distribution"
            bonus = 0.06
        
        if is_volume_spike and recent_close[-1] < recent_close[-2]:
            structure = "bearish_breakout"
            bonus = 0.08
        
        if avg_up_vol > avg_down_vol * 1.5 and recent_close[-1] > recent_close[0]:
            structure = "strong_buying"
            bonus = -0.05
    
    return {
        "structure": structure,
        "bonus": bonus,
        "details": {
            "avg_up_vol": avg_up_vol,
            "avg_down_vol": avg_down_vol,
            "is_dry_volume": is_dry_volume,
            "is_volume_spike": is_volume_spike
        }
    }


# ============ å¤šæ—¶é—´æ¡†æ¶åˆ†æ ============
def fetch_multi_timeframe_data(ex, symbol: str, timeframes: List[str] = None) -> Dict[str, pd.DataFrame]:
    """è·å–å¤šæ—¶é—´æ¡†æ¶Kçº¿æ•°æ®"""
    global _MTF_KLINE_CACHE
    
    if timeframes is None:
        timeframes = ["5m", "15m", "1h"]
    
    now = time.time()
    result = {}
    
    for tf in timeframes:
        cache_key = f"{symbol}_{tf}"
        
        if cache_key in _MTF_KLINE_CACHE:
            cached = _MTF_KLINE_CACHE[cache_key]
            if now - cached["ts"] < _MTF_CACHE_TTL:
                result[tf] = cached["data"]
                continue
        
        try:
            limit = 100
            raw = ex.fetch_ohlcv(symbol, timeframe=tf, limit=limit)
            if raw and len(raw) > 20:
                df = pd.DataFrame(raw, columns=["ts", "open", "high", "low", "close", "volume"])
                df["ts"] = pd.to_datetime(df["ts"], unit="ms", utc=True)
                result[tf] = df
                _MTF_KLINE_CACHE[cache_key] = {"data": df, "ts": now}
        except Exception as e:
            print(f"[MTF] {symbol} {tf} è·å–å¤±è´¥: {e}")
    
    return result


def analyze_multi_timeframe(ex, symbol: str, df_1m: pd.DataFrame, side: str, cfg: Dict) -> Dict:
    """å¤šæ—¶é—´æ¡†æ¶åˆ†æ"""
    mtf_cfg = cfg.get("trend_anticipation", {}).get("multi_timeframe", {})
    if not mtf_cfg.get("enabled", True):
        return {"confirm_count": 0, "bonus": 0, "details": {}}
    
    timeframes = mtf_cfg.get("timeframes", ["5m", "15m", "1h"])
    timeframes = [tf for tf in timeframes if tf != "1m"]  # æ’é™¤1mï¼Œç”¨ä¼ å…¥çš„df_1m
    
    mtf_data = fetch_multi_timeframe_data(ex, symbol, timeframes)
    
    confirm_count = 0
    details = {}
    
    # å…ˆåˆ†æ1m
    if len(df_1m) >= 30:
        rsi_1m = _calc_rsi(df_1m, 14)
        confirmed_1m = (side == "long" and rsi_1m < 45) or (side == "short" and rsi_1m > 55)
        details["1m"] = {"rsi": rsi_1m, "confirmed": confirmed_1m}
        if confirmed_1m:
            confirm_count += 1
    
    for tf in timeframes:
        if tf not in mtf_data or mtf_data[tf] is None:
            continue
        
        df_tf = mtf_data[tf]
        if len(df_tf) < 30:
            continue
        
        rsi_val = _calc_rsi(df_tf, 14)
        
        confirmed = False
        if side == "long" and rsi_val < 45:
            confirmed = True
        elif side == "short" and rsi_val > 55:
            confirmed = True
        
        details[tf] = {"rsi": rsi_val, "confirmed": confirmed}
        
        if confirmed:
            confirm_count += 1
    
    weights = mtf_cfg.get("weights", {"1m": 0.15, "5m": 0.25, "15m": 0.30, "1h": 0.30})
    weighted_bonus = sum(weights.get(tf, 0) for tf, d in details.items() if d.get("confirmed", False))
    
    max_bonus = cfg.get("trend_anticipation", {}).get("scoring", {}).get("max_mtf_bonus", 0.15)
    bonus = min(weighted_bonus * 0.5, max_bonus)
    
    return {
        "confirm_count": confirm_count,
        "bonus": bonus,
        "details": details
    }


def _calc_rsi(df: pd.DataFrame, period: int = 14) -> float:
    """è®¡ç®—RSI"""
    delta = df["close"].diff()
    gain = delta.where(delta > 0, 0).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    val = float(rsi.iloc[-1])
    return val if not np.isnan(val) else 50.0


# ============ ä¿¡å·å»é‡å™¨ ============
class SignalDeduplicator:
    """ä¿¡å·å»é‡å™¨"""
    
    def __init__(self, cfg: Dict):
        dedup_cfg = cfg.get("signal_dedup", {})
        self.enabled = dedup_cfg.get("enabled", True)
        self.cooldown_minutes = dedup_cfg.get("cooldown_minutes", 30)  # ğŸ”¥ v7.9.4: 45 -> 30åˆ†é’Ÿ æ”¾å®½
        self.priority = dedup_cfg.get("priority", {
            "trend_anticipation": 4,
            "reversal": 3,
            "trend_explosion": 2,
            "trend_continuation": 1
        })
        self.replace_rules = dedup_cfg.get("replace_rules", {})
    
    def should_emit(self, symbol: str, signal_type: str, score: float, side: str) -> Tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘å‡ºä¿¡å·"""
        global _SIGNAL_DEDUP_CACHE
        
        if not self.enabled:
            return True, "å»é‡ç¦ç”¨"
        
        now = dt.datetime.now()
        
        if symbol not in _SIGNAL_DEDUP_CACHE:
            self._record_signal(symbol, signal_type, score, side)
            return True, "é¦–ä¸ªä¿¡å·"
        
        existing = _SIGNAL_DEDUP_CACHE[symbol]
        time_since = (now - existing["timestamp"]).total_seconds() / 60
        
        # å†·å´æœŸå·²è¿‡
        if time_since >= self.cooldown_minutes:
            self._record_signal(symbol, signal_type, score, side)
            return True, f"å†·å´æœŸå·²è¿‡({time_since:.0f}åˆ†é’Ÿ)"
        
        # å…è®¸ç›¸åæ–¹å‘
        if self.replace_rules.get("allow_opposite_side", True):
            if side != existing["side"]:
                self._record_signal(symbol, signal_type, score, side)
                return True, f"ç›¸åæ–¹å‘({existing['side']}â†’{side})"
        
        # æ£€æŸ¥ä¼˜å…ˆçº§
        new_priority = self.priority.get(signal_type, 0)
        existing_priority = self.priority.get(existing["signal_type"], 0)
        
        if self.replace_rules.get("higher_priority_always", True):
            if new_priority > existing_priority:
                self._record_signal(symbol, signal_type, score, side)
                return True, f"æ›´é«˜ä¼˜å…ˆçº§({existing['signal_type']}â†’{signal_type})"
        
        # åŒä¼˜å…ˆçº§æ£€æŸ¥è¯„åˆ†
        score_diff = self.replace_rules.get("same_priority_score_diff", 0.05)
        if new_priority == existing_priority and score > existing["score"] + score_diff:
            self._record_signal(symbol, signal_type, score, side)
            return True, f"æ›´é«˜è¯„åˆ†({existing['score']:.2f}â†’{score:.2f})"
        
        return False, f"å†·å´ä¸­({time_since:.0f}/{self.cooldown_minutes}åˆ†é’Ÿ)"
    
    def _record_signal(self, symbol: str, signal_type: str, score: float, side: str):
        """è®°å½•ä¿¡å·"""
        global _SIGNAL_DEDUP_CACHE
        _SIGNAL_DEDUP_CACHE[symbol] = {
            "signal_type": signal_type,
            "score": score,
            "side": side,
            "timestamp": dt.datetime.now()
        }
    
    def clear_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        global _SIGNAL_DEDUP_CACHE
        now = dt.datetime.now()
        expired = [
            sym for sym, data in _SIGNAL_DEDUP_CACHE.items()
            if (now - data["timestamp"]).total_seconds() / 60 > self.cooldown_minutes * 2
        ]
        for sym in expired:
            del _SIGNAL_DEDUP_CACHE[sym]


# ============ è¶‹åŠ¿é¢„åˆ¤ä¿¡å·æ£€æµ‹ ============
def detect_trend_anticipation(
    cfg: Dict,
    ex,
    symbol: str,
    df: pd.DataFrame,
    btc_status: Dict,
    metrics: Dict,
    correlation_analysis: Optional[Dict] = None
) -> Optional[Dict]:
    """
    è¶‹åŠ¿é¢„åˆ¤ä¿¡å·æ£€æµ‹
    
    ğŸ”¥ v7.9: æ”¶ç´§æ¡ä»¶ï¼Œå¢åŠ BTCæš´è·Œä¿æŠ¤
    
    Returns:
        ä¿¡å·å­—å…¸æˆ–None
    """
    ta_cfg = cfg.get("trend_anticipation", {})
    if not ta_cfg.get("enabled", False):
        return None
    
    rsi_val = metrics.get("rsi", 50)
    adx_val = metrics.get("adx", 0)
    macd_hist = metrics.get("macd_histogram", 0)
    vol_spike = metrics.get("vol_spike_ratio", 1.0)
    current_price = float(df["close"].iloc[-1])
    
    # ğŸ”¥ v7.9: æå‰è·å–BTCçŠ¶æ€ç”¨äºæ—©æœŸè¿‡æ»¤
    btc_change_1h = btc_status.get("price_change_1h", 0) if btc_status else 0
    
    # ========== ç¬¬ä¸€æ­¥ï¼šåˆ¤æ–­æ–¹å‘ï¼ˆåŸºäºRSIåŒºé—´ï¼‰==========
    # ğŸ”¥ v7.9.3: å¤§å¹…æ”¶çª„RSIåŒºé—´
    # åè½¬åšå¤š: RSI â‰¤ 15  |  è¶‹åŠ¿é¢„åˆ¤åšå¤š: RSI 12-20
    # åè½¬åšç©º: RSI â‰¥ 85  |  è¶‹åŠ¿é¢„åˆ¤åšç©º: RSI 80-88
    side = None
    
    long_cfg = ta_cfg.get("long_conditions", {})
    long_rsi_range = long_cfg.get("rsi_range", [15, 25])  # ğŸ”¥ğŸ”¥ğŸ”¥ v7.9.4: [12,20] -> [15,25] æ”¾å®½
    if long_rsi_range[0] <= rsi_val <= long_rsi_range[1]:
        side = "long"
    
    short_cfg = ta_cfg.get("short_conditions", {})
    short_rsi_range = short_cfg.get("rsi_range", [75, 85])  # ğŸ”¥ğŸ”¥ğŸ”¥ v7.9.4: [80,88] -> [75,85] æ”¾å®½
    if short_rsi_range[0] <= rsi_val <= short_rsi_range[1]:
        side = "short"
    
    if side is None:
        return None
    
    # ========== ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥å¤šä¸ªæ¡ä»¶ï¼ˆè‡³å°‘æ»¡è¶³4ä¸ªï¼‰==========
    conditions_met = []
    conditions_failed = []
    
    # æ¡ä»¶1: RSIåœ¨é¢„åˆ¤åŒºé—´ï¼ˆå·²æ»¡è¶³ï¼Œå› ä¸ºsideä¸æ˜¯Noneï¼‰
    conditions_met.append("RSIé¢„åˆ¤åŒºé—´")
    
    # æ¡ä»¶2: MACDæŸ±çŠ¶å›¾ç¼©çŸ­ï¼ˆè¶‹åŠ¿å‡é€Ÿï¼‰
    macd_shrinking = False
    if len(df) >= 5:
        # è·å–æœ€è¿‘5æ ¹Kçº¿çš„MACDæŸ±çŠ¶å›¾
        close_vals = df["close"].values[-6:]
        price_changes = [close_vals[i+1] - close_vals[i] for i in range(len(close_vals)-1)]
        
        if side == "long":
            # åšå¤šï¼šä¸‹è·ŒåŠ¨èƒ½å‡å¼±ï¼ˆè´Ÿå˜åŒ–åœ¨å˜å°ï¼Œå³ç»å¯¹å€¼å‡å°æˆ–å˜æ­£ï¼‰
            if len(price_changes) >= 3:
                # æ£€æŸ¥æœ€è¿‘3æ ¹æ˜¯å¦æœ‰æ”¹å–„è¶‹åŠ¿
                if price_changes[-1] > price_changes[-2] or price_changes[-1] > price_changes[-3]:
                    macd_shrinking = True
        else:
            # åšç©ºï¼šä¸Šæ¶¨åŠ¨èƒ½å‡å¼±ï¼ˆæ­£å˜åŒ–åœ¨å˜å°ï¼Œå³ç»å¯¹å€¼å‡å°æˆ–å˜è´Ÿï¼‰
            if len(price_changes) >= 3:
                if price_changes[-1] < price_changes[-2] or price_changes[-1] < price_changes[-3]:
                    macd_shrinking = True
    
    if macd_shrinking:
        conditions_met.append("åŠ¨èƒ½å‡é€Ÿ")
    else:
        # ğŸ”¥ğŸ”¥ v1.1: åŠ¨èƒ½æœªå‡å¼±æ˜¯ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦æ›´å¤šå…¶ä»–æ¡ä»¶è¡¥å¿
        conditions_failed.append("åŠ¨èƒ½æœªå‡é€Ÿâš ï¸")
    
    # æ¡ä»¶3: ä»·æ ¼æ¥è¿‘æ”¯æ’‘ä½/é˜»åŠ›ä½ï¼ˆ<2%ï¼‰
    sr_result = detect_support_resistance(df, cfg, side, current_price)
    near_support = sr_result.get("distance_pct", 999) < 0.02  # 2%ä»¥å†…
    
    if near_support:
        conditions_met.append(f"æ¥è¿‘æ”¯æ’‘({sr_result.get('distance_pct', 0)*100:.1f}%)")
    else:
        conditions_failed.append(f"è¿œç¦»æ”¯æ’‘({sr_result.get('distance_pct', 0)*100:.1f}%)")
    
    # æ¡ä»¶4: BTCä¼ç¨³æˆ–åŒå‘
    btc_ok = False
    btc_crashing = False  # ğŸ”¥ æ–°å¢ï¼šBTCæ˜¯å¦åœ¨æš´è·Œ
    if btc_status:
        btc_change_1h = btc_status.get("price_change_1h", 0)
        btc_cfg = ta_cfg.get("btc_analysis", {})
        # ğŸ”¥ æ³¨æ„ï¼šprice_change_1h å·²ç»æ˜¯ç™¾åˆ†æ¯”å½¢å¼ï¼Œå¦‚ -0.18 è¡¨ç¤º -0.18%
        stabilizing_threshold = btc_cfg.get("btc_stabilizing_threshold", 0.3)  # ğŸ”¥ 0.3%
        
        # ğŸ”¥ æ£€æŸ¥BTCæ˜¯å¦åœ¨æš´è·Œï¼ˆ1hè·Œå¹…>1%ï¼‰
        if btc_change_1h < -1.0:  # ğŸ”¥ ä¿®å¤ï¼š-1.0 è¡¨ç¤º -1%
            btc_crashing = True
        
        # BTCä¼ç¨³ï¼ˆæ³¢åŠ¨<0.3%ï¼‰
        if abs(btc_change_1h) < stabilizing_threshold:
            btc_ok = True
        # æˆ–è€…BTCåŒå‘
        elif (side == "long" and btc_change_1h > 0) or (side == "short" and btc_change_1h < 0):
            btc_ok = True
        # BTCæš´è·Œæ—¶ä¸åšå¤šé¢„åˆ¤
        if btc_cfg.get("require_btc_not_crashing", True):
            if side == "long" and btc_change_1h < -2.0:  # ğŸ”¥ ä¿®å¤ï¼š-2.0 è¡¨ç¤º -2%
                btc_ok = False
    else:
        btc_ok = True  # æ— BTCæ•°æ®æ—¶é»˜è®¤é€šè¿‡
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ v7.9: BTCæš´è·Œæ—¶ç›´æ¥æ‹’ç»åšå¤šä¿¡å·
    if side == "long" and btc_crashing:
        print(f"[TREND_ANTICIPATION] âŒ {symbol} BTCæš´è·Œä¸­(1h:{btc_change_1h:.2f}%)ï¼Œæ‹’ç»åšå¤šé¢„åˆ¤")
        return None
    
    if btc_ok:
        conditions_met.append("BTCæ”¯æŒ")
    else:
        conditions_failed.append("BTCä¸æ”¯æŒ")
    
    # æ¡ä»¶5: æˆäº¤é‡ï¼ˆé™ä½è¦æ±‚åˆ°1.0xï¼Œä½†ç¼©é‡å¤ªä¸¥é‡è¦æ‰£åˆ†ï¼‰
    vol_ok = vol_spike >= 1.0
    if vol_ok:
        conditions_met.append(f"é‡èƒ½({vol_spike:.1f}x)")
    else:
        conditions_failed.append(f"ç¼©é‡({vol_spike:.1f}x)")
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ v7.9.4: æˆäº¤é‡å¤ªä½ç›´æ¥æ‹’ç»ï¼ˆæ”¾å®½åˆ°0.8xï¼‰
    min_vol = ta_cfg.get("hard_filter", {}).get("min_volume_ratio", 0.8)  # ğŸ”¥ v7.9.4: 1.0->0.8 æ”¾å®½
    if vol_spike < min_vol:
        print(f"[TREND_ANTICIPATION] âŒ {symbol} æˆäº¤é‡å¤ªä½({vol_spike:.1f}x<{min_vol}x)ï¼Œæ‹’ç»")
        return None
    
    # æ¡ä»¶6: ADXæ˜¾ç¤ºæœ‰è¶‹åŠ¿ï¼ˆğŸ”¥ğŸ”¥ v7.9.4æ”¾å®½åˆ°22ï¼‰
    min_adx = ta_cfg.get("hard_filter", {}).get("min_adx", 22)  # ğŸ”¥ v7.9.4: 28->22 æ”¾å®½
    adx_ok = adx_val >= min_adx
    if adx_ok:
        conditions_met.append(f"æœ‰è¶‹åŠ¿(ADX{adx_val:.0f})")
    else:
        conditions_failed.append(f"æ— è¶‹åŠ¿(ADX{adx_val:.0f}<{min_adx})")
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ æ¡ä»¶7: è“„åŠ¿ç¡®è®¤ï¼ˆå¸ƒæ—å¸¦æ”¶çª„ - squeezeï¼‰
    bb_width = metrics.get("bb_width", 0.03)
    bb_squeeze = bb_width < 0.025  # å¸ƒæ—å¸¦å®½åº¦å°äº2.5%è¡¨ç¤ºè“„åŠ¿
    if bb_squeeze:
        conditions_met.append(f"è“„åŠ¿ä¸­(BB{bb_width*100:.1f}%)")
    else:
        conditions_failed.append(f"æœªè“„åŠ¿(BB{bb_width*100:.1f}%)")
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ æ¡ä»¶8: å¯åŠ¨ä¿¡å·æ£€æµ‹ï¼ˆä»·æ ¼çªç ´+æ”¾é‡ï¼‰
    startup_confirmed = False
    startup_details = []
    
    if len(df) >= 10:
        prices = df['close'].values
        volumes = df['volume'].values
        highs = df['high'].values
        lows = df['low'].values
        
        # æœ€è¿‘5æ ¹Kçº¿çš„é«˜ä½ç‚¹
        recent_high_5 = max(highs[-6:-1])
        recent_low_5 = min(lows[-6:-1])
        current_close = prices[-1]
        
        # æˆäº¤é‡å¯¹æ¯”
        vol_now = volumes[-1]
        vol_recent_avg = np.mean(volumes[-6:-1])
        vol_spike_sudden = vol_now > vol_recent_avg * 1.5
        
        if side == "long":
            # åšå¤šï¼šä»·æ ¼çªç ´å‰5æ ¹é«˜ç‚¹
            price_breakout = current_close > recent_high_5
            if price_breakout:
                startup_details.append("çªç ´å‰é«˜")
            if vol_spike_sudden:
                startup_details.append("æ”¾é‡å¯åŠ¨")
        else:
            # åšç©ºï¼šä»·æ ¼è·Œç ´å‰5æ ¹ä½ç‚¹
            price_breakout = current_close < recent_low_5
            if price_breakout:
                startup_details.append("çªç ´å‰ä½")
            if vol_spike_sudden:
                startup_details.append("æ”¾é‡å¯åŠ¨")
        
        # æ»¡è¶³çªç ´+æ”¾é‡ = å¯åŠ¨ç¡®è®¤
        if price_breakout and vol_spike_sudden:
            startup_confirmed = True
    
    if startup_confirmed:
        conditions_met.append(f"å¯åŠ¨ç¡®è®¤({','.join(startup_details)})")
    # å¯åŠ¨ä¸æ˜¯å¿…è¦æ¡ä»¶ï¼Œåªæ˜¯åŠ åˆ†é¡¹
    
    # ========== ğŸ”¥v2.0æ–°å¢ï¼šè¶‹åŠ¿è´¨é‡æ£€æµ‹ ==========
    trend_quality_result = None
    fdi_value = 1.25  # é»˜è®¤ä¸­æ€§
    is_smart_money = False
    
    try:
        # è®¡ç®—FDIåˆ†å½¢ç»´æ•°
        fdi_value = _calculate_fdi(df)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ FDIè¿‡æ»¤ï¼šè¶‹åŠ¿å¤ªå˜ˆæ‚ç›´æ¥æ‹’ç»
        if fdi_value >= 1.45:
            print(f"[TREND_ANTICIPATION] âš ï¸ {symbol} FDI={fdi_value:.3f} è¿‡é«˜ï¼Œè¶‹åŠ¿å¤ªå˜ˆæ‚ï¼Œè·³è¿‡")
            return None
        
        # è®¡ç®—èªæ˜é’±æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰OIæ•°æ®ï¼‰
        oi_change = metrics.get("oi_change", 0)
        volume_24h = metrics.get("volume_24h", 1)
        
        if oi_change != 0:
            price_change = (current_price - float(df['close'].iloc[-20])) / float(df['close'].iloc[-20]) if len(df) >= 20 else 0
            sm_result = _analyze_smart_money(price_change, oi_change, volume_24h)
            is_smart_money = sm_result.get("is_smart_money", False)
            
            # å¦‚æœä¸æ˜¯èªæ˜é’±æ¨åŠ¨ä¸”FDIåé«˜ï¼Œé™ä½ä¿¡å·è´¨é‡
            if not is_smart_money and fdi_value >= 1.35:
                print(f"[TREND_ANTICIPATION] âš ï¸ {symbol} éèªæ˜é’±+FDIåé«˜ï¼Œä¿¡å·è´¨é‡é™ä½")
        
        # è®¡ç®—ç»¼åˆè¶‹åŠ¿è´¨é‡
        trend_quality_result = {
            "fdi": fdi_value,
            "is_smart_money": is_smart_money,
            "trend_quality": "strong" if fdi_value < 1.25 else "moderate" if fdi_value < 1.35 else "weak"
        }
        
    except Exception as e:
        print(f"[TREND_ANTICIPATION] è¶‹åŠ¿è´¨é‡è®¡ç®—å¼‚å¸¸: {e}")
    
    # ========== ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æ˜¯å¦æ»¡è¶³è‡³å°‘3ä¸ªæ¡ä»¶ï¼ˆğŸ”¥v7.9.4æ”¾å®½ï¼‰==========
    min_conditions = 3  # ğŸ”¥ v7.9.4: 4->3 æ”¾å®½
    if len(conditions_met) < min_conditions:
        # ä¸æ»¡è¶³æœ€ä½æ¡ä»¶æ•°ï¼Œä¸å‘ä¿¡å·
        return None
    
    # ========== ç¬¬å››æ­¥ï¼šè®¡ç®—è¯„åˆ† ==========
    scoring_cfg = ta_cfg.get("scoring", {})
    base_score = scoring_cfg.get("base_score", 0.55)
    
    # 1. æ”¯æ’‘ä½åŠ æˆ
    support_bonus = sr_result.get("bonus", 0)
    
    # 2. Kçº¿å½¢æ€åŠ æˆ
    pattern_result = detect_candlestick_patterns(df, side)
    pattern_bonus = pattern_result.get("bonus", 0)
    
    # 3. æˆäº¤é‡ç»“æ„åŠ æˆ
    volume_result = analyze_volume_structure(df, side)
    volume_bonus = volume_result.get("bonus", 0)
    
    # 4. å¤šæ—¶é—´æ¡†æ¶åŠ æˆ
    mtf_result = analyze_multi_timeframe(ex, symbol, df, side, cfg)
    mtf_bonus = mtf_result.get("bonus", 0)
    
    # 5. BTCè”åŠ¨åŠ æˆ
    btc_bonus = 0
    if btc_ok and btc_status:
        btc_change_1h = btc_status.get("price_change_1h", 0)
        if abs(btc_change_1h) < 0.003:
            btc_bonus += 0.03
        if (side == "long" and btc_change_1h > 0) or (side == "short" and btc_change_1h < 0):
            btc_bonus += 0.05
    btc_bonus = min(btc_bonus, scoring_cfg.get("max_btc_bonus", 0.10))
    
    # 6. æ¡ä»¶æ»¡è¶³æ•°åŠ æˆï¼ˆæ»¡è¶³è¶Šå¤šåˆ†è¶Šé«˜ï¼Œä½†è®¾ç½®ä¸Šé™ï¼‰
    condition_bonus = (len(conditions_met) - min_conditions) * 0.03
    condition_bonus = min(condition_bonus, 0.06)
    
    # ğŸ”¥ 7. è“„åŠ¿åŠ æˆ
    squeeze_bonus = 0.05 if bb_squeeze else 0
    
    # ğŸ”¥ 8. å¯åŠ¨ç¡®è®¤åŠ æˆ
    startup_bonus = 0.08 if startup_confirmed else 0
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ v2.0æ–°å¢: 9. FDIè¶‹åŠ¿çº¯åº¦åŠ æˆ/æ‰£åˆ†
    fdi_bonus = 0
    if fdi_value < 1.20:
        fdi_bonus = 0.08  # éå¸¸çº¯å‡€çš„è¶‹åŠ¿
        conditions_met.append(f"FDIä¼˜ç§€({fdi_value:.2f})")
    elif fdi_value < 1.30:
        fdi_bonus = 0.04  # è‰¯å¥½è¶‹åŠ¿
        conditions_met.append(f"FDIè‰¯å¥½({fdi_value:.2f})")
    elif fdi_value >= 1.40:
        fdi_bonus = -0.05  # å˜ˆæ‚è¶‹åŠ¿æ‰£åˆ†
        conditions_failed.append(f"FDIåé«˜({fdi_value:.2f})")
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ v2.0æ–°å¢: 10. èªæ˜é’±åŠ æˆ
    smart_money_bonus = 0
    if is_smart_money:
        smart_money_bonus = 0.06
        conditions_met.append("èªæ˜é’±æ¨åŠ¨")
    
    # è®¡ç®—æ€»åˆ†
    total_score = (
        base_score +
        min(support_bonus, scoring_cfg.get("max_support_bonus", 0.15)) +
        min(pattern_bonus, scoring_cfg.get("max_pattern_bonus", 0.12)) +
        min(volume_bonus, scoring_cfg.get("max_volume_bonus", 0.10)) +
        min(mtf_bonus, scoring_cfg.get("max_mtf_bonus", 0.15)) +
        btc_bonus +
        condition_bonus +
        squeeze_bonus +
        startup_bonus +
        fdi_bonus +
        smart_money_bonus
    )
    
    total_score = min(total_score, 1.0)
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å‘å‡ºä¿¡å·çš„é—¨æ§›ï¼ˆğŸ”¥ğŸ”¥ğŸ”¥ v7.9.4æ”¾å®½åˆ°0.75ï¼‰
    min_score = scoring_cfg.get("min_score_to_emit", 0.75)  # ğŸ”¥ v7.9.4: 0.85->0.75 æ”¾å®½
    if total_score < min_score:
        return None
    
    # ========== ç¬¬äº”æ­¥ï¼šè®¡ç®—æ­¢æŸæ­¢ç›ˆ ==========
    risk_cfg = ta_cfg.get("risk", {})
    sl_pct = risk_cfg.get("sl_pct", 0.02)
    tp_pct = risk_cfg.get("tp_pct", 0.06)
    
    # ä½¿ç”¨æ”¯æ’‘ä½ä½œä¸ºæ­¢æŸå‚è€ƒ
    if risk_cfg.get("use_support_as_sl", True) and sr_result.get("nearest_level", 0) > 0:
        support_price = sr_result["nearest_level"]
        buffer = risk_cfg.get("sl_buffer_below_support", 0.005)
        
        if side == "long":
            sl_price = support_price * (1 - buffer)
            max_sl_price = current_price * (1 - sl_pct)
            sl_price = max(sl_price, max_sl_price)
        else:
            sl_price = support_price * (1 + buffer)
            min_sl_price = current_price * (1 + sl_pct)
            sl_price = min(sl_price, min_sl_price)
    else:
        if side == "long":
            sl_price = current_price * (1 - sl_pct)
        else:
            sl_price = current_price * (1 + sl_pct)
    
    if side == "long":
        tp_price = current_price * (1 + tp_pct)
    else:
        tp_price = current_price * (1 - tp_pct)
    
    # ========== è¾“å‡ºæ—¥å¿— ==========
    # ä½¿ç”¨å®é™…è®¡ç®—æ—¶çš„é™åˆ¶å€¼
    actual_support_bonus = min(support_bonus, scoring_cfg.get("max_support_bonus", 0.15))
    actual_pattern_bonus = min(pattern_bonus, scoring_cfg.get("max_pattern_bonus", 0.12))
    actual_volume_bonus = min(volume_bonus, scoring_cfg.get("max_volume_bonus", 0.10))
    actual_mtf_bonus = min(mtf_bonus, scoring_cfg.get("max_mtf_bonus", 0.15))
    
    print(f"[TREND_ANTICIPATION] ğŸ”® {symbol} é¢„åˆ¤ä¿¡å·: {side.upper()}")
    print(f"[TREND_ANTICIPATION]    è¯„åˆ†: {total_score:.2f} | RSI: {rsi_val:.1f} | ADX: {adx_val:.1f}")
    # ğŸ”¥ v2.0: æ·»åŠ FDIå’Œèªæ˜é’±æ—¥å¿—
    fdi_status = "ä¼˜ç§€" if fdi_value < 1.25 else "è‰¯å¥½" if fdi_value < 1.35 else "ä¸€èˆ¬" if fdi_value < 1.45 else "å·®"
    sm_status = "âœ…" if is_smart_money else "âŒ"
    print(f"[TREND_ANTICIPATION]    ğŸ”¥v2.0: FDI={fdi_value:.3f}({fdi_status}) | èªæ˜é’±:{sm_status}")
    print(f"[TREND_ANTICIPATION]    âœ… æ»¡è¶³æ¡ä»¶({len(conditions_met)}): {', '.join(conditions_met)}")
    if conditions_failed:
        print(f"[TREND_ANTICIPATION]    âŒ æœªæ»¡è¶³: {', '.join(conditions_failed)}")
    print(f"[TREND_ANTICIPATION]    åŠ æˆ: æ”¯æ’‘{actual_support_bonus:.2f} å½¢æ€{actual_pattern_bonus:.2f} é‡èƒ½{actual_volume_bonus:.2f} MTF{actual_mtf_bonus:.2f} BTC{btc_bonus:.2f} FDI{fdi_bonus:+.2f} SM{smart_money_bonus:.2f}")
    print(f"[TREND_ANTICIPATION]    æ”¯æ’‘ä½: ${sr_result.get('nearest_level', 0):.4f} ({sr_result.get('level_type', 'none')})")
    if pattern_result.get("patterns"):
        print(f"[TREND_ANTICIPATION]    Kçº¿å½¢æ€: {', '.join(pattern_result['patterns'])}")
    
    return {
        "ts": dt.datetime.utcnow().isoformat(),
        "category": "majors",
        "symbol": symbol,
        "price": current_price,
        "entry": current_price,
        "score": float(total_score),
        "bias": side,
        "signal_type": "trend_anticipation",
        "subscores": {
            "support_bonus": support_bonus,
            "pattern_bonus": pattern_bonus,
            "volume_bonus": volume_bonus,
            "mtf_bonus": mtf_bonus,
            "btc_bonus": btc_bonus,
            "fdi_bonus": fdi_bonus,  # ğŸ”¥ v2.0æ–°å¢
            "smart_money_bonus": smart_money_bonus,  # ğŸ”¥ v2.0æ–°å¢
            "conditions_met": len(conditions_met)
        },
        "metrics": metrics,
        # ğŸ”¥ğŸ”¥ğŸ”¥ v2.0æ–°å¢: è¶‹åŠ¿è´¨é‡æŒ‡æ ‡
        "trend_quality": {
            "fdi": fdi_value,
            "fdi_status": "ä¼˜ç§€" if fdi_value < 1.25 else "è‰¯å¥½" if fdi_value < 1.35 else "ä¸€èˆ¬" if fdi_value < 1.45 else "å·®",
            "is_smart_money": is_smart_money,
            "trend_purity": round((1.5 - fdi_value) * 200, 1),  # 0-100åˆ†
        },
        "calculated_stops": {
            "sl_price": sl_price,
            "tp_price": tp_price,
            "sl_pct": abs(current_price - sl_price) / current_price * 100,
            "tp_pct": abs(tp_price - current_price) / current_price * 100,
            "max_leverage": 15,
            "category": "trend_anticipation"
        },
        "btc_status": btc_status,
        "correlation_analysis": correlation_analysis or {},
        "support_analysis": sr_result,
        "pattern_analysis": pattern_result,
        "volume_analysis": volume_result,
        "mtf_analysis": mtf_result,
        "obs_signals": [
            f"RSI{rsi_val:.0f}é¢„åˆ¤",
            sr_result.get("level_type", ""),
            volume_result.get("structure", ""),
            f"æ¡ä»¶{len(conditions_met)}/{len(conditions_met)+len(conditions_failed)}",
            f"FDI{fdi_value:.2f}"  # ğŸ”¥ v2.0æ–°å¢
        ],
        "conditions_met": conditions_met,
        "conditions_failed": conditions_failed,
        "obs_adjustment": 0,
        "pullback_pct": 0
    }


# ============ äº¤æ˜“å†å²ç®¡ç†ï¼ˆç”¨äºAIå­¦ä¹ ï¼‰============
def add_trade_to_history(trade: Dict):
    """æ·»åŠ äº¤æ˜“åˆ°å†å²"""
    global _TRADE_HISTORY
    _TRADE_HISTORY.append(trade)
    # åªä¿ç•™æœ€è¿‘100æ¡
    if len(_TRADE_HISTORY) > 100:
        _TRADE_HISTORY = _TRADE_HISTORY[-100:]


def get_recent_trades(count: int = 10) -> List[Dict]:
    """è·å–æœ€è¿‘çš„äº¤æ˜“è®°å½•"""
    global _TRADE_HISTORY
    return _TRADE_HISTORY[-count:]


def get_trade_statistics() -> Dict:
    """è·å–äº¤æ˜“ç»Ÿè®¡"""
    global _TRADE_HISTORY
    
    if not _TRADE_HISTORY:
        return {"total": 0, "wins": 0, "losses": 0, "win_rate": 0}
    
    wins = sum(1 for t in _TRADE_HISTORY if t.get("result") == "win")
    losses = sum(1 for t in _TRADE_HISTORY if t.get("result") == "loss")
    total = wins + losses
    
    return {
        "total": total,
        "wins": wins,
        "losses": losses,
        "win_rate": wins / total if total > 0 else 0,
        "by_signal_type": _get_stats_by_signal_type()
    }


def _get_stats_by_signal_type() -> Dict:
    """æŒ‰ä¿¡å·ç±»å‹ç»Ÿè®¡"""
    global _TRADE_HISTORY
    
    stats = {}
    for trade in _TRADE_HISTORY:
        st = trade.get("signal_type", "unknown")
        if st not in stats:
            stats[st] = {"wins": 0, "losses": 0}
        
        if trade.get("result") == "win":
            stats[st]["wins"] += 1
        elif trade.get("result") == "loss":
            stats[st]["losses"] += 1
    
    # è®¡ç®—èƒœç‡
    for st in stats:
        total = stats[st]["wins"] + stats[st]["losses"]
        stats[st]["win_rate"] = stats[st]["wins"] / total if total > 0 else 0
    
    return stats


# ============ ğŸ”¥ğŸ”¥ğŸ”¥ v2.1æ–°å¢: ç‹¬ç«‹åˆ†æå‡½æ•° - ä¾›é«˜æ³¢åŠ¨è½¨é“è°ƒç”¨ ============

def analyze_trend_context(df: pd.DataFrame, symbol: str, 
                          oi_change: float = 0, volume_24h: float = 0) -> Dict:
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ v2.1æ–°å¢: ç‹¬ç«‹è¶‹åŠ¿åˆ†æå‡½æ•° - ä¾›é«˜æ³¢åŠ¨è½¨é“AIå®¡æ ¸è°ƒç”¨
    
    ä¸ç”Ÿæˆä¿¡å·ï¼Œåªè¿”å›è¶‹åŠ¿åˆ†æç»“æœï¼Œä¾›AIå†³ç­–å‚è€ƒ
    
    Args:
        df: Kçº¿æ•°æ® DataFrame
        symbol: äº¤æ˜“å¯¹
        oi_change: æŒä»“é‡å˜åŒ–ï¼ˆå¯é€‰ï¼‰
        volume_24h: 24å°æ—¶æˆäº¤é‡ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Dict: è¶‹åŠ¿åˆ†æä¸Šä¸‹æ–‡
        {
            "fdi_value": float,           # FDIåˆ†å½¢ç»´æ•° (1.0-1.5)
            "fdi_quality": str,           # "excellent"/"good"/"moderate"/"noisy"
            "is_smart_money": bool,       # æ˜¯å¦æœ‰èªæ˜é’±æ¨åŠ¨
            "smart_money_type": str,      # "accumulation"/"distribution"/"squeeze"/"liquidation"/"neutral"
            "efficiency_ratio": float,    # æ•ˆç‡æ¯” (0-1)
            "trend_bias_score": float,    # è¶‹åŠ¿åå‘è¯„åˆ† (-1åˆ°1)
            "trend_strength": str,        # "strong"/"moderate"/"weak"/"choppy"
            "momentum_direction": str,    # "bullish"/"bearish"/"neutral"
            "adx_value": float,           # ADXå€¼
            "rsi_value": float,           # RSIå€¼
            "bb_width": float,            # å¸ƒæ—å¸¦å®½åº¦
            "is_squeeze": bool,           # æ˜¯å¦å¸ƒæ—å¸¦æ”¶çª„ï¼ˆè“„åŠ¿ï¼‰
            "recommendation": str,        # "long_bias"/"short_bias"/"neutral"/"avoid"
        }
    """
    result = {
        "fdi_value": 1.35,
        "fdi_quality": "moderate",
        "is_smart_money": False,
        "smart_money_type": "neutral",
        "efficiency_ratio": 0.5,
        "trend_bias_score": 0,
        "trend_strength": "moderate",
        "momentum_direction": "neutral",
        "adx_value": 25,
        "rsi_value": 50,
        "bb_width": 0.03,
        "is_squeeze": False,
        "recommendation": "neutral"
    }
    
    if df is None or len(df) < 30:
        return result
    
    try:
        # ========== 1. è®¡ç®—FDIåˆ†å½¢ç»´æ•° ==========
        fdi_value = _calculate_fdi(df)
        result["fdi_value"] = fdi_value
        
        if fdi_value < 1.20:
            result["fdi_quality"] = "excellent"
        elif fdi_value < 1.30:
            result["fdi_quality"] = "good"
        elif fdi_value < 1.40:
            result["fdi_quality"] = "moderate"
        else:
            result["fdi_quality"] = "noisy"
        
        # ========== 2. è®¡ç®—èªæ˜é’±åˆ†æ ==========
        if oi_change != 0 and volume_24h > 0:
            # è®¡ç®—ä»·æ ¼å˜åŒ–
            price_change = 0
            if len(df) >= 20:
                price_change = (float(df['close'].iloc[-1]) - float(df['close'].iloc[-20])) / float(df['close'].iloc[-20])
            
            sm_result = _analyze_smart_money(price_change, oi_change, volume_24h)
            result["is_smart_money"] = sm_result.get("is_smart_money", False)
            result["smart_money_type"] = sm_result.get("trend_type", "neutral")
        
        # ========== 3. è®¡ç®—æ•ˆç‡æ¯” (Efficiency Ratio) ==========
        if len(df) >= 14:
            prices = df['close'].values[-14:]
            net_change = abs(prices[-1] - prices[0])
            total_change = sum(abs(prices[i+1] - prices[i]) for i in range(len(prices)-1))
            
            if total_change > 0:
                result["efficiency_ratio"] = net_change / total_change
        
        # ========== 4. è®¡ç®—ADX ==========
        if len(df) >= 28:
            try:
                high = df['high'].values
                low = df['low'].values
                close = df['close'].values
                
                # ç®€åŒ–ADXè®¡ç®—
                tr = np.maximum(high[1:] - low[1:], 
                               np.abs(high[1:] - close[:-1]),
                               np.abs(low[1:] - close[:-1]))
                
                plus_dm = np.where((high[1:] - high[:-1]) > (low[:-1] - low[1:]),
                                  np.maximum(high[1:] - high[:-1], 0), 0)
                minus_dm = np.where((low[:-1] - low[1:]) > (high[1:] - high[:-1]),
                                   np.maximum(low[:-1] - low[1:], 0), 0)
                
                # 14æœŸå¹³æ»‘
                period = 14
                atr_14 = pd.Series(tr).rolling(window=period).mean().iloc[-1]
                plus_di = 100 * pd.Series(plus_dm).rolling(window=period).mean().iloc[-1] / atr_14 if atr_14 > 0 else 0
                minus_di = 100 * pd.Series(minus_dm).rolling(window=period).mean().iloc[-1] / atr_14 if atr_14 > 0 else 0
                
                dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di) if (plus_di + minus_di) > 0 else 0
                result["adx_value"] = dx
            except:
                pass
        
        # ========== 5. è®¡ç®—RSI ==========
        if len(df) >= 15:
            deltas = df['close'].diff()
            gains = deltas.where(deltas > 0, 0)
            losses = (-deltas).where(deltas < 0, 0)
            
            avg_gain = gains.rolling(window=14).mean().iloc[-1]
            avg_loss = losses.rolling(window=14).mean().iloc[-1]
            
            if avg_loss > 0:
                rs = avg_gain / avg_loss
                result["rsi_value"] = 100 - (100 / (1 + rs))
            else:
                result["rsi_value"] = 100
        
        # ========== 6. è®¡ç®—å¸ƒæ—å¸¦å®½åº¦ ==========
        if len(df) >= 20:
            sma = df['close'].rolling(window=20).mean()
            std = df['close'].rolling(window=20).std()
            bb_upper = sma + 2 * std
            bb_lower = sma - 2 * std
            
            current_price = float(df['close'].iloc[-1])
            bb_width = (float(bb_upper.iloc[-1]) - float(bb_lower.iloc[-1])) / current_price
            result["bb_width"] = bb_width
            result["is_squeeze"] = bb_width < 0.025  # å¸ƒæ—å¸¦å®½åº¦<2.5%ä¸ºè“„åŠ¿
        
        # ========== 7. åˆ¤æ–­è¶‹åŠ¿å¼ºåº¦ ==========
        er = result["efficiency_ratio"]
        adx = result["adx_value"]
        fdi = result["fdi_value"]
        
        # ç»¼åˆè¯„ä¼°è¶‹åŠ¿å¼ºåº¦
        if er > 0.6 and adx > 30 and fdi < 1.30:
            result["trend_strength"] = "strong"
        elif er > 0.4 and adx > 22 and fdi < 1.40:
            result["trend_strength"] = "moderate"
        elif er < 0.25 or fdi > 1.45:
            result["trend_strength"] = "choppy"
        else:
            result["trend_strength"] = "weak"
        
        # ========== 8. åˆ¤æ–­åŠ¨é‡æ–¹å‘ ==========
        rsi = result["rsi_value"]
        
        if rsi < 30:
            result["momentum_direction"] = "oversold"
        elif rsi > 70:
            result["momentum_direction"] = "overbought"
        elif rsi < 45:
            result["momentum_direction"] = "bearish"
        elif rsi > 55:
            result["momentum_direction"] = "bullish"
        else:
            result["momentum_direction"] = "neutral"
        
        # ========== 9. è®¡ç®—è¶‹åŠ¿åå‘è¯„åˆ† ==========
        # -1 = å¼ºçœ‹ç©º, 0 = ä¸­æ€§, +1 = å¼ºçœ‹å¤š
        bias_score = 0
        
        # RSIè´¡çŒ®
        if rsi < 25:
            bias_score += 0.3  # è¶…å–çœ‹å¤š
        elif rsi > 75:
            bias_score -= 0.3  # è¶…ä¹°çœ‹ç©º
        elif rsi < 40:
            bias_score -= 0.1
        elif rsi > 60:
            bias_score += 0.1
        
        # èªæ˜é’±è´¡çŒ®
        if result["is_smart_money"]:
            if result["smart_money_type"] == "accumulation":
                bias_score += 0.3
            elif result["smart_money_type"] == "distribution":
                bias_score -= 0.3
        
        # FDIè´¡çŒ® (è¶‹åŠ¿æ¸…æ™°åº¦)
        if fdi < 1.25:
            bias_score *= 1.2  # è¶‹åŠ¿æ¸…æ™°ï¼Œæ”¾å¤§åå‘
        elif fdi > 1.40:
            bias_score *= 0.5  # è¶‹åŠ¿å˜ˆæ‚ï¼Œå‡å¼±åå‘
        
        result["trend_bias_score"] = max(-1, min(1, bias_score))
        
        # ========== 10. ç»™å‡ºå»ºè®® ==========
        if fdi > 1.45:
            result["recommendation"] = "avoid"  # å¤ªå˜ˆæ‚ï¼Œä¸å»ºè®®
        elif bias_score > 0.3:
            result["recommendation"] = "long_bias"
        elif bias_score < -0.3:
            result["recommendation"] = "short_bias"
        else:
            result["recommendation"] = "neutral"
        
        print(f"[TREND_CONTEXT] {symbol}: FDI={fdi:.3f}({result['fdi_quality']}) | "
              f"ER={er:.2f} | RSI={rsi:.1f} | ADX={adx:.1f} | "
              f"SmartMoney={result['is_smart_money']}({result['smart_money_type']}) | "
              f"Bias={bias_score:+.2f} â†’ {result['recommendation']}")
        
    except Exception as e:
        print(f"[TREND_CONTEXT] âš ï¸ åˆ†æå¼‚å¸¸ {symbol}: {e}")
    
    return result


def get_trend_context_for_ai(df: pd.DataFrame, symbol: str,
                             oi_change: float = 0, volume_24h: float = 0) -> str:
    """
    ğŸ”¥ğŸ”¥ğŸ”¥ v2.1æ–°å¢: è·å–è¶‹åŠ¿ä¸Šä¸‹æ–‡çš„æ–‡æœ¬æè¿° - ç›´æ¥ç”¨äºAI prompt
    
    Args:
        df: Kçº¿æ•°æ®
        symbol: äº¤æ˜“å¯¹
        oi_change: æŒä»“é‡å˜åŒ–
        volume_24h: 24hæˆäº¤é‡
    
    Returns:
        str: æ ¼å¼åŒ–çš„è¶‹åŠ¿åˆ†ææ–‡æœ¬ï¼Œå¯ç›´æ¥æ’å…¥AI prompt
    """
    ctx = analyze_trend_context(df, symbol, oi_change, volume_24h)
    
    # æ„å»ºæè¿°æ–‡æœ¬
    fdi_desc = {
        "excellent": "è¶‹åŠ¿æçº¯å‡€(å™ªéŸ³æå°‘)",
        "good": "è¶‹åŠ¿è‰¯å¥½(å™ªéŸ³è¾ƒå°‘)",
        "moderate": "è¶‹åŠ¿ä¸€èˆ¬(æœ‰ä¸€å®šå™ªéŸ³)",
        "noisy": "è¶‹åŠ¿å˜ˆæ‚(å™ªéŸ³å¤§,æ˜“æ‰«æŸ)"
    }.get(ctx["fdi_quality"], "æœªçŸ¥")
    
    sm_desc = ""
    if ctx["is_smart_money"]:
        sm_type_desc = {
            "accumulation": "èªæ˜é’±åœ¨å¸ç­¹(çœ‹å¤š)",
            "distribution": "èªæ˜é’±åœ¨å‡ºè´§(çœ‹ç©º)",
            "squeeze": "ç©ºå¤´æŒ¤å‹",
            "liquidation": "å¤šå¤´æ¸…ç®—"
        }.get(ctx["smart_money_type"], "èªæ˜é’±æ´»è·ƒ")
        sm_desc = f"âœ… {sm_type_desc}"
    else:
        sm_desc = "âŒ æ— æ˜æ˜¾ä¸»åŠ›ç—•è¿¹"
    
    strength_desc = {
        "strong": "å¼ºåŠ¿è¶‹åŠ¿",
        "moderate": "ä¸­ç­‰è¶‹åŠ¿",
        "weak": "å¼±åŠ¿è¶‹åŠ¿",
        "choppy": "éœ‡è¡æ— è¶‹åŠ¿"
    }.get(ctx["trend_strength"], "æœªçŸ¥")
    
    rec_desc = {
        "long_bias": "â¬†ï¸ åå¤š",
        "short_bias": "â¬‡ï¸ åç©º",
        "neutral": "â†”ï¸ ä¸­æ€§",
        "avoid": "âš ï¸ å»ºè®®å›é¿"
    }.get(ctx["recommendation"], "æœªçŸ¥")
    
    text = f"""### ğŸ”® è¶‹åŠ¿ä¸Šä¸‹æ–‡åˆ†æ (v2.1)

| æŒ‡æ ‡ | æ•°å€¼ | è§£è¯» |
|------|------|------|
| FDIåˆ†å½¢ç»´æ•° | {ctx['fdi_value']:.3f} | {fdi_desc} |
| æ•ˆç‡æ¯”(ER) | {ctx['efficiency_ratio']:.2f} | {'è¶‹åŠ¿çº¯å‡€' if ctx['efficiency_ratio'] > 0.5 else 'éœ‡è¡å¸‚'} |
| è¶‹åŠ¿å¼ºåº¦ | {strength_desc} | ADX={ctx['adx_value']:.1f} |
| å¸ƒæ—å¸¦å®½åº¦ | {ctx['bb_width']*100:.1f}% | {'ğŸ”¥è“„åŠ¿æ”¶çª„ä¸­' if ctx['is_squeeze'] else 'æ­£å¸¸æ³¢åŠ¨'} |
| èªæ˜é’± | {sm_desc} | |
| åå‘è¯„åˆ† | {ctx['trend_bias_score']:+.2f} | {rec_desc} |

**FDIè§„åˆ™**:
- FDI < 1.25: å¯ç§¯æå…¥åœºï¼ŒæŒ‚è¿‘å•(1-1.5%)
- FDI 1.25-1.35: æ­£å¸¸å…¥åœºï¼Œæ ‡å‡†æŒ‚å•(1.5-2%)
- FDI 1.35-1.45: è°¨æ…å…¥åœºï¼ŒæŒ‚è¿œå•æ¥é’ˆ(2-3%)
- FDI > 1.45: å»ºè®®å›é¿ï¼Œèµ°åŠ¿å¤ªä¹±
"""
    
    return text